#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æª”æ¡ˆè¿½è¹¤ç³»çµ±

åŠŸèƒ½ï¼š
1. ç›£æ§æª”æ¡ˆå¯«å…¥æ“ä½œ
2. è‡ªå‹•è¨˜éŒ„æ–°å¢çš„ç¶“å…¸æª”æ¡ˆ
3. å¯¦æ™‚æ›´æ–°è¿½è¹¤ç³»çµ±
4. æä¾›æª”æ¡ˆè®Šæ›´æ­·å²
"""

import os
import json
import hashlib
from datetime import datetime
from pathlib import Path
from classic_tracker import get_tracker, track_new_classic, generate_tracking_report

class FileTracker:
    """æª”æ¡ˆè¿½è¹¤å™¨"""
    
    def __init__(self):
        self.tracker_log = Path("æª”æ¡ˆè¿½è¹¤æ—¥èªŒ.json")
        self.load_log()
        
    def load_log(self):
        """è¼‰å…¥è¿½è¹¤æ—¥èªŒ"""
        if self.tracker_log.exists():
            with open(self.tracker_log, 'r', encoding='utf-8') as f:
                self.log_data = json.load(f)
        else:
            self.log_data = {
                "metadata": {
                    "created": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "total_operations": 0
                },
                "operations": []
            }
            
    def save_log(self):
        """å„²å­˜è¿½è¹¤æ—¥èªŒ"""
        self.log_data["metadata"]["last_updated"] = datetime.now().isoformat()
        
        with open(self.tracker_log, 'w', encoding='utf-8') as f:
            json.dump(self.log_data, f, ensure_ascii=False, indent=2)
            
    def calculate_file_hash(self, file_path):
        """è¨ˆç®—æª”æ¡ˆé›œæ¹Šå€¼"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return None         
   
    def log_file_operation(self, operation_type, file_path, details=None):
        """è¨˜éŒ„æª”æ¡ˆæ“ä½œ"""
        file_path = Path(file_path)
        
        operation = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation_type,
            "file_path": str(file_path),
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size if file_path.exists() else 0,
            "file_hash": self.calculate_file_hash(file_path) if file_path.exists() else None,
            "details": details or {}
        }
        
        self.log_data["operations"].append(operation)
        self.log_data["metadata"]["total_operations"] += 1
        
        # ä¿æŒæ—¥èªŒå¤§å°åˆç†ï¼ˆæœ€å¤šä¿ç•™1000æ¢è¨˜éŒ„ï¼‰
        if len(self.log_data["operations"]) > 1000:
            self.log_data["operations"] = self.log_data["operations"][-1000:]
            
        self.save_log()
        
        print(f"ğŸ“ è¨˜éŒ„æª”æ¡ˆæ“ä½œ: {operation_type} - {file_path.name}")
        
    def track_new_file(self, file_path, file_type="unknown"):
        """è¿½è¹¤æ–°æª”æ¡ˆ"""
        file_path = Path(file_path)
        
        # è¨˜éŒ„æª”æ¡ˆæ“ä½œ
        self.log_file_operation("create", file_path, {
            "file_type": file_type,
            "parent_dir": str(file_path.parent)
        })
        
        # å¦‚æœæ˜¯ç¶“å…¸ç›¸é—œæª”æ¡ˆï¼Œå˜—è©¦è‡ªå‹•åˆ†æ
        if self.is_classic_file(file_path):
            self.analyze_classic_file(file_path)
            
    def is_classic_file(self, file_path):
        """åˆ¤æ–·æ˜¯å¦ç‚ºç¶“å…¸ç›¸é—œæª”æ¡ˆ"""
        file_path = Path(file_path)
        
        # æª¢æŸ¥è·¯å¾‘æ˜¯å¦åŒ…å«ç¶“å…¸ç›¸é—œç›®éŒ„
        path_parts = file_path.parts
        classic_indicators = ['source_texts', 'translations', 'åŸæ–‡', 'ç¿»è­¯']
        
        return any(indicator in path_parts for indicator in classic_indicators)
        
    def analyze_classic_file(self, file_path):
        """åˆ†æç¶“å…¸æª”æ¡ˆä¸¦æ›´æ–°è¿½è¹¤ç³»çµ±"""
        file_path = Path(file_path)
        
        try:
            # å¾è·¯å¾‘åˆ†æç¶“å…¸è³‡è¨Š
            if 'source_texts' in file_path.parts:
                # é€™æ˜¯åŸæ–‡æª”æ¡ˆ
                self.handle_source_file(file_path)
            elif 'translations' in file_path.parts:
                # é€™æ˜¯ç¿»è­¯æª”æ¡ˆ
                self.handle_translation_file(file_path)
                
        except Exception as e:
            print(f"âš ï¸  åˆ†æç¶“å…¸æª”æ¡ˆå¤±æ•—: {e}")
            
    def handle_source_file(self, file_path):
        """è™•ç†åŸæ–‡æª”æ¡ˆ"""
        # å¾è·¯å¾‘æå–ç¶“å…¸è³‡è¨Š
        path_parts = file_path.parts
        source_texts_idx = path_parts.index('source_texts')
        
        if source_texts_idx + 1 < len(path_parts):
            classic_folder = path_parts[source_texts_idx + 1]
            
            print(f"ğŸ” æª¢æ¸¬åˆ°æ–°çš„åŸæ–‡æª”æ¡ˆ: {classic_folder}")
            
            # è§¸ç™¼è¿½è¹¤ç³»çµ±æ›´æ–°
            self.trigger_tracking_update(classic_folder)
            
    def handle_translation_file(self, file_path):
        """è™•ç†ç¿»è­¯æª”æ¡ˆ"""
        print(f"ğŸ“– æª¢æ¸¬åˆ°ç¿»è­¯æª”æ¡ˆæ›´æ–°: {file_path.name}")
        
        # æ›´æ–°ç¿»è­¯é€²åº¦
        self.update_translation_progress()
        
    def trigger_tracking_update(self, classic_folder):
        """è§¸ç™¼è¿½è¹¤ç³»çµ±æ›´æ–°"""
        try:
            # é‡æ–°ç”Ÿæˆè¿½è¹¤å ±å‘Š
            generate_tracking_report()
            print("âœ… è¿½è¹¤ç³»çµ±å·²è‡ªå‹•æ›´æ–°")
            
        except Exception as e:
            print(f"âš ï¸  è‡ªå‹•æ›´æ–°è¿½è¹¤ç³»çµ±å¤±æ•—: {e}")
            
    def update_translation_progress(self):
        """æ›´æ–°ç¿»è­¯é€²åº¦"""
        try:
            tracker = get_tracker()
            tracker.check_translation_progress()
            print("ğŸ“Š ç¿»è­¯é€²åº¦å·²æ›´æ–°")
            
        except Exception as e:
            print(f"âš ï¸  æ›´æ–°ç¿»è­¯é€²åº¦å¤±æ•—: {e}")
            
    def get_recent_operations(self, limit=10):
        """ç²å–æœ€è¿‘çš„æ“ä½œè¨˜éŒ„"""
        operations = self.log_data["operations"]
        return operations[-limit:] if operations else []
        
    def generate_activity_report(self):
        """ç”Ÿæˆæ´»å‹•å ±å‘Š"""
        operations = self.log_data["operations"]
        
        if not operations:
            return "ğŸ“‹ æš«ç„¡æª”æ¡ˆæ“ä½œè¨˜éŒ„"
            
        # çµ±è¨ˆè³‡è¨Š
        total_ops = len(operations)
        create_ops = len([op for op in operations if op["operation"] == "create"])
        modify_ops = len([op for op in operations if op["operation"] == "modify"])
        
        # æœ€è¿‘æ´»å‹•
        recent_ops = self.get_recent_operations(5)
        
        report = f"""# ğŸ“Š æª”æ¡ˆè¿½è¹¤æ´»å‹•å ±å‘Š

**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ˆ çµ±è¨ˆæ‘˜è¦

- **ç¸½æ“ä½œæ•¸**: {total_ops}
- **æ–°å»ºæª”æ¡ˆ**: {create_ops}
- **ä¿®æ”¹æª”æ¡ˆ**: {modify_ops}
- **æœ€å¾Œæ›´æ–°**: {self.log_data['metadata']['last_updated'][:19].replace('T', ' ')}

## ğŸ•’ æœ€è¿‘æ´»å‹•

"""
        
        for op in reversed(recent_ops):
            timestamp = op['timestamp'][:19].replace('T', ' ')
            report += f"- **{timestamp}**: {op['operation']} - `{op['file_name']}`\n"
            
        return report

# å…¨åŸŸæª”æ¡ˆè¿½è¹¤å™¨
_file_tracker = None

def get_file_tracker():
    """ç²å–å…¨åŸŸæª”æ¡ˆè¿½è¹¤å™¨å¯¦ä¾‹"""
    global _file_tracker
    if _file_tracker is None:
        _file_tracker = FileTracker()
    return _file_tracker

def track_file_write(file_path, file_type="unknown"):
    """è¿½è¹¤æª”æ¡ˆå¯«å…¥ï¼ˆä¾›å…¶ä»–æ¨¡çµ„èª¿ç”¨ï¼‰"""
    tracker = get_file_tracker()
    tracker.track_new_file(file_path, file_type)

def log_operation(operation_type, file_path, details=None):
    """è¨˜éŒ„æ“ä½œï¼ˆä¾›å…¶ä»–æ¨¡çµ„èª¿ç”¨ï¼‰"""
    tracker = get_file_tracker()
    tracker.log_file_operation(operation_type, file_path, details)

if __name__ == "__main__":
    # å‘½ä»¤åˆ—ä½¿ç”¨
    tracker = FileTracker()
    report = tracker.generate_activity_report()
    print(report)