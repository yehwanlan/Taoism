#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
from core.unicode_handler import safe_print
ä¿®å¾©å±¤ç´šç« ç¯€å·¥å…·

å°ˆé–€è™•ç†æœ‰å±¤ç´šçµæ§‹çš„ç¶“å…¸ï¼Œå¦‚æ¯å·åŒ…å«å¤šå€‹å“çš„æƒ…æ³
"""

import requests
import re
import json
import time
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin


class HierarchicalChapterFixer:
    """å±¤ç´šç« ç¯€ä¿®å¾©å™¨"""
    
    def __init__(self):
        self.base_url = "https://www.shidianguji.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def analyze_hierarchical_structure(self, book_id):
        """åˆ†æå±¤ç´šçµæ§‹"""
        safe_print(f"ğŸ” åˆ†æå±¤ç´šçµæ§‹: {book_id}")
        
        book_url = f"{self.base_url}/book/{book_id}"
        
        try:
            response = self.session.get(book_url, timeout=10)
            response.raise_for_status()
            
            # å¾JavaScriptä¸­æå–å®Œæ•´çš„ç« ç¯€æ¨¹çµæ§‹
            script_data = self._extract_chapter_tree_from_scripts(response.text)
            
            if script_data:
                return script_data
            
            # å¦‚æœJavaScriptæ–¹æ³•å¤±æ•—ï¼Œå˜—è©¦HTMLè§£æ
            return self._parse_html_structure(response.text)
            
        except Exception as e:
            safe_print(f"âŒ åˆ†æçµæ§‹å¤±æ•—: {e}")
            return None
    
    def _extract_chapter_tree_from_scripts(self, html_content):
        """å¾JavaScriptä¸­æå–ç« ç¯€æ¨¹çµæ§‹"""
        safe_print("ğŸŒ³ å¾JavaScriptæå–ç« ç¯€æ¨¹...")
        
        # å°‹æ‰¾åŒ…å«ç« ç¯€æ•¸æ“šçš„JavaScriptè®Šé‡
        patterns = [
            r'window\._ROUTER_DATA\s*=\s*({.*?});',
            r'window\._SSR_DATA\s*=\s*({.*?});',
            r'__MODERN_SERVER_DATA__[^>]*>([^<]+)',
        ]
        
        for pattern in patterns:
            matches = re.search(pattern, html_content, re.DOTALL)
            if matches:
                try:
                    data_str = matches.group(1)
                    data = json.loads(data_str)
                    
                    # éæ­¸æœå°‹ç« ç¯€çµæ§‹
                    chapter_tree = self._find_chapter_tree_in_data(data)
                    if chapter_tree:
                        safe_print(f"âœ… å¾JavaScriptæ‰¾åˆ°ç« ç¯€æ¨¹çµæ§‹")
                        return chapter_tree
                        
                except json.JSONDecodeError as e:
                    safe_print(f"âš ï¸  JSONè§£æå¤±æ•—: {e}")
                    continue
        
        return None
    
    def _find_chapter_tree_in_data(self, data):
        """åœ¨æ•¸æ“šä¸­éæ­¸å°‹æ‰¾ç« ç¯€æ¨¹"""
        if isinstance(data, dict):
            # æª¢æŸ¥æ˜¯å¦åŒ…å«ç« ç¯€æ¨¹çš„é—œéµå­—æ®µ
            for key in ['chapterTree', 'chapters', 'contents', 'catalog', 'toc']:
                if key in data:
                    tree_data = data[key]
                    if isinstance(tree_data, (list, dict)):
                        return self._parse_tree_structure(tree_data)
            
            # éæ­¸æœç´¢
            for value in data.values():
                result = self._find_chapter_tree_in_data(value)
                if result:
                    return result
        
        elif isinstance(data, list):
            for item in data:
                result = self._find_chapter_tree_in_data(item)
                if result:
                    return result
        
        return None
    
    def _parse_tree_structure(self, tree_data):
        """è§£ææ¨¹çµæ§‹"""
        chapters = []
        
        def parse_node(node, level=1, parent_title=""):
            if isinstance(node, dict):
                # æå–ç¯€é»ä¿¡æ¯
                title = node.get('title') or node.get('name') or node.get('chapterName', '')
                chapter_id = node.get('id') or node.get('chapterId') or node.get('key', '')
                
                if title and chapter_id:
                    chapter_info = {
                        'title': title,
                        'chapter_id': chapter_id,
                        'level': level,
                        'parent_title': parent_title,
                        'url': f"{self.base_url}/book/DZ0336/chapter/{chapter_id}",
                        'children': []
                    }
                    
                    # è™•ç†å­ç¯€é»
                    children_key = None
                    for key in ['children', 'subChapters', 'items']:
                        if key in node and isinstance(node[key], list):
                            children_key = key
                            break
                    
                    if children_key:
                        for child in node[children_key]:
                            child_chapters = parse_node(child, level + 1, title)
                            chapter_info['children'].extend(child_chapters)
                    
                    chapters.append(chapter_info)
                    return [chapter_info]
            
            elif isinstance(node, list):
                all_chapters = []
                for item in node:
                    item_chapters = parse_node(item, level, parent_title)
                    all_chapters.extend(item_chapters)
                return all_chapters
            
            return []
        
        if isinstance(tree_data, list):
            for item in tree_data:
                parse_node(item)
        else:
            parse_node(tree_data)
        
        return chapters
    
    def _parse_html_structure(self, html_content):
        """å¾HTMLè§£æçµæ§‹ï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰"""
        safe_print("ğŸ“„ å¾HTMLè§£æçµæ§‹...")
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # å°‹æ‰¾ç›®éŒ„çµæ§‹
        catalog_selectors = [
            '.reader-catalog-tree',
            '.catalog-tree',
            '.chapter-list',
            '.toc'
        ]
        
        for selector in catalog_selectors:
            catalog = soup.select_one(selector)
            if catalog:
                return self._parse_catalog_html(catalog)
        
        return None
    
    def _parse_catalog_html(self, catalog_element):
        """è§£æç›®éŒ„HTMLå…ƒç´ """
        chapters = []
        
        # å°‹æ‰¾æ‰€æœ‰ç« ç¯€é …ç›®
        items = catalog_element.find_all(['div', 'li'], class_=re.compile(r'tree-option|chapter-item'))
        
        for item in items:
            # æå–å±¤ç´šä¿¡æ¯
            level_match = re.search(r'level-(\d+)', item.get('class', [''])[0] if item.get('class') else '')
            level = int(level_match.group(1)) if level_match else 1
            
            # æå–éˆæ¥å’Œæ¨™é¡Œ
            link = item.find('a')
            if link:
                href = link.get('href', '')
                title = link.get_text().strip()
                
                chapter_id_match = re.search(r'/chapter/([^/?]+)', href)
                if chapter_id_match:
                    chapter_id = chapter_id_match.group(1)
                    
                    chapters.append({
                        'title': title,
                        'chapter_id': chapter_id,
                        'level': level,
                        'url': urljoin(self.base_url, href),
                        'children': []
                    })
        
        return chapters
    
    def get_missing_chapters(self, all_chapters, existing_files):
        """æ‰¾å‡ºç¼ºå¤±çš„ç« ç¯€"""
        existing_titles = set()
        
        for file_path in existing_files:
            filename = file_path.stem
            # ç§»é™¤ç·¨è™Ÿå‰ç¶´ï¼Œæå–æ¨™é¡Œ
            title_part = re.sub(r'^\d+_', '', filename)
            existing_titles.add(title_part)
        
        missing_chapters = []
        
        def check_chapter(chapter):
            clean_title = re.sub(r'[<>:"/\\|?*]', '_', chapter['title'])
            if clean_title not in existing_titles:
                missing_chapters.append(chapter)
            
            # æª¢æŸ¥å­ç« ç¯€
            for child in chapter.get('children', []):
                check_chapter(child)
        
        for chapter in all_chapters:
            check_chapter(chapter)
        
        return missing_chapters
    
    def crawl_chapter_content(self, chapter_info):
        """çˆ¬å–ç« ç¯€å…§å®¹"""
        safe_print(f"ğŸ“– çˆ¬å–: {chapter_info['title']} (Level {chapter_info['level']})")
        
        try:
            # å˜—è©¦å¤šç¨®APIç«¯é»
            api_urls = [
                f"{self.base_url}/api/book/DZ0336/chapter/{chapter_info['chapter_id']}",
                f"{self.base_url}/api/ancientlib/volume/{chapter_info['chapter_id']}/content",
                chapter_info['url']
            ]
            
            for api_url in api_urls:
                safe_print(f"  å˜—è©¦: {api_url}")
                content = self._extract_content_from_url(api_url)
                if content and len(content) > 100:  # ç¢ºä¿å…§å®¹æœ‰æ„ç¾©
                    return {
                        'title': chapter_info['title'],
                        'content': content,
                        'chapter_id': chapter_info['chapter_id'],
                        'level': chapter_info['level']
                    }
                time.sleep(1)
            
            safe_print(f"âŒ ç„¡æ³•ç²å–å…§å®¹: {chapter_info['title']}")
            return None
            
        except Exception as e:
            safe_print(f"âŒ çˆ¬å–å¤±æ•—: {e}")
            return None
    
    def _extract_content_from_url(self, url):
        """å¾URLæå–å…§å®¹"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # æª¢æŸ¥éŸ¿æ‡‰é¡å‹
            content_type = response.headers.get('content-type', '')
            
            if 'application/json' in content_type:
                # JSONéŸ¿æ‡‰
                data = response.json()
                return self._extract_text_from_json(data)
            else:
                # HTMLéŸ¿æ‡‰
                soup = BeautifulSoup(response.text, 'html.parser')
                return self._extract_text_from_html(soup)
                
        except Exception as e:
            safe_print(f"  âš ï¸  æå–å¤±æ•—: {e}")
            return None
    
    def _extract_text_from_json(self, data):
        """å¾JSONæå–æ–‡æœ¬"""
        content_parts = []
        
        def extract_recursive(obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if key in ['content', 'text', 'body', 'html'] and isinstance(value, str):
                        text = value.strip()
                        if len(text) > 20 and re.search(r'[\u4e00-\u9fff]', text):
                            # æ¸…ç†HTMLæ¨™ç±¤
                            clean_text = re.sub(r'<[^>]+>', '', text)
                            if clean_text.strip():
                                content_parts.append(clean_text.strip())
                    else:
                        extract_recursive(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract_recursive(item)
        
        extract_recursive(data)
        
        if content_parts:
            return '\n\n'.join(content_parts)
        return None
    
    def _extract_text_from_html(self, soup):
        """å¾HTMLæå–æ–‡æœ¬"""
        # å°‹æ‰¾ä¸»è¦å…§å®¹å€åŸŸ
        content_selectors = [
            'main.read-layout-main article.chapter-reader',
            '.chapter-content',
            '.book-content', 
            '.text-content',
            'article',
            '.main-content'
        ]
        
        for selector in content_selectors:
            elements = soup.select(selector)
            if elements:
                content_parts = []
                for element in elements[0].find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'div']):
                    text = element.get_text().strip()
                    if text and len(text) > 5:
                        content_parts.append(text)
                
                if content_parts:
                    return '\n\n'.join(content_parts)
        
        return None
    
    def save_hierarchical_chapter(self, book_folder, chapter_data, chapter_number):
        """ä¿å­˜å±¤ç´šç« ç¯€"""
        # æ ¹æ“šå±¤ç´šèª¿æ•´æ–‡ä»¶å
        level_prefix = "  " * (chapter_data['level'] - 1)  # ç¸®é€²è¡¨ç¤ºå±¤ç´š
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', chapter_data['title'])
        
        filename = f"{chapter_number:02d}_{clean_title}.txt"
        file_path = book_folder / "åŸæ–‡" / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# {chapter_data['title']}\n\n")
            f.write(chapter_data['content'])
        
        safe_print(f"âœ… å·²ä¿å­˜: {filename} (Level {chapter_data['level']})")
        return filename
    
    def fix_hierarchical_structure(self, book_id, book_folder_name):
        """ä¿®å¾©å±¤ç´šçµæ§‹"""
        safe_print(f"ğŸ”§ é–‹å§‹ä¿®å¾©å±¤ç´šçµæ§‹: {book_id}")
        safe_print("=" * 60)
        
        # 1. åˆ†æå±¤ç´šçµæ§‹
        chapter_tree = self.analyze_hierarchical_structure(book_id)
        if not chapter_tree:
            safe_print("âŒ ç„¡æ³•ç²å–ç« ç¯€æ¨¹çµæ§‹")
            return False
        
        safe_print(f"ğŸŒ³ æ‰¾åˆ°ç« ç¯€æ¨¹ï¼Œå…± {len(chapter_tree)} å€‹é ‚ç´šç« ç¯€")
        
        # æ‰“å°çµæ§‹é è¦½
        def print_tree(chapters, indent=0):
            for chapter in chapters:
                prefix = "  " * indent
                safe_print(f"{prefix}- {chapter['title']} (Level {chapter['level']})")
                if chapter.get('children'):
                    print_tree(chapter['children'], indent + 1)
        
        safe_print("\nğŸ“‹ ç« ç¯€çµæ§‹é è¦½:")
        print_tree(chapter_tree)
        
        # 2. æª¢æŸ¥ç¾æœ‰æ–‡ä»¶
        book_folder = Path(f"../docs/source_texts/{book_folder_name}")
        source_folder = book_folder / "åŸæ–‡"
        
        if not source_folder.exists():
            safe_print(f"âŒ æ‰¾ä¸åˆ°æºæ–‡ä»¶å¤¾: {source_folder}")
            return False
        
        existing_files = list(source_folder.glob("*.txt"))
        safe_print(f"\nğŸ“ ç¾æœ‰æ–‡ä»¶: {len(existing_files)} å€‹")
        
        # 3. æ‰¾å‡ºç¼ºå¤±çš„ç« ç¯€
        missing_chapters = self.get_missing_chapters(chapter_tree, existing_files)
        
        safe_print(f"âŒ ç¼ºå¤±ç« ç¯€: {len(missing_chapters)} å€‹")
        for chapter in missing_chapters:
            level_prefix = "  " * (chapter['level'] - 1)
            safe_print(f"  {level_prefix}- {chapter['title']} (Level {chapter['level']})")
        
        if not missing_chapters:
            safe_print("âœ… æ²’æœ‰ç¼ºå¤±çš„ç« ç¯€")
            return True
        
        # 4. çˆ¬å–ç¼ºå¤±çš„ç« ç¯€
        success_count = 0
        for i, chapter in enumerate(missing_chapters, 1):
            safe_print(f"\nğŸ“– è™•ç†ç¼ºå¤±ç« ç¯€ {i}/{len(missing_chapters)}")
            
            chapter_data = self.crawl_chapter_content(chapter)
            if chapter_data:
                # ç¢ºå®šç« ç¯€ç·¨è™Ÿ
                chapter_number = len(existing_files) + success_count + 1
                
                # ä¿å­˜ç« ç¯€
                filename = self.save_hierarchical_chapter(book_folder, chapter_data, chapter_number)
                success_count += 1
                
                # æ›´æ–°README
                self._update_readme_with_hierarchy(book_folder, chapter_data, chapter_number)
            
            time.sleep(2)  # é¿å…è«‹æ±‚éå¿«
        
        safe_print(f"\nğŸ‰ ä¿®å¾©å®Œæˆï¼æˆåŠŸæ·»åŠ  {success_count}/{len(missing_chapters)} å€‹ç« ç¯€")
        return success_count > 0
    
    def _update_readme_with_hierarchy(self, book_folder, chapter_data, chapter_number):
        """æ›´æ–°READMEï¼ŒåŒ…å«å±¤ç´šä¿¡æ¯"""
        readme_path = book_folder / "README.md"
        if readme_path.exists():
            try:
                with open(readme_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ ¹æ“šå±¤ç´šæ·»åŠ ç¸®é€²
                level_prefix = "  " * (chapter_data['level'] - 1)
                new_line = f"{level_prefix}- {chapter_number:02d}. {chapter_data['title']}"
                
                # åœ¨ç« ç¯€åˆ—è¡¨ä¸­æ·»åŠ æ–°ç« ç¯€
                if "## ç« ç¯€åˆ—è¡¨" in content:
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if line.startswith("## ç« ç¯€åˆ—è¡¨"):
                            # æ‰¾åˆ°åˆ—è¡¨çµæŸä½ç½®
                            j = i + 1
                            while j < len(lines) and (lines[j].startswith('- ') or lines[j].startswith('  ') or lines[j].strip() == ''):
                                j += 1
                            # æ’å…¥æ–°ç« ç¯€
                            lines.insert(j, new_line)
                            break
                    
                    with open(readme_path, 'w', encoding='utf-8') as f:
                        f.write('\n'.join(lines))
                
            except Exception as e:
                safe_print(f"âš ï¸  æ›´æ–°READMEå¤±æ•—: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    fixer = HierarchicalChapterFixer()
    
    # ä¿®å¾© å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»_DZ0336
    book_id = "DZ0336"
    book_folder_name = "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»_DZ0336"
    
    success = fixer.fix_hierarchical_structure(book_id, book_folder_name)
    
    if success:
        safe_print("\nğŸŠ å±¤ç´šçµæ§‹ä¿®å¾©æˆåŠŸï¼")
        safe_print("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥æ–°æ·»åŠ çš„ç« ç¯€å…§å®¹å’Œå±¤ç´šçµæ§‹")
    else:
        safe_print("\nâŒ å±¤ç´šçµæ§‹ä¿®å¾©å¤±æ•—")
        safe_print("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥ç¶²çµ¡é€£æ¥å’Œèª¿è©¦ä¿¡æ¯")


if __name__ == "__main__":
    main()