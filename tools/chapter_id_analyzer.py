#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
from core.unicode_handler import safe_print
ç« ç¯€IDåˆ†æå™¨ - æ™ºèƒ½è­˜åˆ¥ç« ç¯€IDæ¨¡å¼ä¸¦æ¡ç”¨å°æ‡‰ç­–ç•¥

æ ¹æ“šç« ç¯€IDçš„ç‰¹å¾µï¼ˆæ•¸å­—åºåˆ— vs éš¨æ©Ÿå­—ç¬¦ä¸²ï¼‰ä¾†æ±ºå®šæœ€ä½³çš„å­ç« ç¯€ç™¼ç¾ç­–ç•¥
"""

import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

sys.path.append(str(Path(__file__).parent.parent))

@dataclass
class ChapterIdPattern:
    """ç« ç¯€IDæ¨¡å¼åˆ†æçµæœ"""
    pattern_type: str  # 'sequential', 'random', 'mixed', 'unknown'
    confidence: float  # 0.0 - 1.0
    characteristics: Dict
    recommended_strategy: str

class ChapterIdAnalyzer:
    """ç« ç¯€IDåˆ†æå™¨"""
    
    def __init__(self):
        self.patterns = {
            'sequential_numeric': r'^\d+$',  # ç´”æ•¸å­—
            'sequential_prefixed': r'^[a-zA-Z]+\d+$',  # å­—æ¯+æ•¸å­—
            'sequential_suffixed': r'^\d+[a-zA-Z]+$',  # æ•¸å­—+å­—æ¯
            'random_string': r'^[a-zA-Z0-9]{8,}$',  # é•·éš¨æ©Ÿå­—ç¬¦ä¸²
            'uuid_like': r'^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$',  # UUIDæ ¼å¼
            'hash_like': r'^[a-f0-9]{32,}$',  # Hashæ ¼å¼
            'mixed_pattern': r'^[a-zA-Z0-9]+$'  # æ··åˆæ¨¡å¼
        }
    
    def analyze_chapter_ids(self, chapters: List[Dict]) -> ChapterIdPattern:
        """åˆ†æç« ç¯€IDåˆ—è¡¨ï¼Œè­˜åˆ¥æ¨¡å¼"""
        safe_print("ğŸ” åˆ†æç« ç¯€IDæ¨¡å¼...")
        
        if not chapters:
            return ChapterIdPattern('unknown', 0.0, {}, 'default')
        
        chapter_ids = [ch.get('chapter_id', '') for ch in chapters if ch.get('chapter_id')]
        
        if not chapter_ids:
            return ChapterIdPattern('unknown', 0.0, {}, 'default')
        
        safe_print(f"ğŸ“Š åˆ†æ {len(chapter_ids)} å€‹ç« ç¯€ID")
        
        # åˆ†ææ¯å€‹IDçš„ç‰¹å¾µ
        analysis_results = []
        for chapter_id in chapter_ids:
            result = self._analyze_single_id(chapter_id)
            analysis_results.append(result)
        
        # çµ±è¨ˆæ¨¡å¼åˆ†å¸ƒ
        pattern_counts = {}
        for result in analysis_results:
            pattern = result['primary_pattern']
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
        
        # ç¢ºå®šä¸»è¦æ¨¡å¼
        total_ids = len(chapter_ids)
        dominant_pattern = max(pattern_counts.items(), key=lambda x: x[1])
        confidence = dominant_pattern[1] / total_ids
        
        safe_print(f"ğŸ“‹ æ¨¡å¼åˆ†æçµæœ:")
        for pattern, count in pattern_counts.items():
            percentage = (count / total_ids) * 100
            safe_print(f"   {pattern}: {count} å€‹ ({percentage:.1f}%)")
        
        safe_print(f"ğŸ¯ ä¸»è¦æ¨¡å¼: {dominant_pattern[0]} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
        
        # ç”Ÿæˆç‰¹å¾µåˆ†æ
        characteristics = self._generate_characteristics(chapter_ids, analysis_results)
        
        # æ¨è–¦ç­–ç•¥
        strategy = self._recommend_strategy(dominant_pattern[0], confidence, characteristics)
        
        return ChapterIdPattern(
            pattern_type=dominant_pattern[0],
            confidence=confidence,
            characteristics=characteristics,
            recommended_strategy=strategy
        )
    
    def _analyze_single_id(self, chapter_id: str) -> Dict:
        """åˆ†æå–®å€‹ç« ç¯€ID"""
        result = {
            'id': chapter_id,
            'length': len(chapter_id),
            'has_numbers': bool(re.search(r'\d', chapter_id)),
            'has_letters': bool(re.search(r'[a-zA-Z]', chapter_id)),
            'has_special': bool(re.search(r'[^a-zA-Z0-9]', chapter_id)),
            'numeric_ratio': len(re.findall(r'\d', chapter_id)) / len(chapter_id),
            'letter_ratio': len(re.findall(r'[a-zA-Z]', chapter_id)) / len(chapter_id),
            'patterns_matched': []
        }
        
        # æª¢æŸ¥åŒ¹é…çš„æ¨¡å¼
        for pattern_name, pattern_regex in self.patterns.items():
            if re.match(pattern_regex, chapter_id):
                result['patterns_matched'].append(pattern_name)
        
        # ç¢ºå®šä¸»è¦æ¨¡å¼
        if result['patterns_matched']:
            # å„ªå…ˆç´šæ’åº
            priority_order = [
                'sequential_numeric', 'sequential_prefixed', 'sequential_suffixed',
                'uuid_like', 'hash_like', 'random_string', 'mixed_pattern'
            ]
            
            for pattern in priority_order:
                if pattern in result['patterns_matched']:
                    result['primary_pattern'] = pattern
                    break
        else:
            result['primary_pattern'] = 'unknown'
        
        return result
    
    def _generate_characteristics(self, chapter_ids: List[str], analysis_results: List[Dict]) -> Dict:
        """ç”Ÿæˆæ•´é«”ç‰¹å¾µåˆ†æ"""
        characteristics = {
            'total_count': len(chapter_ids),
            'avg_length': sum(len(id) for id in chapter_ids) / len(chapter_ids),
            'min_length': min(len(id) for id in chapter_ids),
            'max_length': max(len(id) for id in chapter_ids),
            'has_consistent_length': len(set(len(id) for id in chapter_ids)) == 1,
            'all_numeric': all(result['primary_pattern'] == 'sequential_numeric' for result in analysis_results),
            'all_random': all(result['primary_pattern'] == 'random_string' for result in analysis_results),
            'mixed_types': len(set(result['primary_pattern'] for result in analysis_results)) > 1
        }
        
        # æª¢æŸ¥åºåˆ—æ€§
        if characteristics['all_numeric']:
            numeric_ids = [int(id) for id in chapter_ids if id.isdigit()]
            if numeric_ids:
                numeric_ids.sort()
                is_sequential = all(numeric_ids[i] == numeric_ids[i-1] + 1 for i in range(1, len(numeric_ids)))
                characteristics['is_sequential'] = is_sequential
                characteristics['sequence_gaps'] = not is_sequential
        
        return characteristics
    
    def _recommend_strategy(self, pattern_type: str, confidence: float, characteristics: Dict) -> str:
        """æ ¹æ“šåˆ†æçµæœæ¨è–¦ç™¼ç¾ç­–ç•¥"""
        
        if confidence < 0.5:
            return 'hybrid_strategy'  # æ··åˆç­–ç•¥
        
        strategy_map = {
            'sequential_numeric': 'numeric_sequence_strategy',
            'sequential_prefixed': 'prefixed_sequence_strategy', 
            'sequential_suffixed': 'suffixed_sequence_strategy',
            'random_string': 'structure_based_strategy',
            'uuid_like': 'structure_based_strategy',
            'hash_like': 'structure_based_strategy',
            'mixed_pattern': 'adaptive_strategy',
            'unknown': 'default_strategy'
        }
        
        base_strategy = strategy_map.get(pattern_type, 'default_strategy')
        
        # æ ¹æ“šç‰¹å¾µèª¿æ•´ç­–ç•¥
        if characteristics.get('mixed_types', False):
            return 'hybrid_strategy'
        
        if pattern_type in ['random_string', 'uuid_like', 'hash_like']:
            return 'structure_based_strategy'  # ä½¿ç”¨æˆ‘å€‘ç¾æœ‰çš„æ™ºèƒ½çµæ§‹åˆ†æ
        
        return base_strategy
    
    def get_discovery_recommendations(self, pattern: ChapterIdPattern) -> Dict:
        """ç²å–ç™¼ç¾ç­–ç•¥çš„å…·é«”å»ºè­°"""
        recommendations = {
            'strategy': pattern.recommended_strategy,
            'confidence': pattern.confidence,
            'methods': [],
            'fallback_methods': [],
            'special_considerations': []
        }
        
        if pattern.pattern_type == 'sequential_numeric':
            recommendations['methods'] = [
                'numeric_increment_probing',
                'range_scanning',
                'gap_detection'
            ]
            recommendations['fallback_methods'] = ['structure_based_discovery']
            recommendations['special_considerations'] = [
                'å¯ä»¥å˜—è©¦æ•¸å­—éå¢æ¢æ¸¬',
                'æ³¨æ„å¯èƒ½çš„åºåˆ—é–“éš™',
                'æª¢æŸ¥æ˜¯å¦æœ‰è·³è™Ÿ'
            ]
        
        elif pattern.pattern_type in ['random_string', 'uuid_like', 'hash_like']:
            recommendations['methods'] = [
                'structure_based_discovery',
                'catalog_tree_analysis',
                'level_hierarchy_detection'
            ]
            recommendations['fallback_methods'] = ['content_pattern_matching']
            recommendations['special_considerations'] = [
                'ä¾è³´é é¢çµæ§‹åˆ†æ',
                'ä½¿ç”¨ç›®éŒ„æ¨¹å±¤ç´šé—œä¿‚',
                'ç„¡æ³•é€²è¡ŒIDæ¨¡å¼é æ¸¬'
            ]
        
        elif pattern.pattern_type in ['sequential_prefixed', 'sequential_suffixed']:
            recommendations['methods'] = [
                'pattern_based_increment',
                'prefix_suffix_analysis',
                'structure_based_discovery'
            ]
            recommendations['fallback_methods'] = ['hybrid_approach']
            recommendations['special_considerations'] = [
                'åˆ†æå‰ç¶´/å¾Œç¶´æ¨¡å¼',
                'çµåˆçµæ§‹åˆ†æ',
                'å¯èƒ½éœ€è¦æ··åˆç­–ç•¥'
            ]
        
        else:  # mixed_pattern, unknown
            recommendations['methods'] = [
                'adaptive_discovery',
                'multiple_strategy_testing',
                'structure_based_discovery'
            ]
            recommendations['fallback_methods'] = ['manual_inspection']
            recommendations['special_considerations'] = [
                'éœ€è¦è‡ªé©æ‡‰ç­–ç•¥',
                'æ¸¬è©¦å¤šç¨®æ–¹æ³•',
                'å¯èƒ½éœ€è¦äººå·¥æª¢æŸ¥'
            ]
        
        return recommendations

def test_chapter_id_analyzer():
    """æ¸¬è©¦ç« ç¯€IDåˆ†æå™¨"""
    safe_print("ğŸ§ª æ¸¬è©¦ç« ç¯€IDåˆ†æå™¨")
    safe_print("=" * 50)
    
    analyzer = ChapterIdAnalyzer()
    
    # æ¸¬è©¦æ¡ˆä¾‹1: æ•¸å­—åºåˆ—
    safe_print("\nğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹1: æ•¸å­—åºåˆ—")
    numeric_chapters = [
        {'chapter_id': '1', 'title': 'ç¬¬ä¸€ç« '},
        {'chapter_id': '2', 'title': 'ç¬¬äºŒç« '},
        {'chapter_id': '3', 'title': 'ç¬¬ä¸‰ç« '},
        {'chapter_id': '5', 'title': 'ç¬¬äº”ç« '},  # æœ‰é–“éš™
    ]
    
    pattern1 = analyzer.analyze_chapter_ids(numeric_chapters)
    recommendations1 = analyzer.get_discovery_recommendations(pattern1)
    
    safe_print(f"æ¨¡å¼é¡å‹: {pattern1.pattern_type}")
    safe_print(f"æ¨è–¦ç­–ç•¥: {pattern1.recommended_strategy}")
    safe_print(f"å»ºè­°æ–¹æ³•: {', '.join(recommendations1['methods'])}")
    
    # æ¸¬è©¦æ¡ˆä¾‹2: éš¨æ©Ÿå­—ç¬¦ä¸²ï¼ˆå¦‚DZ0735çš„æƒ…æ³ï¼‰
    safe_print("\nğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹2: éš¨æ©Ÿå­—ç¬¦ä¸²")
    random_chapters = [
        {'chapter_id': '1k1r7oqmxh8uz', 'title': 'åº„å­å£ä¹‰å‘é¢˜'},
        {'chapter_id': '1k1r7pcj7a2wi', 'title': 'å—åçœŸç»å£ä¹‰å·ä¹‹ä¸€'},
        {'chapter_id': '1k1r7pdhjf8kb', 'title': 'å—åçœŸç»å£ä¹‰å·ä¹‹äºŒ'},
        {'chapter_id': '1k1ro1wu1qwiu', 'title': 'å—åçœŸç»å£ä¹‰å·ä¹‹ä¸‰åä¸€'},
    ]
    
    pattern2 = analyzer.analyze_chapter_ids(random_chapters)
    recommendations2 = analyzer.get_discovery_recommendations(pattern2)
    
    safe_print(f"æ¨¡å¼é¡å‹: {pattern2.pattern_type}")
    safe_print(f"æ¨è–¦ç­–ç•¥: {pattern2.recommended_strategy}")
    safe_print(f"å»ºè­°æ–¹æ³•: {', '.join(recommendations2['methods'])}")
    safe_print(f"ç‰¹æ®Šè€ƒæ…®: {recommendations2['special_considerations']}")
    
    # æ¸¬è©¦æ¡ˆä¾‹3: æ··åˆæ¨¡å¼
    safe_print("\nğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹3: æ··åˆæ¨¡å¼")
    mixed_chapters = [
        {'chapter_id': '1', 'title': 'åºè¨€'},
        {'chapter_id': 'ch001', 'title': 'ç¬¬ä¸€ç« '},
        {'chapter_id': '1k1r7oqmxh8uz', 'title': 'ç‰¹æ®Šç« ç¯€'},
        {'chapter_id': 'appendix', 'title': 'é™„éŒ„'},
    ]
    
    pattern3 = analyzer.analyze_chapter_ids(mixed_chapters)
    recommendations3 = analyzer.get_discovery_recommendations(pattern3)
    
    safe_print(f"æ¨¡å¼é¡å‹: {pattern3.pattern_type}")
    safe_print(f"æ¨è–¦ç­–ç•¥: {pattern3.recommended_strategy}")
    safe_print(f"å»ºè­°æ–¹æ³•: {', '.join(recommendations3['methods'])}")

if __name__ == "__main__":
    test_chapter_id_analyzer()