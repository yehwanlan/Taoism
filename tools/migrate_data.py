#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
from core.unicode_handler import safe_print
è³‡æ–™é·ç§»å·¥å…·

å°‡èˆŠç³»çµ±çš„è³‡æ–™é·ç§»åˆ°æ–°çš„æ¨¡çµ„åŒ–çµæ§‹ä¸­
"""

import json
import shutil
from pathlib import Path
from datetime import datetime


class DataMigrator:
    """è³‡æ–™é·ç§»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é·ç§»å™¨"""
        self.root_dir = Path(".")
        self.old_files = {
            "ç¶“å…¸è¿½è¹¤è¨˜éŒ„.json": "data/tracking/classics.json",
            "ç¶“å…¸è¿½è¹¤å ±å‘Š.md": "data/tracking/tracking_report.md",
            "æª”æ¡ˆè¿½è¹¤æ—¥èªŒ.json": "data/logs/file_operations.json"
        }
        
    def migrate_tracking_data(self):
        """é·ç§»è¿½è¹¤è³‡æ–™"""
        safe_print("ğŸ“Š é·ç§»è¿½è¹¤è³‡æ–™...")
        
        old_file = self.root_dir / "ç¶“å…¸è¿½è¹¤è¨˜éŒ„.json"
        new_file = self.root_dir / "data/tracking/classics.json"
        
        if old_file.exists():
            # ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
            new_file.parent.mkdir(parents=True, exist_ok=True)
            
            # è®€å–èˆŠè³‡æ–™
            with open(old_file, 'r', encoding='utf-8') as f:
                old_data = json.load(f)
                
            # æ¸…ç†æ¸¬è©¦è³‡æ–™
            if "classics" in old_data:
                # ç§»é™¤æ¸¬è©¦ç¶“å…¸
                old_data["classics"] = {
                    k: v for k, v in old_data["classics"].items()
                    if not k.startswith("TEST") and "æ¸¬è©¦" not in v.get("book_info", {}).get("title", "")
                }
                
                # æ›´æ–°çµ±è¨ˆ
                total_classics = len(old_data["classics"])
                total_chapters = sum(classic["chapter_count"] for classic in old_data["classics"].values())
                total_characters = sum(classic["total_characters"] for classic in old_data["classics"].values())
                
                old_data["metadata"].update({
                    "total_classics": total_classics,
                    "total_chapters": total_chapters,
                    "total_characters": total_characters,
                    "migrated_at": datetime.now().isoformat(),
                    "version": "2.0"
                })
                
            # ä¿®å¾©è·¯å¾‘æ ¼å¼ï¼ˆçµ±ä¸€ä½¿ç”¨æ­£æ–œç·šï¼‰
            for classic in old_data.get("classics", {}).values():
                if "source_dir" in classic:
                    classic["source_dir"] = classic["source_dir"].replace("\\", "/")
                if "translation_dir" in classic:
                    classic["translation_dir"] = classic["translation_dir"].replace("\\", "/")
                    
            # å¯«å…¥æ–°æª”æ¡ˆ
            with open(new_file, 'w', encoding='utf-8') as f:
                json.dump(old_data, f, ensure_ascii=False, indent=2)
                
            safe_print(f"âœ… è¿½è¹¤è³‡æ–™å·²é·ç§»: {new_file}")
            
            # å‚™ä»½èˆŠæª”æ¡ˆ
            backup_file = self.root_dir / "backup" / f"ç¶“å…¸è¿½è¹¤è¨˜éŒ„_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            backup_file.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(old_file, backup_file)
            safe_print(f"ğŸ“¦ èˆŠæª”æ¡ˆå·²å‚™ä»½: {backup_file}")
            
        else:
            safe_print("âš ï¸  æœªæ‰¾åˆ°èˆŠçš„è¿½è¹¤è¨˜éŒ„æª”æ¡ˆ")
            
    def migrate_file_logs(self):
        """é·ç§»æª”æ¡ˆæ—¥èªŒ"""
        safe_print("ğŸ“ é·ç§»æª”æ¡ˆæ—¥èªŒ...")
        
        old_file = self.root_dir / "æª”æ¡ˆè¿½è¹¤æ—¥èªŒ.json"
        new_file = self.root_dir / "data/logs/file_operations.json"
        
        if old_file.exists():
            # ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
            new_file.parent.mkdir(parents=True, exist_ok=True)
            
            # è®€å–èˆŠè³‡æ–™
            with open(old_file, 'r', encoding='utf-8') as f:
                old_data = json.load(f)
                
            # æ¸…ç†æ¸¬è©¦è³‡æ–™å’Œä¿®å¾©è·¯å¾‘
            if "operations" in old_data:
                cleaned_operations = []
                for op in old_data["operations"]:
                    # è·³éæ¸¬è©¦è³‡æ–™
                    if "æ¸¬è©¦" not in op.get("file_path", ""):
                        # ä¿®å¾©è·¯å¾‘æ ¼å¼
                        if "file_path" in op:
                            op["file_path"] = op["file_path"].replace("\\", "/")
                        cleaned_operations.append(op)
                        
                old_data["operations"] = cleaned_operations
                old_data["metadata"]["total_operations"] = len(cleaned_operations)
                old_data["metadata"]["migrated_at"] = datetime.now().isoformat()
                old_data["metadata"]["version"] = "2.0"
                
            # å¯«å…¥æ–°æª”æ¡ˆ
            with open(new_file, 'w', encoding='utf-8') as f:
                json.dump(old_data, f, ensure_ascii=False, indent=2)
                
            safe_print(f"âœ… æª”æ¡ˆæ—¥èªŒå·²é·ç§»: {new_file}")
            
            # å‚™ä»½èˆŠæª”æ¡ˆ
            backup_file = self.root_dir / "backup" / f"æª”æ¡ˆè¿½è¹¤æ—¥èªŒ_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            backup_file.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(old_file, backup_file)
            safe_print(f"ğŸ“¦ èˆŠæª”æ¡ˆå·²å‚™ä»½: {backup_file}")
            
        else:
            safe_print("âš ï¸  æœªæ‰¾åˆ°èˆŠçš„æª”æ¡ˆæ—¥èªŒ")
            
    def migrate_reports(self):
        """é·ç§»å ±å‘Šæª”æ¡ˆ"""
        safe_print("ğŸ“‹ é·ç§»å ±å‘Šæª”æ¡ˆ...")
        
        old_files = [
            "ç¶“å…¸è¿½è¹¤å ±å‘Š.md",
            "è¿½è¹¤ç‹€æ…‹.json"
        ]
        
        for old_filename in old_files:
            old_file = self.root_dir / old_filename
            if old_file.exists():
                if old_filename.endswith('.md'):
                    new_file = self.root_dir / "data/tracking/tracking_report.md"
                else:
                    new_file = self.root_dir / "data/tracking/system_status.json"
                    
                # ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
                new_file.parent.mkdir(parents=True, exist_ok=True)
                
                # è¤‡è£½æª”æ¡ˆ
                shutil.copy2(old_file, new_file)
                safe_print(f"âœ… å·²é·ç§»: {old_filename} -> {new_file}")
                
                # å‚™ä»½èˆŠæª”æ¡ˆ
                backup_file = self.root_dir / "backup" / f"{old_filename}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                backup_file.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(old_file, backup_file)
                
    def archive_old_files(self):
        """æ­¸æª”èˆŠæª”æ¡ˆ"""
        safe_print("ğŸ“¦ æ­¸æª”èˆŠæª”æ¡ˆ...")
        
        # è¦æ­¸æª”çš„æª”æ¡ˆ
        old_files = [
            "auto_translator.py",
            "easy_translator.py", 
            "classic_tracker.py",
            "file_tracker.py",
            "tracking_monitor.py",
            "update_tracker.py",
            "baopuzi_manager.py",
            "rename_folders.py",
            "cleanup_duplicates.py",
            "config.json",
            "GIT.txt",
            "GEMINI.md",
            "generate_scriptures_js.py",
            "å°ˆæ¡ˆç‹€æ…‹ç¸½çµ.md"
        ]
        
        archive_dir = self.root_dir / "archive" / f"v1_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        archive_dir.mkdir(parents=True, exist_ok=True)
        
        archived_count = 0
        for filename in old_files:
            old_file = self.root_dir / filename
            if old_file.exists():
                new_file = archive_dir / filename
                shutil.move(str(old_file), str(new_file))
                safe_print(f"ğŸ“ å·²æ­¸æª”: {filename}")
                archived_count += 1
                
        safe_print(f"âœ… å·²æ­¸æª” {archived_count} å€‹æª”æ¡ˆåˆ°: {archive_dir}")
        
    def clean_old_data_files(self):
        """æ¸…ç†èˆŠçš„è³‡æ–™æª”æ¡ˆ"""
        safe_print("ğŸ§¹ æ¸…ç†èˆŠè³‡æ–™æª”æ¡ˆ...")
        
        old_data_files = [
            "ç¶“å…¸è¿½è¹¤è¨˜éŒ„.json",
            "ç¶“å…¸è¿½è¹¤å ±å‘Š.md", 
            "æª”æ¡ˆè¿½è¹¤æ—¥èªŒ.json",
            "è¿½è¹¤ç‹€æ…‹.json"
        ]
        
        for filename in old_data_files:
            old_file = self.root_dir / filename
            if old_file.exists():
                old_file.unlink()
                safe_print(f"ğŸ—‘ï¸  å·²åˆªé™¤: {filename}")
                
    def run_migration(self):
        """åŸ·è¡Œå®Œæ•´é·ç§»"""
        safe_print("ğŸš€ é–‹å§‹è³‡æ–™é·ç§»...")
        safe_print("=" * 50)
        
        try:
            # 1. é·ç§»è¿½è¹¤è³‡æ–™
            self.migrate_tracking_data()
            
            # 2. é·ç§»æª”æ¡ˆæ—¥èªŒ
            self.migrate_file_logs()
            
            # 3. é·ç§»å ±å‘Šæª”æ¡ˆ
            self.migrate_reports()
            
            # 4. æ­¸æª”èˆŠæª”æ¡ˆ
            self.archive_old_files()
            
            # 5. æ¸…ç†èˆŠè³‡æ–™æª”æ¡ˆ
            self.clean_old_data_files()
            
            safe_print("\nğŸ‰ é·ç§»å®Œæˆï¼")
            safe_print("=" * 50)
            safe_print("âœ… æ‰€æœ‰è³‡æ–™å·²æˆåŠŸé·ç§»åˆ°æ–°çš„æ¨¡çµ„åŒ–çµæ§‹")
            safe_print("ğŸ“¦ èˆŠæª”æ¡ˆå·²å‚™ä»½åˆ° backup/ å’Œ archive/ ç›®éŒ„")
            safe_print("ğŸš€ ç¾åœ¨å¯ä»¥ä½¿ç”¨æ–°çš„ main.py ä»‹é¢")
            
        except Exception as e:
            safe_print(f"âŒ é·ç§»éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            safe_print("ğŸ’¡ è«‹æª¢æŸ¥éŒ¯èª¤ä¸¦é‡æ–°åŸ·è¡Œé·ç§»")


def main():
    """ä¸»å‡½æ•¸"""
    migrator = DataMigrator()
    
    safe_print("ğŸ“‹ é“æ•™ç¶“å…¸ç¿»è­¯ç³»çµ± - è³‡æ–™é·ç§»å·¥å…·")
    safe_print("=" * 50)
    safe_print("æ­¤å·¥å…·å°‡æŠŠèˆŠç³»çµ±çš„è³‡æ–™é·ç§»åˆ°æ–°çš„æ¨¡çµ„åŒ–çµæ§‹ä¸­")
    safe_print("âš ï¸  é·ç§»å‰æœƒè‡ªå‹•å‚™ä»½æ‰€æœ‰èˆŠæª”æ¡ˆ")
    
    confirm = input("\nç¢ºå®šè¦é–‹å§‹é·ç§»å—ï¼Ÿ(y/N): ").strip().lower()
    
    if confirm == 'y':
        migrator.run_migration()
    else:
        safe_print("âŒ é·ç§»å·²å–æ¶ˆ")


if __name__ == "__main__":
    main()