#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
from core.unicode_handler import safe_print
å°ˆé–€ä¿®å¾© DZ0336 å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç» çš„çµæ§‹å•é¡Œ

æ ¹æ“šmeta descriptionä¸­çš„ä¿¡æ¯ï¼Œé€™æœ¬æ›¸æ‡‰è©²æœ‰ä»¥ä¸‹çµæ§‹ï¼š
- é¦–ç‚ºã€Šå¼€åº¦å“ã€‹
- æ¬¡ç‚ºã€Šå–„å¯¹ã€‹ã€Šæ¶æŠ¥ã€‹ã€Šå—ç½ªã€‹ä¸‰å“  
- å†æ¬¡ç‚ºã€Šå¿æ‚”ã€‹ã€Šå¥‰æˆ’ã€‹ç­‰å…«å“
- å†æ¬¡ã€Šç”Ÿç¥ã€‹ã€Šå¼˜æ•™ã€‹ç­‰ä¹å“

ä½†ç¾åœ¨çš„æ–‡ä»¶åªæœ‰å·çš„æ¨™é¡Œï¼Œç¼ºå°‘å…·é«”çš„å“çš„å…§å®¹ã€‚
"""

import requests
import re
import json
import time
from pathlib import Path
from bs4 import BeautifulSoup


class DZ0336StructureFixer:
    """DZ0336çµæ§‹ä¿®å¾©å™¨"""
    
    def __init__(self):
        self.base_url = "https://www.shidianguji.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # æ ¹æ“šmeta descriptionå®šç¾©çš„é æœŸçµæ§‹
        self.expected_structure = {
            "å·ä¹‹ä¸€": ["å¼€åº¦å“ç¬¬ä¸€"],
            "å·ä¹‹äºŒ": ["å–„å¯¹å“ç¬¬äºŒ"],
            "å·ä¹‹ä¸‰": ["æ¶æŠ¥å“ç¬¬ä¸‰", "å—ç½ªå“ç¬¬å››"],  # æ¨æ¸¬
            "å·ä¹‹å››": ["å¿æ‚”å“ç¬¬äº”"],  # å¾ç¾æœ‰æ–‡ä»¶å¯çŸ¥
            "å·ä¹‹äº”": ["å¥‰æˆ’å“ç¬¬å…­"],  # å¾ç¾æœ‰æ–‡ä»¶å¯çŸ¥
            "å·ä¹‹å…­": ["å“ç¬¬ä¸ƒ"],  # å¾…ç¢ºèª
            "å·ä¹‹ä¸ƒ": ["å“ç¬¬å…«"],  # å¾…ç¢ºèª
            "å·ä¹‹å…«": ["å“ç¬¬ä¹"],  # å¾…ç¢ºèª
            "å·ä¹‹ä¹": ["å“ç¬¬å"],  # å¾…ç¢ºèª
            "å·ä¹‹å": ["ç”Ÿç¥å“", "å¼˜æ•™å“"]  # æ¨æ¸¬
        }
        
    def analyze_actual_structure(self):
        """åˆ†æå¯¦éš›çš„ç¶²ç«™çµæ§‹"""
        safe_print("ğŸ” åˆ†æå¯¦éš›ç¶²ç«™çµæ§‹...")
        
        # å·²çŸ¥çš„ç« ç¯€IDå’Œå°æ‡‰é—œä¿‚
        known_chapters = {
            "DZ0336_1": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹ä¸€",
            "DZ0336_2": "å¼€åº¦å“ç¬¬ä¸€",
            "DZ0336_3": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹äºŒ", 
            "DZ0336_7": "å¤ªä¸Šæ´ç„çµå®ç´«æŠ¥å› ç¼˜ç»å·ä¹‹ä¸‰",
            "DZ0336_9": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹å››",
            "DZ0336_12": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹äº”",
            "DZ0336_19": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹å…­",
            "DZ0336_22": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹ä¸ƒ",
            "DZ0336_26": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹å…«",
            "DZ0336_28": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹ä¹",
            "DZ0336_33": "å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»å·ä¹‹å"
        }
        
        # åˆ†ææ¯å€‹ç« ç¯€IDä¹‹é–“çš„é–“éš”ï¼Œæ¨æ¸¬ç¼ºå¤±çš„ç« ç¯€
        chapter_ids = [1, 2, 3, 7, 9, 12, 19, 22, 26, 28, 33]
        
        missing_ranges = []
        for i in range(len(chapter_ids) - 1):
            current = chapter_ids[i]
            next_id = chapter_ids[i + 1]
            if next_id - current > 1:
                missing_ranges.append((current + 1, next_id - 1))
        
        safe_print("ğŸ“Š ç« ç¯€IDåˆ†æ:")
        safe_print(f"å·²çŸ¥ç« ç¯€ID: {chapter_ids}")
        safe_print(f"å¯èƒ½ç¼ºå¤±çš„IDç¯„åœ: {missing_ranges}")
        
        return missing_ranges, known_chapters
    
    def probe_missing_chapters(self, missing_ranges):
        """æ¢æ¸¬ç¼ºå¤±çš„ç« ç¯€"""
        safe_print("\nğŸ” æ¢æ¸¬ç¼ºå¤±ç« ç¯€...")
        
        found_chapters = []
        
        for start, end in missing_ranges:
            safe_print(f"æ¢æ¸¬ç¯„åœ DZ0336_{start} åˆ° DZ0336_{end}:")
            
            for chapter_id in range(start, end + 1):
                chapter_key = f"DZ0336_{chapter_id}"
                url = f"{self.base_url}/book/DZ0336/chapter/{chapter_key}"
                
                safe_print(f"  æ¸¬è©¦: {chapter_key}")
                
                try:
                    response = self.session.get(url, timeout=5)
                    if response.status_code == 200:
                        # å˜—è©¦æå–æ¨™é¡Œ
                        soup = BeautifulSoup(response.text, 'html.parser')
                        title_elem = soup.find('h1', class_='Goq6DYSE')
                        if title_elem:
                            title = title_elem.get_text().strip()
                            safe_print(f"    âœ… æ‰¾åˆ°: {title}")
                            found_chapters.append({
                                'chapter_id': chapter_key,
                                'title': title,
                                'url': url
                            })
                        else:
                            safe_print(f"    âš ï¸  éŸ¿æ‡‰æˆåŠŸä½†ç„¡æ¨™é¡Œ")
                    else:
                        safe_print(f"    âŒ HTTP {response.status_code}")
                        
                except Exception as e:
                    safe_print(f"    âŒ éŒ¯èª¤: {e}")
                
                time.sleep(1)  # é¿å…è«‹æ±‚éå¿«
        
        return found_chapters
    
    def probe_extended_chapters(self, max_chapter=40):
        """æ¢æ¸¬æ“´å±•ç¯„åœçš„ç« ç¯€ï¼ˆç”¨æ–¼ç™¼ç¾æ›´å¤šç« ç¯€ï¼‰"""
        safe_print(f"\nğŸ” æ¢æ¸¬æ“´å±•ç« ç¯€ç¯„åœ (DZ0336_34 åˆ° DZ0336_{max_chapter})...")
        
        found_chapters = []
        
        for chapter_id in range(34, max_chapter + 1):
            chapter_key = f"DZ0336_{chapter_id}"
            url = f"{self.base_url}/book/DZ0336/chapter/{chapter_key}"
            
            safe_print(f"  æ¸¬è©¦: {chapter_key}")
            
            try:
                response = self.session.get(url, timeout=5)
                if response.status_code == 200:
                    # å˜—è©¦æå–æ¨™é¡Œ
                    soup = BeautifulSoup(response.text, 'html.parser')
                    title_elem = soup.find('h1', class_='Goq6DYSE')
                    if title_elem:
                        title = title_elem.get_text().strip()
                        safe_print(f"    âœ… æ‰¾åˆ°: {title}")
                        found_chapters.append({
                            'chapter_id': chapter_key,
                            'title': title,
                            'url': url
                        })
                    else:
                        safe_print(f"    âš ï¸  éŸ¿æ‡‰æˆåŠŸä½†ç„¡æ¨™é¡Œ")
                else:
                    safe_print(f"    âŒ HTTP {response.status_code}")
                    
            except Exception as e:
                safe_print(f"    âŒ éŒ¯èª¤: {e}")
            
            time.sleep(1)  # é¿å…è«‹æ±‚éå¿«
        
        return found_chapters
    
    def crawl_chapter_content(self, chapter_info):
        """çˆ¬å–ç« ç¯€å…§å®¹"""
        safe_print(f"\nğŸ“– çˆ¬å–ç« ç¯€: {chapter_info['title']}")
        
        try:
            # å˜—è©¦APIç«¯é»
            api_url = f"{self.base_url}/api/book/DZ0336/chapter/{chapter_info['chapter_id']}"
            
            response = self.session.get(api_url, timeout=10)
            if response.status_code == 200:
                try:
                    data = response.json()
                    content = self._extract_content_from_api_response(data)
                    if content:
                        # å˜—è©¦å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å
                        actual_title = self._extract_actual_title_from_content(content)
                        if actual_title and actual_title != chapter_info['title']:
                            safe_print(f"  ğŸ“ ç™¼ç¾å¯¦éš›å“å: {actual_title}")
                            chapter_info['actual_title'] = actual_title
                        return content
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœAPIå¤±æ•—ï¼Œå˜—è©¦ç›´æ¥è¨ªå•é é¢
            response = self.session.get(chapter_info['url'], timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                content = self._extract_content_from_html(soup)
                if content:
                    # å˜—è©¦å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å
                    actual_title = self._extract_actual_title_from_content(content)
                    if actual_title and actual_title != chapter_info['title']:
                        safe_print(f"  ğŸ“ ç™¼ç¾å¯¦éš›å“å: {actual_title}")
                        chapter_info['actual_title'] = actual_title
                    return content
            
            safe_print(f"âŒ ç„¡æ³•ç²å–å…§å®¹")
            return None
            
        except Exception as e:
            safe_print(f"âŒ çˆ¬å–å¤±æ•—: {e}")
            return None
    
    def _extract_content_from_api_response(self, data):
        """å¾APIéŸ¿æ‡‰ä¸­æå–å…§å®¹"""
        content_parts = []
        
        def extract_recursive(obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if key in ['content', 'text', 'body'] and isinstance(value, str):
                        text = value.strip()
                        if len(text) > 20 and re.search(r'[\u4e00-\u9fff]', text):
                            # æ¸…ç†HTMLæ¨™ç±¤
                            clean_text = re.sub(r'<[^>]+>', '', text)
                            if clean_text.strip():
                                content_parts.append(clean_text.strip())
                    else:
                        extract_recursive(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract_recursive(item)
        
        extract_recursive(data)
        
        if content_parts:
            return '\n\n'.join(content_parts)
        return None
    
    def _extract_content_from_html(self, soup):
        """å¾HTMLä¸­æå–å…§å®¹"""
        # å°‹æ‰¾ä¸»è¦å…§å®¹å€åŸŸ
        content_selectors = [
            'main.read-layout-main article.chapter-reader',
            '.chapter-content',
            '.book-content',
            '.text-content'
        ]
        
        for selector in content_selectors:
            elements = soup.select(selector)
            if elements:
                content_parts = []
                for element in elements[0].find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p']):
                    text = element.get_text().strip()
                    if text and len(text) > 3:
                        content_parts.append(text)
                
                if content_parts:
                    return '\n\n'.join(content_parts)
        
        return None
    
    def _extract_actual_title_from_content(self, content):
        """å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å"""
        lines = content.split('\n')
        
        for line in lines[:10]:  # æª¢æŸ¥å‰10è¡Œ
            line = line.strip()
            
            # å°‹æ‰¾å“åæ¨¡å¼
            if 'å“ç¬¬' in line and len(line) < 30:
                # æ¸…ç†å“å
                clean_title = line.replace('å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»', '').strip()
                if clean_title and clean_title != line:
                    return clean_title
                return line
            
            # å°‹æ‰¾å…¶ä»–å¯èƒ½çš„ç« ç¯€æ¨™é¡Œ
            if line and len(line) < 50 and not line.startswith('#'):
                # æª¢æŸ¥æ˜¯å¦åŒ…å«å“ã€ç« ã€å·ç­‰é—œéµå­—
                if any(keyword in line for keyword in ['å“', 'ç« ', 'å·']):
                    if 'å¤ªä¸Šæ´ç„' not in line:  # æ’é™¤æ›¸å
                        return line
        
        return None
    
    def save_new_chapter(self, book_folder, chapter_info, content):
        """ä¿å­˜æ–°ç™¼ç¾çš„ç« ç¯€"""
        # ä½¿ç”¨å¯¦éš›çš„å“åä½œç‚ºæ¨™é¡Œï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        display_title = chapter_info.get('actual_title', chapter_info['title'])
        
        # æ¸…ç†æ¨™é¡Œä½œç‚ºæ–‡ä»¶å
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', display_title)
        
        # ç¢ºå®šæ–‡ä»¶ç·¨è™Ÿ
        source_folder = book_folder / "åŸæ–‡"
        existing_files = list(source_folder.glob("*.txt"))
        next_number = len(existing_files) + 1
        
        filename = f"{next_number:02d}_{clean_title}.txt"
        file_path = source_folder / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# {display_title}\n\n")
            f.write(content)
        
        safe_print(f"âœ… å·²ä¿å­˜: {filename}")
        
        # æ›´æ–°chapter_infoä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
        chapter_info['display_title'] = display_title
        chapter_info['filename'] = filename
        
        return filename
    
    def update_readme(self, book_folder, new_chapters):
        """æ›´æ–°READMEæ–‡ä»¶"""
        readme_path = book_folder / "README.md"
        if not readme_path.exists():
            return
        
        try:
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›´æ–°ç« ç¯€ç¸½æ•¸
            total_chapters = len(list((book_folder / "åŸæ–‡").glob("*.txt")))
            content = re.sub(r'ç¸½å…± \d+ å€‹ç« ç¯€', f'ç¸½å…± {total_chapters} å€‹ç« ç¯€', content)
            
            # æ·»åŠ æ–°ç« ç¯€åˆ°åˆ—è¡¨
            if "## ç« ç¯€åˆ—è¡¨" in content:
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    if line.startswith("## ç« ç¯€åˆ—è¡¨"):
                        # æ‰¾åˆ°åˆ—è¡¨çµæŸä½ç½®
                        j = i + 1
                        while j < len(lines) and (lines[j].startswith('- ') or lines[j].strip() == ''):
                            j += 1
                        
                        # æ·»åŠ æ–°ç« ç¯€
                        for chapter in new_chapters:
                            chapter_num = len(list((book_folder / "åŸæ–‡").glob("*.txt")))
                            new_line = f"- {chapter_num:02d}. {chapter['title']}"
                            lines.insert(j, new_line)
                            j += 1
                        break
                
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(lines))
            
        except Exception as e:
            safe_print(f"âš ï¸  æ›´æ–°READMEå¤±æ•—: {e}")
    
    def fix_dz0336_structure(self):
        """ä¿®å¾©DZ0336çµæ§‹"""
        safe_print("ğŸ”§ é–‹å§‹ä¿®å¾© DZ0336 çµæ§‹å•é¡Œ")
        safe_print("=" * 60)
        
        # 1. åˆ†æå¯¦éš›çµæ§‹
        missing_ranges, known_chapters = self.analyze_actual_structure()
        
        # 2. æ¢æ¸¬ç¼ºå¤±ç« ç¯€
        found_chapters = self.probe_missing_chapters(missing_ranges)
        
        # 3. æ¢æ¸¬æ“´å±•ç¯„åœçš„ç« ç¯€ï¼ˆ34-40ï¼‰
        extended_chapters = self.probe_extended_chapters(40)
        found_chapters.extend(extended_chapters)
        
        if not found_chapters:
            safe_print("\nâŒ æ²’æœ‰æ‰¾åˆ°æ–°çš„ç« ç¯€")
            return False
        
        safe_print(f"\nğŸ¯ æ‰¾åˆ° {len(found_chapters)} å€‹æ–°ç« ç¯€:")
        for chapter in found_chapters:
            safe_print(f"  - {chapter['chapter_id']}: {chapter['title']}")
        
        # 4. æª¢æŸ¥ç›®æ¨™æ–‡ä»¶å¤¾
        book_folder = Path("../docs/source_texts/å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»_DZ0336")
        if not book_folder.exists():
            safe_print(f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™æ–‡ä»¶å¤¾: {book_folder}")
            return False
        
        # 5. çˆ¬å–ä¸¦ä¿å­˜æ–°ç« ç¯€
        success_count = 0
        saved_chapters = []
        
        for chapter in found_chapters:
            content = self.crawl_chapter_content(chapter)
            if content and len(content) > 100:  # ç¢ºä¿å…§å®¹æœ‰æ„ç¾©
                filename = self.save_new_chapter(book_folder, chapter, content)
                success_count += 1
                saved_chapters.append(chapter)
                
                # åŒæ™‚ç”Ÿæˆç¿»è­¯æ¨¡æ¿
                self._generate_translation_template(book_folder, chapter, content)
            
            time.sleep(2)  # é¿å…è«‹æ±‚éå¿«
        
        # 6. æ›´æ–°README
        if saved_chapters:
            self.update_readme(book_folder, saved_chapters)
        
        safe_print(f"\nğŸ‰ ä¿®å¾©å®Œæˆï¼æˆåŠŸæ·»åŠ  {success_count}/{len(found_chapters)} å€‹ç« ç¯€")
        
        if success_count > 0:
            safe_print("\nğŸ“‹ å»ºè­°æª¢æŸ¥ä»¥ä¸‹å…§å®¹:")
            safe_print("1. æ–°æ·»åŠ çš„åŸæ–‡æ–‡ä»¶å…§å®¹æ˜¯å¦æ­£ç¢º")
            safe_print("2. ç¿»è­¯æ¨¡æ¿æ˜¯å¦å·²ç”Ÿæˆ")
            safe_print("3. README.md æ˜¯å¦å·²æ›´æ–°")
            safe_print("4. ç« ç¯€é †åºæ˜¯å¦åˆç†")
        
        return success_count > 0
    
    def _generate_translation_template(self, book_folder, chapter_info, content):
        """ç”Ÿæˆç¿»è­¯æ¨¡æ¿"""
        translation_folder = Path(f"../docs/translations/å¤ªä¸Šæ´ç„çµå®ä¸šæŠ¥å› ç¼˜ç»_DZ0336")
        translation_folder.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨å¯¦éš›çš„å“åä½œç‚ºæ¨™é¡Œ
        display_title = chapter_info.get('display_title', chapter_info['title'])
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', display_title)
        
        # ç¢ºå®šæ–‡ä»¶ç·¨è™Ÿ
        existing_files = list(translation_folder.glob("*.md"))
        next_number = len(existing_files) + 1
        
        filename = f"{next_number:02d}_{clean_title}.md"
        file_path = translation_folder / filename
        
        template_content = f"""# {display_title}

## åŸæ–‡

{content}

## ç¿»è­¯

[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]

åŸæ–‡å­—æ•¸ï¼š{len(content)} å­—
å»ºè­°ï¼šè«‹ä½¿ç”¨AIç¿»è­¯å·¥å…·æˆ–äººå·¥ç¿»è­¯æ­¤æ®µè½ã€‚

ç¿»è­¯è¦é»ï¼š
1. ä¿æŒåŸæ–‡æ„æ€
2. ä½¿ç”¨ç¾ä»£ä¸­æ–‡è¡¨é”
3. ä¿ç•™é‡è¦çš„å¤ä»£è¡“èª
4. æ·»åŠ å¿…è¦çš„è¨»è§£èªªæ˜

## è¨»è§£

**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……]

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- [å¾…è£œå……]

**ç¿»è­¯è¦é»ï¼š**
- [å¾…è£œå……]

---
*ç¿»è­¯æ™‚é–“ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}*
*ç¿»è­¯æ–¹å¼ï¼šè‡ªå‹•ç”Ÿæˆæ¨¡æ¿*
*ç« ç¯€IDï¼š{chapter_info['chapter_id']}*
*å¯¦éš›å“åï¼š{display_title}*
"""
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(template_content)
        
        safe_print(f"ğŸ“ å·²ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {filename}")


def main():
    """ä¸»å‡½æ•¸"""
    fixer = DZ0336StructureFixer()
    
    success = fixer.fix_dz0336_structure()
    
    if success:
        safe_print("\nğŸŠ DZ0336 çµæ§‹ä¿®å¾©æˆåŠŸï¼")
        safe_print("ğŸ’¡ ç¾åœ¨é€™æœ¬ç¶“å…¸æ‡‰è©²åŒ…å«äº†æ‰€æœ‰ç¼ºå¤±çš„å“ï¼ˆç« ç¯€ï¼‰")
    else:
        safe_print("\nâŒ DZ0336 çµæ§‹ä¿®å¾©å¤±æ•—")
        safe_print("ğŸ’¡ å¯èƒ½æ‰€æœ‰ç« ç¯€éƒ½å·²ç¶“å­˜åœ¨ï¼Œæˆ–è€…ç¶²çµ¡é€£æ¥æœ‰å•é¡Œ")


if __name__ == "__main__":
    main()