#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°¡å–®ç¿»è­¯å™¨ - ç©©å®šç‰ˆæœ¬
ç›´æ¥è¼¸å…¥URLï¼Œè‡ªå‹•å®Œæˆçˆ¬å–å’Œæ¨¡æ¿ç”Ÿæˆ
"""

import asyncio
import aiohttp
import re
import json
import time
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime

def safe_print(*args, **kwargs):
    """å®‰å…¨æ‰“å°å‡½æ•¸"""
    try:
        print(*args, **kwargs)
    except UnicodeEncodeError:
        safe_args = []
        for arg in args:
            if isinstance(arg, str):
                safe_args.append(arg.encode('utf-8', errors='replace').decode('utf-8'))
            else:
                safe_args.append(str(arg))
        print(*safe_args, **kwargs)
    except Exception as e:
        print(f"æ‰“å°éŒ¯èª¤: {e}")

class SimpleTranslator:
    """ç°¡å–®ç¿»è­¯å™¨"""
    
    def __init__(self):
        self.base_url = "https://www.shidianguji.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    async def translate_book(self, book_url: str):
        """ç¿»è­¯æ›¸ç±çš„å®Œæ•´æµç¨‹"""
        safe_print("ğŸš€ ç°¡å–®ç¿»è­¯å™¨å•Ÿå‹•")
        safe_print("=" * 50)
        
        try:
            # 1. ç²å–æ›¸ç±è³‡è¨Š
            book_info = await self.get_book_info(book_url)
            safe_print(f"ğŸ“š æ›¸ç±ï¼š{book_info['title']}")
            safe_print(f"ğŸ‘¤ ä½œè€…ï¼š{book_info['author']}")
            
            # 2. è¨­å®šå°ˆæ¡ˆçµæ§‹
            self.setup_project_structure(book_info)
            
            # 3. ç²å–ç« ç¯€åˆ—è¡¨
            chapters = await self.get_chapter_list(book_url)
            if not chapters:
                safe_print("âŒ ç„¡æ³•ç²å–ç« ç¯€åˆ—è¡¨")
                return False
            
            safe_print(f"ğŸ“‹ æ‰¾åˆ° {len(chapters)} å€‹ç« ç¯€")
            
            # 4. çˆ¬å–ç« ç¯€å…§å®¹ï¼ˆæ·»åŠ å»é‡åŠŸèƒ½ï¼‰
            success_count = 0
            content_hashes = set()  # ç”¨æ–¼æª¢æ¸¬é‡è¤‡å…§å®¹
            actual_chapter_number = 1
            
            for i, chapter in enumerate(chapters, 1):
                safe_print(f"\nğŸ”„ è™•ç†ç¬¬ {i} ç« : {chapter['title']}")
                
                content = await self.crawl_chapter(chapter)
                if content:
                    # æª¢æŸ¥å…§å®¹æ˜¯å¦é‡è¤‡
                    content_hash = hash(content['content'])
                    if content_hash in content_hashes:
                        safe_print(f"â­ï¸  è·³éé‡è¤‡å…§å®¹")
                        continue
                    
                    content_hashes.add(content_hash)
                    
                    # ä¿å­˜åŸæ–‡
                    self.save_source_text(content, actual_chapter_number)
                    # ç”Ÿæˆç¿»è­¯æ¨¡æ¿
                    self.generate_translation_template(content, actual_chapter_number)
                    success_count += 1
                    actual_chapter_number += 1
                    safe_print(f"âœ… å®Œæˆ")
                else:
                    safe_print(f"âŒ å¤±æ•—")
                
                # å»¶é²é¿å…è¢«å°é–
                await asyncio.sleep(1)
            
            safe_print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
            safe_print(f"âœ… æˆåŠŸè™•ç†ï¼š{success_count}/{len(chapters)} ç« ")
            safe_print(f"ğŸ“ åŸæ–‡ä½ç½®ï¼š{self.source_dir}")
            safe_print(f"ğŸ“ ç¿»è­¯ä½ç½®ï¼š{self.translation_dir}")
            
            return success_count > 0
            
        except Exception as e:
            safe_print(f"âŒ è™•ç†å¤±æ•—: {e}")
            return False
    
    async def get_book_info(self, book_url: str):
        """ç²å–æ›¸ç±è³‡è¨Š"""
        async with aiohttp.ClientSession(headers=self.headers) as session:
            async with session.get(book_url) as response:
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # æå–æ›¸ç±ID
                book_id = re.search(r'/book/([^/?]+)', book_url)
                book_id = book_id.group(1) if book_id else "unknown"
                
                # æå–æ¨™é¡Œ
                title_selectors = ['h1', '.book-title', 'title']
                title = book_id
                
                for selector in title_selectors:
                    title_elem = soup.select_one(selector)
                    if title_elem:
                        title_text = title_elem.get_text().strip()
                        title_text = re.sub(r'[-â€“â€”]\s*è­˜å…¸å¤ç±.*', '', title_text)
                        if len(title_text) > 2 and title_text != book_id:
                            title = title_text
                            break
                
                # æå–ä½œè€…
                author = "æœªçŸ¥ä½œè€…"
                author_selectors = ['.author', '[class*="author"]']
                for selector in author_selectors:
                    author_elem = soup.select_one(selector)
                    if author_elem:
                        author_text = author_elem.get_text().strip()
                        if author_text and len(author_text) > 1:
                            author = author_text
                            break
                
                return {
                    'id': book_id,
                    'title': title,
                    'author': author,
                    'url': book_url
                }
    
    def setup_project_structure(self, book_info):
        """è¨­å®šå°ˆæ¡ˆçµæ§‹"""
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', book_info['title'])
        clean_title = re.sub(r'\s+', '_', clean_title)
        folder_name = f"{clean_title}_{book_info['id']}"
        
        self.project_root = Path(f"docs/source_texts/{folder_name}")
        self.source_dir = self.project_root / "åŸæ–‡"
        self.translation_dir = Path(f"docs/translations/{folder_name}")
        
        self.source_dir.mkdir(parents=True, exist_ok=True)
        self.translation_dir.mkdir(parents=True, exist_ok=True)
        
        self.current_book = book_info
    
    async def get_chapter_list(self, book_url: str):
        """ç²å–ç« ç¯€åˆ—è¡¨"""
        async with aiohttp.ClientSession(headers=self.headers) as session:
            async with session.get(book_url) as response:
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                chapters = []
                
                # å°‹æ‰¾ç›®éŒ„çµæ§‹
                catalog_selectors = [
                    '.reader-catalog-tree',
                    '.semi-tree-option-list',
                    '.catalog-tree'
                ]
                
                for selector in catalog_selectors:
                    catalog = soup.select_one(selector)
                    if catalog:
                        items = catalog.find_all(['div', 'li'])
                        chapter_number = 1
                        
                        for item in items:
                            link = item.find('a')
                            if link:
                                href = link.get('href', '')
                                title = link.get_text().strip()
                                
                                if href and title and len(title) > 2:
                                    chapter_id = re.search(r'/chapter/([^/?]+)', href)
                                    if chapter_id:
                                        full_url = self.base_url + href if href.startswith('/') else href
                                        
                                        chapters.append({
                                            'number': chapter_number,
                                            'title': title,
                                            'url': full_url,
                                            'chapter_id': chapter_id.group(1)
                                        })
                                        chapter_number += 1
                        
                        if chapters:
                            break
                
                return chapters
    
    async def crawl_chapter(self, chapter_info):
        """çˆ¬å–ç« ç¯€å…§å®¹"""
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(chapter_info['url']) as response:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # æå–å…§å®¹
                    content_selectors = [
                        'main .chapter-reader',
                        '.chapter-content',
                        '.content',
                        'article'
                    ]
                    
                    content_parts = []
                    
                    for selector in content_selectors:
                        content_elem = soup.select_one(selector)
                        if content_elem:
                            for element in content_elem.find_all(['h1', 'h2', 'h3', 'p']):
                                text = element.get_text().strip()
                                if text and len(text) > 3:
                                    content_parts.append(text)
                            break
                    
                    if content_parts:
                        return {
                            'title': chapter_info['title'],
                            'content': '\n\n'.join(content_parts),
                            'chapter_id': chapter_info['chapter_id']
                        }
                    
                    return None
                    
        except Exception as e:
            safe_print(f"  âŒ çˆ¬å–éŒ¯èª¤: {e}")
            return None
    
    def save_source_text(self, content_data, chapter_number):
        """ä¿å­˜åŸæ–‡"""
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', content_data['title'])
        filename = f"{chapter_number:02d}_{clean_title}.txt"
        file_path = self.source_dir / filename
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# {content_data['title']}\n\n")
                f.write(content_data['content'])
            
            safe_print(f"  ğŸ“„ å·²ä¿å­˜åŸæ–‡: {filename}")
            
        except Exception as e:
            safe_print(f"  âŒ ä¿å­˜åŸæ–‡å¤±æ•—: {e}")
    
    def generate_translation_template(self, content_data, chapter_number):
        """ç”Ÿæˆç¿»è­¯æ¨¡æ¿"""
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', content_data['title'])
        filename = f"{chapter_number:02d}_{clean_title}.md"
        file_path = self.translation_dir / filename
        
        template_content = f"""# {content_data['title']}

## åŸæ–‡

# {content_data['title']}

{content_data['content']}

## ç¿»è­¯

[æ­¤è™•å¡«å…¥ç¾ä»£ä¸­æ–‡ç¿»è­¯]

---

**ç¿»è­¯èªªæ˜ï¼š**
- åŸæ–‡å­—æ•¸ï¼š{len(content_data['content'])} å­—
- å»ºè­°ä½¿ç”¨AIç¿»è­¯å·¥å…·æˆ–äººå·¥ç¿»è­¯
- ä¿æŒåŸæ–‡æ„æ€ï¼Œä½¿ç”¨ç¾ä»£ä¸­æ–‡è¡¨é”
- ä¿ç•™é‡è¦çš„å¤ä»£è¡“èªï¼Œå¿…è¦æ™‚æ·»åŠ è¨»è§£

**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……é‡è¦è©å½™è§£é‡‹]

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- [å¾…è£œå……ç›¸é—œæ–‡åŒ–èƒŒæ™¯]

**ç¿»è­¯è¦é»ï¼š**
- [å¾…è£œå……ç¿»è­¯æ³¨æ„äº‹é …]

---
*ç¿»è­¯æ¨¡æ¿ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*åŸæ–‡æª”æ¡ˆï¼š{clean_title}.txt*
"""
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(template_content)
            
            safe_print(f"  ğŸ“ å·²ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {filename}")
            
        except Exception as e:
            safe_print(f"  âŒ ç”Ÿæˆç¿»è­¯æ¨¡æ¿å¤±æ•—: {e}")

async def main():
    """ä¸»å‡½æ•¸"""
    translator = SimpleTranslator()
    
    safe_print("ğŸŒŸ ç°¡å–®ç¿»è­¯å™¨")
    safe_print("=" * 30)
    
    while True:
        url = input("\nè«‹è¼¸å…¥æ›¸ç±URL (æˆ–è¼¸å…¥ 'quit' é€€å‡º): ").strip()
        
        if url.lower() in ['quit', 'exit', 'q']:
            safe_print("ğŸ‘‹ å†è¦‹ï¼")
            break
        
        if not url:
            safe_print("âŒ URLä¸èƒ½ç‚ºç©º")
            continue
        
        if not url.startswith('http'):
            safe_print("âŒ è«‹è¼¸å…¥å®Œæ•´çš„URL")
            continue
        
        success = await translator.translate_book(url)
        
        if success:
            safe_print("\nğŸ‰ ç¿»è­¯ä»»å‹™å®Œæˆï¼")
        else:
            safe_print("\nâŒ ç¿»è­¯ä»»å‹™å¤±æ•—")
        
        continue_choice = input("\næ˜¯å¦ç¹¼çºŒæ·»åŠ å…¶ä»–æ›¸ç±ï¼Ÿ(Y/n): ").strip().lower()
        if continue_choice in ['n', 'no', 'å¦']:
            safe_print("ğŸ‘‹ å†è¦‹ï¼")
            break

if __name__ == "__main__":
    asyncio.run(main())