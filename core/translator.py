#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é“æ•™ç¶“å…¸ç¿»è­¯ç³»çµ± - æ ¸å¿ƒç¿»è­¯å™¨

æ•´åˆåŸæœ‰çš„ auto_translator.py åŠŸèƒ½ï¼Œæä¾›çµ±ä¸€çš„ç¿»è­¯ä»‹é¢
"""

import requests
import re
import json
import time
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime
from typing import Dict, List, Optional, Tuple

from .tracker import ClassicTracker
from .file_monitor import FileMonitor

# ç¢ºä¿safe_printåœ¨æ‰€æœ‰åœ°æ–¹éƒ½å¯ç”¨
try:
    from .unicode_handler import safe_print
except ImportError:
    def safe_print(*args, **kwargs):
        try:
            print(*args, **kwargs)
        except UnicodeEncodeError:
            safe_args = []
            for arg in args:
                if isinstance(arg, str):
                    safe_args.append(arg.encode('utf-8', errors='replace').decode('utf-8'))
                else:
                    safe_args.append(str(arg))
            print(*safe_args, **kwargs)
        except Exception as e:
            print(f"æ‰“å°éŒ¯èª¤: {e}")


class TranslationEngine:
    """ç¿»è­¯å¼•æ“æ ¸å¿ƒé¡"""
    
    def __init__(self, config: Dict = None):
        """åˆå§‹åŒ–ç¿»è­¯å¼•æ“"""
        self.config = config or self._load_default_config()
        self.session = self._create_session()
        self.tracker = ClassicTracker()
        self.file_monitor = FileMonitor()
        
        # åˆå§‹åŒ–ç‹€æ…‹
        self.current_book = None
        self.project_root = None
        self.source_dir = None
        self.translation_dir = None
        
    def _load_default_config(self) -> Dict:
        """è¼‰å…¥é è¨­é…ç½®"""
        return {
            "base_url": "https://www.shidianguji.com",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "request_delay": 2,
            "max_retries": 3,
            "timeout": 10
        }
        
    def _create_session(self) -> requests.Session:
        """å‰µå»ºHTTPæœƒè©±"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': self.config["user_agent"]
        })
        return session
        
    def extract_book_id(self, url: str) -> Optional[str]:
        """å¾URLæå–æ›¸ç±ID"""
        match = re.search(r'/book/([^/?]+)', url)
        return match.group(1) if match else None
        
    def get_book_info(self, book_url: str) -> Dict:
        """ç²å–æ›¸ç±åŸºæœ¬è³‡è¨Š"""
        try:
            response = self.session.get(book_url, timeout=self.config["timeout"])
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            book_id = self.extract_book_id(book_url)
            
            # æå–æ›¸ç±æ¨™é¡Œ
            book_title = self._extract_title(soup, book_id)
            
            # æå–ä½œè€…è³‡è¨Š
            author = self._extract_author(soup)
            
            return {
                'id': book_id,
                'title': book_title,
                'author': author,
                'url': book_url
            }
            
        except Exception as e:
            safe_print(f"âš ï¸  ç²å–æ›¸ç±è³‡è¨Šå¤±æ•—: {e}")
            return {
                'id': self.extract_book_id(book_url),
                'title': self.extract_book_id(book_url),
                'author': "æœªçŸ¥ä½œè€…",
                'url': book_url
            }     
       
    def _extract_title(self, soup: BeautifulSoup, book_id: str) -> str:
        """æå–æ›¸ç±æ¨™é¡Œ"""
        title_selectors = [
            'h1.Goq6DYSE',
            'h1',
            '.book-title h1',
            '.title',
            'title'
        ]
        
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title_text = title_elem.get_text().strip()
                # æ¸…ç†æ¨™é¡Œ
                title_text = re.sub(r'[-â€“â€”]\s*è­˜å…¸å¤ç±.*', '', title_text)
                title_text = re.sub(r'\s*\|\s*.*', '', title_text)
                if len(title_text) > 2 and title_text != book_id:
                    return title_text
                    
        return book_id
        
    def _extract_author(self, soup: BeautifulSoup) -> str:
        """æå–ä½œè€…è³‡è¨Š"""
        author_selectors = [
            '.book-title-author',
            '.author',
            '[class*="author"]'
        ]
        
        for selector in author_selectors:
            author_elem = soup.select_one(selector)
            if author_elem:
                author_text = author_elem.get_text().strip()
                if author_text and len(author_text) > 1:
                    return author_text
                    
        # å˜—è©¦å¾æ–‡æœ¬ä¸­æœå°‹
        text_content = soup.get_text()
        author_patterns = [
            r'[\[ã€\(ï¼ˆ]([^ã€‘\]ï¼‰\)]*(?:æ’°|è‘—|ç·¨|è¼¯))[\]ã€‘\)ï¼‰]',
            r'([^ï¼Œã€‚ï¼›ï¼š\s]{2,6})\s*(?:æ’°|è‘—|ç·¨|è¼¯)',
        ]
        for pattern in author_patterns:
            match = re.search(pattern, text_content)
            if match:
                return match.group(1)
                
        return "æœªçŸ¥ä½œè€…"
        
    def setup_project_structure(self, book_info: Dict) -> None:
        """è¨­å®šå°ˆæ¡ˆçµæ§‹"""
        # æ¸…ç†æ›¸åï¼Œç§»é™¤ä¸é©åˆä½œç‚ºè³‡æ–™å¤¾åç¨±çš„å­—ç¬¦
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', book_info['title'])
        clean_title = re.sub(r'\s+', '_', clean_title)
        folder_name = f"{clean_title}_{book_info['id']}"
        
        self.project_root = Path(f"docs/source_texts/{folder_name}")
        self.source_dir = self.project_root / "åŸæ–‡"
        self.translation_dir = Path(f"docs/translations/{folder_name}")
        
        # å»ºç«‹ç›®éŒ„
        self.source_dir.mkdir(parents=True, exist_ok=True)
        self.translation_dir.mkdir(parents=True, exist_ok=True)
        
        self.current_book = book_info
        
    def get_chapter_list(self, book_url: str) -> List[Dict]:
        """ç²å–ç« ç¯€åˆ—è¡¨ï¼ˆæ”¯æŒå±¤ç´šçµæ§‹å’Œå‹•æ…‹ç™¼ç¾ï¼‰"""
        safe_print(f"ğŸ” æ­£åœ¨ç²å–ç« ç¯€åˆ—è¡¨...")
        
        try:
            response = self.session.get(book_url, timeout=self.config["timeout"])
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # 1. å¾HTMLçµæ§‹ä¸­è§£æå¯è¦‹çš„ç« ç¯€
            visible_chapters = self._parse_hierarchical_chapters(soup)
            
            if visible_chapters:
                safe_print(f"ğŸ“‹ å¾HTMLç²å– {len(visible_chapters)} å€‹å¯è¦‹ç« ç¯€")
                
                # 2. å‹•æ…‹ç™¼ç¾éš±è—çš„ç« ç¯€
                all_chapters = self._discover_hidden_chapters(visible_chapters)
                
                safe_print(f"âœ… ç¸½å…±ç™¼ç¾ {len(all_chapters)} å€‹ç« ç¯€ï¼ˆåŒ…å«éš±è—ç« ç¯€ï¼‰")
                return all_chapters
            else:
                safe_print("âš ï¸  æœªæ‰¾åˆ°ç« ç¯€ï¼Œå˜—è©¦å‚³çµ±æ–¹å¼...")
                return self._get_chapters_traditional(soup)
                
        except Exception as e:
            safe_print(f"âŒ ç²å–ç« ç¯€åˆ—è¡¨å¤±æ•—: {e}")
            return []
    
    def _parse_hierarchical_chapters(self, soup: BeautifulSoup) -> List[Dict]:
        """è§£æå±¤ç´šç« ç¯€çµæ§‹"""
        chapters = []
        
        # å°‹æ‰¾ç›®éŒ„æ¨¹çµæ§‹
        catalog_selectors = [
            '.reader-catalog-tree',
            '.semi-tree-option-list',
            '.catalog-tree',
            '.chapter-list'
        ]
        
        for selector in catalog_selectors:
            catalog = soup.select_one(selector)
            if catalog:
                safe_print(f"ğŸŒ³ æ‰¾åˆ°ç›®éŒ„çµæ§‹: {selector}")
                return self._extract_chapters_from_catalog(catalog)
        
        return []
    
    def _extract_chapters_from_catalog(self, catalog_element) -> List[Dict]:
        """å¾ç›®éŒ„å…ƒç´ ä¸­æå–ç« ç¯€"""
        chapters = []
        chapter_number = 1
        
        # å°‹æ‰¾æ‰€æœ‰ç« ç¯€é …ç›®
        items = catalog_element.find_all(['div', 'li'], class_=re.compile(r'tree-option|chapter-item'))
        
        safe_print(f"ğŸ” åœ¨ç›®éŒ„ä¸­æ‰¾åˆ° {len(items)} å€‹é …ç›®")
        
        for item in items:
            # æå–å±¤ç´šä¿¡æ¯
            level_classes = item.get('class', [])
            level = 1
            
            for cls in level_classes:
                level_match = re.search(r'level-(\d+)', cls)
                if level_match:
                    level = int(level_match.group(1))
                    break
            
            # æå–éˆæ¥å’Œæ¨™é¡Œ
            link = item.find('a')
            if link:
                href = link.get('href', '')
                title = link.get_text().strip()
                
                if href and title and len(title) > 2:
                    chapter_id = self._extract_chapter_id(href)
                    if chapter_id:
                        full_url = self.config["base_url"] + href if href.startswith('/') else href
                        
                        # æ›´æ™ºèƒ½çš„ç« ç¯€é¡å‹åˆ¤æ–·
                        is_volume = self._is_volume_title(title, level)
                        is_chapter = self._is_chapter_title(title, level)
                        
                        chapters.append({
                            'number': chapter_number,
                            'title': title,
                            'url': full_url,
                            'chapter_id': chapter_id,
                            'level': level,
                            'is_volume': is_volume,
                            'is_chapter': is_chapter
                        })
                        
                        level_prefix = "  " * (level - 1)
                        safe_print(f"{level_prefix}ğŸ“„ {chapter_number}. {title} (Level {level}, ID: {chapter_id})")
                        
                        chapter_number += 1
        
        return chapters
    
    def _is_volume_title(self, title: str, level: int) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå·æ¨™é¡Œ"""
        volume_indicators = ['å·ä¹‹', 'å·ç¬¬', 'ç¬¬.*å·', 'å·.*ç¬¬']
        return any(re.search(indicator, title) for indicator in volume_indicators)
    
    def _is_chapter_title(self, title: str, level: int) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºç« ç¯€æ¨™é¡Œ"""
        chapter_indicators = ['å“ç¬¬', 'ç« ç¬¬', 'ç¯‡', 'å¤–ç¯‡', 'å…§ç¯‡', 'é›œç¯‡']
        return any(indicator in title for indicator in chapter_indicators)
    
    def _get_chapters_traditional(self, soup: BeautifulSoup) -> List[Dict]:
        """å‚³çµ±æ–¹å¼ç²å–ç« ç¯€ï¼ˆå‚™ç”¨ï¼‰"""
        chapters = []
        chapter_links = soup.find_all('a', href=re.compile(r'/chapter/'))
        
        for idx, link in enumerate(chapter_links, 1):
            href = link.get('href')
            title = link.get_text().strip()
            
            if href and title and len(title) > 2:
                full_url = self.config["base_url"] + href if href.startswith('/') else href
                chapters.append({
                    'number': idx,
                    'title': title,
                    'url': full_url,
                    'chapter_id': self._extract_chapter_id(href),
                    'level': 1,
                    'is_volume': 'å·' in title,
                    'is_chapter': 'å“' in title or 'ç« ' in title
                })
                
        return chapters
    
    def _discover_hidden_chapters(self, visible_chapters: List[Dict]) -> List[Dict]:
        """å‹•æ…‹ç™¼ç¾éš±è—çš„ç« ç¯€"""
        safe_print("ğŸ” é–‹å§‹å‹•æ…‹ç™¼ç¾éš±è—ç« ç¯€...")
        
        all_chapters = visible_chapters.copy()
        
        # æª¢æŸ¥ç« ç¯€IDé¡å‹
        chapter_id_type = self._detect_chapter_id_type(visible_chapters)
        
        if chapter_id_type == "numeric":
            # æ•¸å­—å‹IDï¼Œä½¿ç”¨åŸæœ‰çš„æ•¸å­—éå¢æ–¹å¼
            return self._discover_numeric_chapters(all_chapters, visible_chapters)
        elif chapter_id_type == "random":
            # éš¨æ©Ÿå­—ç¬¦ä¸²IDï¼Œä½¿ç”¨ä¸åŒçš„ç­–ç•¥
            safe_print("ğŸ² æª¢æ¸¬åˆ°éš¨æ©Ÿå­—ç¬¦ä¸²ç« ç¯€IDï¼Œä½¿ç”¨æ›¿ä»£ç™¼ç¾ç­–ç•¥")
            return self._discover_random_chapters(all_chapters, visible_chapters)
        else:
            safe_print("âš ï¸  ç„¡æ³•è­˜åˆ¥ç« ç¯€IDæ¨¡å¼ï¼Œè·³éå‹•æ…‹ç™¼ç¾")
            return all_chapters
    
    def _detect_chapter_id_type(self, visible_chapters: List[Dict]) -> str:
        """æª¢æ¸¬ç« ç¯€IDçš„é¡å‹"""
        numeric_count = 0
        random_count = 0
        
        for chapter in visible_chapters:
            if chapter.get('chapter_id'):
                chapter_id = chapter['chapter_id']
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸å­—å‹ (å¦‚ DZ0336_1, DZ0336_33)
                if re.search(r'_(\d+)$', chapter_id):
                    numeric_count += 1
                # æª¢æŸ¥æ˜¯å¦ç‚ºéš¨æ©Ÿå­—ç¬¦ä¸²å‹ (å¦‚ 1k1r7oqmxh8uz)
                elif re.search(r'[a-z0-9]{8,}', chapter_id):
                    random_count += 1
        
        if numeric_count > random_count:
            return "numeric"
        elif random_count > 0:
            return "random"
        else:
            return "unknown"
    
    def _discover_numeric_chapters(self, all_chapters: List[Dict], visible_chapters: List[Dict]) -> List[Dict]:
        """ç™¼ç¾æ•¸å­—å‹ç« ç¯€IDçš„éš±è—ç« ç¯€"""
        # æå–å·²çŸ¥çš„ç« ç¯€ID
        known_ids = set()
        for chapter in visible_chapters:
            if chapter.get('chapter_id'):
                # æå–æ•¸å­—ID
                match = re.search(r'_(\d+)$', chapter['chapter_id'])
                if match:
                    known_ids.add(int(match.group(1)))
        
        if not known_ids:
            return all_chapters
        
        # ç¢ºå®šæœç´¢ç¯„åœ
        min_id = min(known_ids)
        max_id = max(known_ids)
        
        # æ“´å±•æœç´¢ç¯„åœ
        search_start = max(1, min_id - 5)
        search_end = min(50, max_id + 10)  # é™åˆ¶æœ€å¤§æœç´¢ç¯„åœ
        
        safe_print(f"ğŸ¯ æ•¸å­—æœç´¢ç¯„åœ: {search_start} åˆ° {search_end}")
        
        # ç³»çµ±æ€§åœ°æ¢æ¸¬ç¼ºå¤±çš„ç« ç¯€
        missing_ids = []
        for chapter_id in range(search_start, search_end + 1):
            if chapter_id not in known_ids:
                missing_ids.append(chapter_id)
        
        if missing_ids:
            safe_print(f"ğŸ” æ¢æ¸¬ {len(missing_ids)} å€‹å¯èƒ½çš„ç¼ºå¤±ç« ç¯€...")
            discovered_chapters = self._probe_chapter_ids(missing_ids)
            
            if discovered_chapters:
                safe_print(f"âœ… ç™¼ç¾ {len(discovered_chapters)} å€‹éš±è—ç« ç¯€")
                all_chapters.extend(discovered_chapters)
                
                # é‡æ–°æ’åºç« ç¯€
                all_chapters.sort(key=lambda x: self._extract_chapter_number(x.get('chapter_id', '')))
                
                # é‡æ–°ç·¨è™Ÿ
                for i, chapter in enumerate(all_chapters, 1):
                    chapter['number'] = i
        
        return all_chapters
    
    def _discover_random_chapters(self, all_chapters: List[Dict], visible_chapters: List[Dict]) -> List[Dict]:
        """ç™¼ç¾éš¨æ©Ÿå­—ç¬¦ä¸²ç« ç¯€IDçš„éš±è—ç« ç¯€"""
        safe_print("ğŸ” å°æ–¼éš¨æ©ŸIDï¼Œä½¿ç”¨å¤šç¨®ç­–ç•¥ç™¼ç¾éš±è—ç« ç¯€...")
        
        try:
            # ç­–ç•¥1: å¾æ›¸ç±é é¢çš„JavaScriptæ•¸æ“šä¸­æå–
            book_url = f"{self.config['base_url']}/book/{self.current_book['id']}"
            response = self.session.get(book_url, timeout=self.config["timeout"])
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # å˜—è©¦å¾JavaScriptæ•¸æ“šä¸­æå–å®Œæ•´ç« ç¯€åˆ—è¡¨
                additional_chapters = self._extract_chapters_from_scripts(soup)
                
                if additional_chapters:
                    safe_print(f"ğŸ“‹ å¾JavaScriptæ•¸æ“šä¸­ç™¼ç¾ {len(additional_chapters)} å€‹é¡å¤–ç« ç¯€")
                    
                    # éæ¿¾æ‰å·²çŸ¥ç« ç¯€
                    known_chapter_ids = {ch.get('chapter_id') for ch in visible_chapters}
                    new_chapters = [ch for ch in additional_chapters 
                                  if ch.get('chapter_id') not in known_chapter_ids]
                    
                    if new_chapters:
                        safe_print(f"âœ… ç™¼ç¾ {len(new_chapters)} å€‹æ–°çš„éš±è—ç« ç¯€")
                        all_chapters.extend(new_chapters)
                        
                        # é‡æ–°ç·¨è™Ÿ
                        for i, chapter in enumerate(all_chapters, 1):
                            chapter['number'] = i
                        
                        return all_chapters
                
                # ç­–ç•¥2: æ·±åº¦æœç´¢HTMLä¸­çš„æ‰€æœ‰ç« ç¯€éˆæ¥
                safe_print("ğŸ” ç­–ç•¥2: æ·±åº¦æœç´¢HTMLä¸­çš„æ‰€æœ‰ç« ç¯€éˆæ¥...")
                deep_search_chapters = self._deep_search_chapter_links(soup)
                
                if deep_search_chapters:
                    known_chapter_ids = {ch.get('chapter_id') for ch in all_chapters}
                    new_chapters = [ch for ch in deep_search_chapters 
                                  if ch.get('chapter_id') not in known_chapter_ids]
                    
                    if new_chapters:
                        safe_print(f"âœ… æ·±åº¦æœç´¢ç™¼ç¾ {len(new_chapters)} å€‹æ–°ç« ç¯€")
                        all_chapters.extend(new_chapters)
                        
                        # é‡æ–°ç·¨è™Ÿ
                        for i, chapter in enumerate(all_chapters, 1):
                            chapter['number'] = i
                        
                        return all_chapters
                
                # ç­–ç•¥3: å˜—è©¦APIç«¯é»æ¢æ¸¬
                safe_print("ğŸ” ç­–ç•¥3: å˜—è©¦APIç«¯é»æ¢æ¸¬...")
                api_chapters = self._probe_api_endpoints()
                
                if api_chapters:
                    known_chapter_ids = {ch.get('chapter_id') for ch in all_chapters}
                    new_chapters = [ch for ch in api_chapters 
                                  if ch.get('chapter_id') not in known_chapter_ids]
                    
                    if new_chapters:
                        safe_print(f"âœ… APIæ¢æ¸¬ç™¼ç¾ {len(new_chapters)} å€‹æ–°ç« ç¯€")
                        all_chapters.extend(new_chapters)
                        
                        # é‡æ–°ç·¨è™Ÿ
                        for i, chapter in enumerate(all_chapters, 1):
                            chapter['number'] = i
                
                safe_print("âš ï¸  æ‰€æœ‰ç­–ç•¥éƒ½æœªèƒ½ç™¼ç¾é¡å¤–ç« ç¯€")
            
        except Exception as e:
            safe_print(f"âŒ å˜—è©¦ç²å–é¡å¤–ç« ç¯€æ™‚å‡ºéŒ¯: {e}")
        
        return all_chapters
    
    def _deep_search_chapter_links(self, soup: BeautifulSoup) -> List[Dict]:
        """æ·±åº¦æœç´¢HTMLä¸­çš„æ‰€æœ‰ç« ç¯€éˆæ¥"""
        chapters = []
        
        # æœç´¢æ‰€æœ‰å¯èƒ½çš„ç« ç¯€éˆæ¥
        all_links = soup.find_all('a', href=True)
        
        chapter_pattern = re.compile(r'/book/' + re.escape(self.current_book['id']) + r'/chapter/([^/?]+)')
        
        found_ids = set()
        
        for link in all_links:
            href = link.get('href', '')
            match = chapter_pattern.search(href)
            
            if match:
                chapter_id = match.group(1)
                if chapter_id not in found_ids:
                    found_ids.add(chapter_id)
                    
                    title = link.get_text().strip()
                    if not title:
                        title = f"ç« ç¯€_{chapter_id}"
                    
                    full_url = self.config["base_url"] + href if href.startswith('/') else href
                    
                    # å˜—è©¦æ¨æ–·å±¤ç´š
                    level = 1
                    if any(indicator in title for indicator in ['å¤–ç¯‡', 'å…§ç¯‡', 'é›œç¯‡', 'å“ç¬¬']):
                        level = 2
                    
                    chapters.append({
                        'number': len(chapters) + 1,
                        'title': title,
                        'url': full_url,
                        'chapter_id': chapter_id,
                        'level': level,
                        'is_volume': self._is_volume_title(title, level),
                        'is_chapter': self._is_chapter_title(title, level),
                        'discovered': True,
                        'discovery_method': 'deep_search'
                    })
        
        return chapters
    
    def _probe_api_endpoints(self) -> List[Dict]:
        """æ¢æ¸¬å¯èƒ½çš„APIç«¯é»"""
        chapters = []
        
        # å˜—è©¦ä¸€äº›å¸¸è¦‹çš„APIç«¯é»
        api_endpoints = [
            f"/api/book/{self.current_book['id']}/chapters",
            f"/api/book/{self.current_book['id']}/contents",
            f"/api/book/{self.current_book['id']}/toc",
            f"/api/books/{self.current_book['id']}/chapters",
        ]
        
        for endpoint in api_endpoints:
            try:
                api_url = self.config["base_url"] + endpoint
                response = self.session.get(api_url, timeout=5)
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if isinstance(data, dict) and 'chapters' in data:
                            api_chapters = self._process_api_chapters(data['chapters'])
                            if api_chapters:
                                safe_print(f"âœ… APIç«¯é» {endpoint} è¿”å› {len(api_chapters)} å€‹ç« ç¯€")
                                chapters.extend(api_chapters)
                                break
                        elif isinstance(data, list):
                            api_chapters = self._process_api_chapters(data)
                            if api_chapters:
                                safe_print(f"âœ… APIç«¯é» {endpoint} è¿”å› {len(api_chapters)} å€‹ç« ç¯€")
                                chapters.extend(api_chapters)
                                break
                    except json.JSONDecodeError:
                        continue
                        
            except Exception:
                continue
        
        return chapters
    
    def _process_api_chapters(self, data) -> List[Dict]:
        """è™•ç†APIè¿”å›çš„ç« ç¯€æ•¸æ“š"""
        chapters = []
        
        if isinstance(data, list):
            for item in data:
                if isinstance(item, dict):
                    title = item.get('title') or item.get('name') or item.get('chapterName', '')
                    chapter_id = item.get('id') or item.get('chapterId') or item.get('key', '')
                    
                    if title and chapter_id:
                        level = 1
                        if any(indicator in title for indicator in ['å¤–ç¯‡', 'å…§ç¯‡', 'é›œç¯‡', 'å“ç¬¬']):
                            level = 2
                        
                        chapters.append({
                            'number': len(chapters) + 1,
                            'title': title,
                            'url': f"{self.config['base_url']}/book/{self.current_book['id']}/chapter/{chapter_id}",
                            'chapter_id': chapter_id,
                            'level': level,
                            'is_volume': self._is_volume_title(title, level),
                            'is_chapter': self._is_chapter_title(title, level),
                            'discovered': True,
                            'discovery_method': 'api'
                        })
        
        return chapters
    
    def _extract_chapters_from_scripts(self, soup: BeautifulSoup) -> List[Dict]:
        """å¾JavaScriptæ•¸æ“šä¸­æå–ç« ç¯€ä¿¡æ¯"""
        chapters = []
        
        # å°‹æ‰¾åŒ…å«ç« ç¯€æ•¸æ“šçš„JavaScript
        scripts = soup.find_all('script')
        
        for script in scripts:
            if script.string:
                script_content = script.string
                
                # å°‹æ‰¾ç« ç¯€æ•¸æ“šçš„æ¨¡å¼
                patterns = [
                    r'chapters["\']?\s*:\s*(\[.*?\])',
                    r'chapterList["\']?\s*:\s*(\[.*?\])',
                    r'contents["\']?\s*:\s*(\[.*?\])',
                    r'"chapters":\s*(\[.*?\])',
                    r'"chapterList":\s*(\[.*?\])',
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, script_content, re.DOTALL)
                    for match in matches:
                        try:
                            chapter_data = json.loads(match)
                            if isinstance(chapter_data, list):
                                for item in chapter_data:
                                    if isinstance(item, dict):
                                        title = item.get('title') or item.get('name') or item.get('chapterName', '')
                                        chapter_id = item.get('id') or item.get('chapterId') or item.get('key', '')
                                        
                                        if title and chapter_id:
                                            chapters.append({
                                                'number': len(chapters) + 1,
                                                'title': title,
                                                'url': f"{self.config['base_url']}/book/{self.current_book['id']}/chapter/{chapter_id}",
                                                'chapter_id': chapter_id,
                                                'level': 2 if 'å“' in title else 1,
                                                'is_volume': 'å·' in title,
                                                'is_chapter': 'å“' in title or 'ç« ' in title,
                                                'discovered': True
                                            })
                        except json.JSONDecodeError:
                            continue
                
                if chapters:
                    break
        
        return chapters
    
    def _probe_chapter_ids(self, chapter_ids: List[int]) -> List[Dict]:
        """æ¢æ¸¬æŒ‡å®šçš„æ•¸å­—ç« ç¯€ID"""
        discovered = []
        
        for chapter_id in chapter_ids:
            chapter_key = f"{self.current_book['id']}_{chapter_id}"
            test_url = f"{self.config['base_url']}/book/{self.current_book['id']}/chapter/{chapter_key}"
            
            try:
                response = self.session.get(test_url, timeout=5)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # å˜—è©¦æå–æ¨™é¡Œ
                    title_elem = soup.find('h1', class_='Goq6DYSE')
                    if title_elem:
                        title = title_elem.get_text().strip()
                        
                        # å˜—è©¦å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å
                        content = self._extract_content_from_html(soup, title)
                        if content and content.get('content'):
                            actual_title = self._extract_actual_title_from_content(
                                content['content'], title
                            )
                            
                            discovered.append({
                                'number': len(discovered) + 1,  # è‡¨æ™‚ç·¨è™Ÿ
                                'title': actual_title,
                                'original_title': title,
                                'url': test_url,
                                'chapter_id': chapter_key,
                                'level': 2 if 'å“' in actual_title else 1,
                                'is_volume': 'å·' in actual_title,
                                'is_chapter': 'å“' in actual_title or 'ç« ' in actual_title,
                                'discovered': True  # æ¨™è¨˜ç‚ºå‹•æ…‹ç™¼ç¾çš„ç« ç¯€
                            })
                            
                            safe_print(f"  âœ… ç™¼ç¾: {actual_title} ({chapter_key})")
                        else:
                            safe_print(f"  âš ï¸  {chapter_key}: ç„¡æœ‰æ•ˆå…§å®¹")
                    else:
                        safe_print(f"  âŒ {chapter_key}: ç„¡æ¨™é¡Œ")
                else:
                    safe_print(f"  âŒ {chapter_key}: HTTP {response.status_code}")
                    
            except Exception as e:
                safe_print(f"  âŒ {chapter_key}: {e}")
            
            # æ·»åŠ å»¶é²é¿å…è¢«å°é–
            time.sleep(1)
        
        return discovered
    
    def _extract_chapter_number(self, chapter_id: str) -> int:
        """å¾ç« ç¯€IDä¸­æå–æ•¸å­—"""
        match = re.search(r'_(\d+)$', chapter_id)
        return int(match.group(1)) if match else 0
            
    def _extract_chapter_id(self, href: str) -> Optional[str]:
        """å¾hrefæå–ç« ç¯€ID"""
        match = re.search(r'/chapter/([^/?]+)', href)
        return match.group(1) if match else None
        
    def _get_chapters_via_api(self) -> List[Dict]:
        """é€šéAPIæ–¹å¼ç²å–ç« ç¯€åˆ—è¡¨"""
        # é ç•™APIå¯¦ç¾
        return []
        
    def crawl_chapter(self, chapter_info: Dict) -> Optional[Dict]:
        """çˆ¬å–å–®ä¸€ç« ç¯€ï¼ˆæ”¯æŒå±¤ç´šçµæ§‹å’Œå…§å®¹å»é‡ï¼‰"""
        from .unicode_handler import safe_print
        level_prefix = "  " * (chapter_info.get('level', 1) - 1)
        safe_print(f"ğŸ“– {level_prefix}çˆ¬å–: {chapter_info['title']} (Level {chapter_info.get('level', 1)})")
        
        try:
            # å˜—è©¦APIç«¯é»
            api_url = f"{self.config['base_url']}/api/book/{self.current_book['id']}/chapter/{chapter_info['chapter_id']}"
            
            response = self.session.get(api_url, timeout=self.config["timeout"])
            if response.status_code == 200:
                try:
                    data = response.json()
                    content = self._extract_content_from_api_response(data)
                    if content:
                        # å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å
                        actual_title = self._extract_actual_title_from_content(content, chapter_info['title'])
                        
                        content_data = {
                            'title': actual_title,
                            'original_title': chapter_info['title'],
                            'content': content,
                            'level': chapter_info.get('level', 1),
                            'is_volume': chapter_info.get('is_volume', False),
                            'is_chapter': chapter_info.get('is_chapter', False),
                            'chapter_id': chapter_info['chapter_id']
                        }
                        
                        # æª¢æŸ¥å…§å®¹é‡è¤‡ä¸¦è™•ç†
                        processed_content = self._process_content_duplication(content_data, chapter_info)
                        if processed_content:
                            self._save_source_text(processed_content, chapter_info['number'])
                            return processed_content
                        else:
                            safe_print(f"  âš ï¸  è·³éé‡è¤‡å…§å®¹: {actual_title}")
                            return None
                            
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœAPIå¤±æ•—ï¼Œå˜—è©¦ç›´æ¥è¨ªå•é é¢
            response = self.session.get(chapter_info['url'], timeout=self.config["timeout"])
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                content_data = self._extract_content_from_html(soup, chapter_info['title'])
                
                if content_data:
                    content_data['level'] = chapter_info.get('level', 1)
                    content_data['is_volume'] = chapter_info.get('is_volume', False)
                    content_data['is_chapter'] = chapter_info.get('is_chapter', False)
                    content_data['chapter_id'] = chapter_info['chapter_id']
                    
                    # æª¢æŸ¥å…§å®¹é‡è¤‡ä¸¦è™•ç†
                    processed_content = self._process_content_duplication(content_data, chapter_info)
                    if processed_content:
                        self._save_source_text(processed_content, chapter_info['number'])
                        return processed_content
                    else:
                        safe_print(f"  âš ï¸  è·³éé‡è¤‡å…§å®¹: {content_data['title']}")
                        return None
            
            safe_print(f"âŒ ç„¡æ³•æå–ç« ç¯€å…§å®¹: {chapter_info['title']}")
            return None
                
        except Exception as e:
            safe_print(f"âŒ çˆ¬å–ç« ç¯€å¤±æ•—: {e}")
            return None
            
    def _extract_content_from_html(self, soup: BeautifulSoup, title: str) -> Optional[Dict]:
        """å¾HTMLä¸­æå–å…§å®¹"""

        try:
            main_content = soup.find('main', class_='read-layout-main')
            if main_content:
                article = main_content.find('article', class_='chapter-reader')
                if article:
                    content_parts = []
                    
                    for element in article.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p']):
                        text = element.get_text().strip()
                        if text and len(text) > 3:
                            content_parts.append(text)
                    
                    if content_parts:
                        return {
                            'title': title,
                            'content': '\n\n'.join(content_parts)
                        }
                        
        except Exception as e:
            safe_print(f"âš ï¸  HTMLè§£æéŒ¯èª¤: {e}")
            
        return None
    
    def _extract_content_from_api_response(self, data) -> Optional[str]:
        """å¾APIéŸ¿æ‡‰ä¸­æå–å…§å®¹"""
        content_parts = []
        
        def extract_recursive(obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if key in ['content', 'text', 'body', 'html'] and isinstance(value, str):
                        text = value.strip()
                        if len(text) > 20 and re.search(r'[\u4e00-\u9fff]', text):
                            # æ¸…ç†HTMLæ¨™ç±¤
                            clean_text = re.sub(r'<[^>]+>', '', text)
                            if clean_text.strip():
                                content_parts.append(clean_text.strip())
                    else:
                        extract_recursive(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract_recursive(item)
        
        extract_recursive(data)
        
        if content_parts:
            return '\n\n'.join(content_parts)
        return None
    
    def _extract_actual_title_from_content(self, content: str, fallback_title: str) -> str:
        """å¾å…§å®¹ä¸­æå–å¯¦éš›çš„å“å"""
        lines = content.split('\n')
        
        for line in lines[:10]:  # æª¢æŸ¥å‰10è¡Œ
            line = line.strip()
            
            # å°‹æ‰¾å“åæ¨¡å¼
            if 'å“ç¬¬' in line and len(line) < 30:
                return line
            
            # å°‹æ‰¾å…¶ä»–å¯èƒ½çš„ç« ç¯€æ¨™é¡Œ
            if line and len(line) < 50 and not line.startswith('#'):
                # æª¢æŸ¥æ˜¯å¦åŒ…å«å“ã€ç« ã€å·ç­‰é—œéµå­—
                if any(keyword in line for keyword in ['å“', 'ç« ', 'å·']):
                    if 'å¤ªä¸Šæ´ç„' not in line:  # æ’é™¤æ›¸å
                        return line
        
        return fallback_title
    
    def _analyze_chapter_id_patterns(self, chapters: List[Dict]) -> Dict:
        """åˆ†æç« ç¯€IDæ¨¡å¼ä¸¦æ¨è–¦ç­–ç•¥"""
        if not chapters:
            return {'pattern_type': 'unknown', 'strategy': 'default', 'confidence': 0.0}
        
        chapter_ids = [ch.get('chapter_id', '') for ch in chapters if ch.get('chapter_id')]
        
        if not chapter_ids:
            return {'pattern_type': 'unknown', 'strategy': 'default', 'confidence': 0.0}
        
        safe_print(f"ğŸ“Š åˆ†æ {len(chapter_ids)} å€‹ç« ç¯€IDæ¨¡å¼...")
        
        # ç°¡åŒ–çš„æ¨¡å¼åˆ†æ
        patterns = {
            'numeric': 0,
            'random_string': 0,
            'mixed': 0
        }
        
        for chapter_id in chapter_ids:
            if chapter_id.isdigit():
                patterns['numeric'] += 1
            elif len(chapter_id) >= 8 and re.match(r'^[a-zA-Z0-9]+$', chapter_id):
                patterns['random_string'] += 1
            else:
                patterns['mixed'] += 1
        
        # ç¢ºå®šä¸»è¦æ¨¡å¼
        total = len(chapter_ids)
        dominant_pattern = max(patterns.items(), key=lambda x: x[1])
        confidence = dominant_pattern[1] / total
        
        safe_print(f"ğŸ¯ IDæ¨¡å¼åˆ†æ:")
        safe_print(f"   æ•¸å­—åºåˆ—: {patterns['numeric']} å€‹ ({patterns['numeric']/total*100:.1f}%)")
        safe_print(f"   éš¨æ©Ÿå­—ç¬¦ä¸²: {patterns['random_string']} å€‹ ({patterns['random_string']/total*100:.1f}%)")
        safe_print(f"   æ··åˆæ¨¡å¼: {patterns['mixed']} å€‹ ({patterns['mixed']/total*100:.1f}%)")
        safe_print(f"   ä¸»è¦æ¨¡å¼: {dominant_pattern[0]} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
        
        # æ¨è–¦ç­–ç•¥
        if dominant_pattern[0] == 'numeric' and confidence > 0.8:
            strategy = 'numeric_sequence_strategy'
            safe_print(f"ğŸ’¡ æ¨è–¦ç­–ç•¥: æ•¸å­—åºåˆ—æ¢æ¸¬ + çµæ§‹åˆ†æ")
        elif dominant_pattern[0] == 'random_string' and confidence > 0.7:
            strategy = 'structure_based_strategy'
            safe_print(f"ğŸ’¡ æ¨è–¦ç­–ç•¥: çµæ§‹åŒ–åˆ†æï¼ˆç•¶å‰ä½¿ç”¨çš„æ–¹æ³•ï¼‰")
        else:
            strategy = 'hybrid_strategy'
            safe_print(f"ğŸ’¡ æ¨è–¦ç­–ç•¥: æ··åˆç­–ç•¥")
        
        return {
            'pattern_type': dominant_pattern[0],
            'strategy': strategy,
            'confidence': confidence,
            'patterns': patterns
        }
    
    def _smart_discover_sub_chapters(self, soup: BeautifulSoup, parent_chapter: Dict) -> List[Dict]:
        """æ™ºèƒ½ç™¼ç¾å­ç« ç¯€ - åŸºæ–¼ç›®éŒ„çµæ§‹åˆ†æ"""
        sub_chapters = []
        
        try:
            # å°‹æ‰¾ç›®éŒ„çµæ§‹
            catalog = soup.select_one('.reader-catalog-tree')
            if not catalog:
                # å‚™ç”¨é¸æ“‡å™¨
                for selector in ['.semi-tree-option-list', '.catalog-tree', '.chapter-list']:
                    catalog = soup.select_one(selector)
                    if catalog:
                        break
            
            if catalog:
                items = catalog.find_all(['div', 'li'], class_=re.compile(r'tree-option|chapter-item'))
                parent_level = parent_chapter.get('level', 1)
                parent_chapter_id = parent_chapter['chapter_id']
                
                # å°‹æ‰¾ç•¶å‰ç« ç¯€åœ¨ç›®éŒ„ä¸­çš„ä½ç½®
                current_index = -1
                for i, item in enumerate(items):
                    link = item.find('a')
                    if link:
                        href = link.get('href', '')
                        title = link.get_text().strip()
                        
                        # æª¢æŸ¥æ˜¯å¦æ˜¯ç•¶å‰ç« ç¯€ - ä½¿ç”¨æ›´ç²¾ç¢ºçš„åŒ¹é…
                        if parent_chapter_id in href:
                            current_index = i
                            break
                
                # å¦‚æœæ‰¾åˆ°ç•¶å‰ç« ç¯€ï¼Œæª¢æŸ¥å¾ŒçºŒé …ç›®
                if current_index >= 0:
                    for i in range(current_index + 1, len(items)):
                        item = items[i]
                        link = item.find('a')
                        
                        if not link:
                            continue
                        
                        href = link.get('href', '')
                        title = link.get_text().strip()
                        item_level = self._extract_level_from_item(item)
                        
                        # å¦‚æœå±¤ç´šæ¯”çˆ¶ç« ç¯€é«˜ï¼Œèªªæ˜æ˜¯å­ç« ç¯€
                        if item_level > parent_level:
                            chapter_id = self._extract_chapter_id(href)
                            if chapter_id and title and len(title) > 2:
                                from urllib.parse import urljoin
                                full_url = urljoin(self.config["base_url"], href)
                                
                                sub_chapters.append({
                                    'title': title,
                                    'url': full_url,
                                    'chapter_id': chapter_id,
                                    'level': item_level,
                                    'parent_id': parent_chapter['chapter_id'],
                                    'parent_title': parent_chapter['title'],
                                    'is_volume': self._is_volume_title(title, item_level),
                                    'is_chapter': self._is_chapter_title(title, item_level),
                                    'discovered': True,
                                    'discovery_method': 'smart_structure_analysis'
                                })
                        
                        # å¦‚æœå±¤ç´šç­‰æ–¼æˆ–å°æ–¼çˆ¶ç« ç¯€ï¼Œåœæ­¢æœç´¢
                        elif item_level <= parent_level:
                            break
            
        except Exception as e:
            safe_print(f"      âš ï¸  æ™ºèƒ½ç™¼ç¾éŒ¯èª¤: {e}")
        
        return sub_chapters
    
    def _extract_level_from_item(self, item) -> int:
        """å¾HTMLé …ç›®ä¸­æå–å±¤ç´š"""
        # æ–¹æ³•1: æª¢æŸ¥CSSé¡ä¸­çš„å±¤ç´šä¿¡æ¯
        level_classes = item.get('class', [])
        for cls in level_classes:
            level_match = re.search(r'level-(\d+)', cls)
            if level_match:
                return int(level_match.group(1))
        
        # æ–¹æ³•2: æª¢æŸ¥æ¨£å¼ä¸­çš„padding-left
        style = item.get('style', '')
        if 'padding-left' in style:
            padding_match = re.search(r'padding-left:\s*(\d+)px', style)
            if padding_match:
                padding = int(padding_match.group(1))
                # å‡è¨­æ¯å±¤ç´šç¸®é€²28px
                level = (padding // 28) + 1
                return level
        
        return 1
    
    def _is_volume_title(self, title: str, level: int) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå·æ¨™é¡Œ"""
        volume_patterns = [r'å·ä¹‹\w+', r'ç¬¬\w+å·', r'å·\w+']
        return any(re.search(pattern, title) for pattern in volume_patterns)
    
    def _is_chapter_title(self, title: str, level: int) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºç« ç¯€æ¨™é¡Œ"""
        chapter_patterns = [r'ç¬¬\w+ç« ', r'ç« \w+', r'\w+ç¯‡', r'\w+å“']
        return any(re.search(pattern, title) for pattern in chapter_patterns)
    
    def _process_content_duplication(self, content_data: Dict, chapter_info: Dict) -> Optional[Dict]:
        """è™•ç†å…§å®¹é‡è¤‡å•é¡Œ"""
        is_volume = content_data.get('is_volume', False)
        is_chapter = content_data.get('is_chapter', False)
        
        # å¦‚æœæ˜¯å·ï¼ˆLevel 1ï¼‰ï¼Œæª¢æŸ¥æ˜¯å¦èˆ‡å“çš„å…§å®¹é‡è¤‡
        if is_volume and content_data.get('level', 1) == 1:
            return self._handle_volume_content(content_data, chapter_info)
        
        # å¦‚æœæ˜¯å“ï¼ˆLevel 2ï¼‰ï¼Œç›´æ¥ä¿å­˜
        elif is_chapter and content_data.get('level', 1) == 2:
            return content_data
        
        # å…¶ä»–æƒ…æ³ï¼Œç›´æ¥ä¿å­˜
        else:
            return content_data
    
    def _handle_volume_content(self, content_data: Dict, chapter_info: Dict) -> Optional[Dict]:
        """è™•ç†å·çš„å…§å®¹ï¼Œé¿å…èˆ‡å“é‡è¤‡"""
        content = content_data['content']
        
        # æª¢æŸ¥å…§å®¹æ˜¯å¦åŒ…å«å…·é«”çš„å“
        if self._content_contains_specific_chapter(content):
            # å¦‚æœå·çš„å…§å®¹åŒ…å«å…·é«”å“çš„å…§å®¹ï¼Œå‰‡æå–å·çš„æ¦‚è¿°éƒ¨åˆ†
            volume_summary = self._extract_volume_summary(content, content_data['title'])
            
            if volume_summary and len(volume_summary) > 100:
                content_data['content'] = volume_summary
                content_data['content_type'] = 'volume_summary'
                safe_print(f"  ğŸ“ æå–å·æ¦‚è¿°: {len(volume_summary)} å­—ç¬¦")
                return content_data
            else:
                # å¦‚æœç„¡æ³•æå–æœ‰æ„ç¾©çš„æ¦‚è¿°ï¼Œè·³éé€™å€‹å·
                safe_print(f"  âš ï¸  å·å…§å®¹èˆ‡å“é‡è¤‡ï¼Œè·³é")
                return None
        else:
            # å¦‚æœå·çš„å…§å®¹ä¸åŒ…å«å…·é«”å“ï¼Œç›´æ¥ä¿å­˜
            return content_data
    
    def _content_contains_specific_chapter(self, content: str) -> bool:
        """æª¢æŸ¥å…§å®¹æ˜¯å¦åŒ…å«å…·é«”çš„å“"""
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å“çš„æ¨™é¡Œæ¨¡å¼
        chapter_patterns = [
            r'å“ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+',
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+å“',
            r'å“ç¬¬\d+',
            r'ç¬¬\d+å“'
        ]
        
        for pattern in chapter_patterns:
            if re.search(pattern, content):
                return True
        
        return False
    
    def _extract_volume_summary(self, content: str, volume_title: str) -> str:
        """å¾å·çš„å…§å®¹ä¸­æå–æ¦‚è¿°éƒ¨åˆ†"""
        lines = content.split('\n')
        summary_lines = []
        
        # æ·»åŠ å·æ¨™é¡Œ
        summary_lines.append(volume_title)
        summary_lines.append('')
        
        # æŸ¥æ‰¾å·çš„ä»‹ç´¹æˆ–æ¦‚è¿°éƒ¨åˆ†
        in_summary = False
        chapter_started = False
        
        for line in lines:
            line = line.strip()
            
            # å¦‚æœé‡åˆ°å“çš„æ¨™é¡Œï¼Œåœæ­¢æå–
            if re.search(r'å“ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', line) or re.search(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+å“', line):
                chapter_started = True
                break
            
            # å¦‚æœæ˜¯å·æ¨™é¡Œè¡Œï¼Œé–‹å§‹æå–
            if volume_title in line or 'å·ä¹‹' in line:
                in_summary = True
                continue
            
            # æå–æ¦‚è¿°å…§å®¹
            if in_summary and line and len(line) > 10:
                summary_lines.append(line)
                
                # å¦‚æœå·²ç¶“æœ‰è¶³å¤ çš„æ¦‚è¿°å…§å®¹ï¼Œåœæ­¢
                if len('\n'.join(summary_lines)) > 500:
                    break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æœ‰æ„ç¾©çš„æ¦‚è¿°ï¼Œè¿”å›ç©º
        if len(summary_lines) <= 3:
            return ""
        
        # æ·»åŠ èªªæ˜
        summary_lines.append('')
        summary_lines.append('---')
        summary_lines.append('æ³¨ï¼šæœ¬å·åŒ…å«å¤šå€‹å“ï¼Œå…·é«”å“çš„å…§å®¹è«‹åƒè€ƒå°æ‡‰çš„å“æ–‡ä»¶ã€‚')
        
        return '\n'.join(summary_lines)
        
    def _save_source_text(self, content_data: Dict, chapter_number: int) -> None:
        """å„²å­˜åŸæ–‡ï¼ˆæ”¯æŒå±¤ç´šçµæ§‹ï¼‰"""
        # ä½¿ç”¨å¯¦éš›æå–çš„æ¨™é¡Œ
        title = content_data.get('title', content_data.get('original_title', f'ç« ç¯€{chapter_number}'))
        level = content_data.get('level', 1)
        
        # æ ¹æ“šå±¤ç´šèª¿æ•´æ–‡ä»¶åæ ¼å¼
        level_prefix = "  " * (level - 1) if level > 1 else ""
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', title)
        
        filename = f"{chapter_number:02d}_{clean_title}.txt"
        file_path = self.source_dir / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# {title}\n\n")
            
            # æ ¹æ“šå…§å®¹é¡å‹æ·»åŠ èªªæ˜
            content_type = content_data.get('content_type', 'full_content')
            if content_type == 'volume_summary':
                f.write("**èªªæ˜ï¼š** æœ¬æ–‡ä»¶ç‚ºå·çš„æ¦‚è¿°ï¼Œå…·é«”å“çš„å…§å®¹è«‹åƒè€ƒå°æ‡‰çš„å“æ–‡ä»¶ã€‚\n\n")
            
            f.write(content_data['content'])
            
        # è¨˜éŒ„æª”æ¡ˆæ“ä½œ
        self.file_monitor.track_file_write(file_path, "source_text", {
            "chapter_number": chapter_number,
            "title": title,
            "original_title": content_data.get('original_title', title),
            "level": level,
            "is_volume": content_data.get('is_volume', False),
            "is_chapter": content_data.get('is_chapter', False),
            "content_length": len(content_data['content'])
        })
        
        level_indicator = f" (Level {level})" if level > 1 else ""
        safe_print(f"âœ… {level_prefix}å·²å„²å­˜: {filename}{level_indicator}")
        
    def generate_translation_template(self, content_data: Dict, chapter_number: int) -> None:
        """ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼ˆæ”¯æŒå±¤ç´šçµæ§‹ï¼‰"""
        title = content_data.get('title', content_data.get('original_title', f'ç« ç¯€{chapter_number}'))
        level = content_data.get('level', 1)
        level_prefix = "  " * (level - 1) if level > 1 else ""
        
        safe_print(f"ğŸ¤– {level_prefix}ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {title}")
        
        clean_title = re.sub(r'[<>:"/\\|?*]', '_', title)
        filename = f"{chapter_number:02d}_{clean_title}.md"
        file_path = self.translation_dir / filename
        
        # æ ¹æ“šå±¤ç´šå’Œé¡å‹èª¿æ•´æ¨¡æ¿å…§å®¹
        structure_info = ""
        if content_data.get('is_volume'):
            structure_info = f"\n**çµæ§‹å±¤ç´šï¼š** å· (Level {level})"
        elif content_data.get('is_chapter'):
            structure_info = f"\n**çµæ§‹å±¤ç´šï¼š** å“/ç«  (Level {level})"
        
        markdown_content = f"""# {title}

## åŸæ–‡

{content_data['content']}

## ç¿»è­¯

[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]

åŸæ–‡å­—æ•¸ï¼š{len(content_data['content'])} å­—{structure_info}
å»ºè­°ï¼šè«‹ä½¿ç”¨AIç¿»è­¯å·¥å…·æˆ–äººå·¥ç¿»è­¯æ­¤æ®µè½ã€‚

ç¿»è­¯è¦é»ï¼š
1. ä¿æŒåŸæ–‡æ„æ€
2. ä½¿ç”¨ç¾ä»£ä¸­æ–‡è¡¨é”
3. ä¿ç•™é‡è¦çš„å¤ä»£è¡“èª
4. æ·»åŠ å¿…è¦çš„è¨»è§£èªªæ˜

## è¨»è§£

**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……]

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- [å¾…è£œå……]

**ç¿»è­¯è¦é»ï¼š**
- [å¾…è£œå……]

## çµæ§‹ä¿¡æ¯

**å±¤ç´šï¼š** Level {level}
**é¡å‹ï¼š** {'å·' if content_data.get('is_volume') else 'å“/ç« ' if content_data.get('is_chapter') else 'ç« ç¯€'}
**åŸå§‹æ¨™é¡Œï¼š** {content_data.get('original_title', title)}

---
*ç¿»è­¯æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ç¿»è­¯æ–¹å¼ï¼šè‡ªå‹•ç”Ÿæˆæ¨¡æ¿ï¼ˆæ”¯æŒå±¤ç´šçµæ§‹ï¼‰*
"""
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
            
        # è¨˜éŒ„æª”æ¡ˆæ“ä½œ
        self.file_monitor.track_file_write(file_path, "translation_template", {
            "chapter_number": chapter_number,
            "title": title,
            "original_title": content_data.get('original_title', title),
            "level": level,
            "is_volume": content_data.get('is_volume', False),
            "is_chapter": content_data.get('is_chapter', False),
            "template_type": "hierarchical_auto_generated"
        })
        
        level_indicator = f" (Level {level})" if level > 1 else ""
        safe_print(f"âœ… {level_prefix}å·²ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {filename}{level_indicator}")
        
    def create_project_readme(self, chapters: List[Dict]) -> None:
        """å»ºç«‹å°ˆæ¡ˆèªªæ˜æª”æ¡ˆ"""
        book_info = self.current_book
        
        readme_content = f"""# {book_info['title']}

## æ›¸ç±è³‡è¨Š

- **æ›¸å**ï¼š{book_info['title']}
- **ä½œè€…**ï¼š{book_info['author']}
- **æ›¸ç±ID**ï¼š{book_info['id']}
- **åŸå§‹ç¶²å€**ï¼š{book_info['url']}

## å°ˆæ¡ˆèªªæ˜

æœ¬å°ˆæ¡ˆä½¿ç”¨é“æ•™ç¶“å…¸ç¿»è­¯ç³»çµ±ç”Ÿæˆï¼ŒåŒ…å«ï¼š
1. è‡ªå‹•çˆ¬å–çš„å¤æ–‡åŸæ–‡
2. è‡ªå‹•ç”Ÿæˆçš„ç¿»è­¯æ¨¡æ¿
3. å®Œæ•´çš„å°ˆæ¡ˆçµæ§‹

## ç« ç¯€åˆ—è¡¨

ç¸½å…± {len(chapters)} å€‹ç« ç¯€ï¼š

"""
        
        for chapter in chapters:
            readme_content += f"- {chapter['number']:02d}. {chapter['title']}\n"
            
        readme_content += f"""

## ä½¿ç”¨èªªæ˜

1. **åŸæ–‡æª”æ¡ˆ**ï¼šä½æ–¼ `åŸæ–‡/` ç›®éŒ„
2. **ç¿»è­¯æª”æ¡ˆ**ï¼šä½æ–¼ `../translations/{book_info['id']}/` ç›®éŒ„
3. **ç¿»è­¯æ¨¡æ¿**ï¼šå·²è‡ªå‹•ç”Ÿæˆï¼Œå¯ç›´æ¥ç·¨è¼¯

## ç¿»è­¯é€²åº¦

- [x] åŸæ–‡çˆ¬å–å®Œæˆ
- [x] ç¿»è­¯æ¨¡æ¿ç”Ÿæˆå®Œæˆ
- [ ] äººå·¥ç¿»è­¯å¾…å®Œæˆ

---
*å°ˆæ¡ˆå»ºç«‹æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ä½¿ç”¨å·¥å…·ï¼šé“æ•™ç¶“å…¸ç¿»è­¯ç³»çµ± v2.0*
"""
        
        readme_path = self.project_root / "README.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
            
        # è¨˜éŒ„æª”æ¡ˆæ“ä½œ
        self.file_monitor.track_file_write(readme_path, "project_readme", {
            "book_id": book_info['id'],
            "book_title": book_info['title'],
            "chapter_count": len(chapters)
        })
            
        safe_print(f"âœ… å·²å»ºç«‹å°ˆæ¡ˆèªªæ˜: {readme_path}")
        
    def translate_book(self, book_url: str) -> bool:
        """ç¿»è­¯æ•´æœ¬æ›¸ç±çš„ä¸»è¦æµç¨‹"""
        safe_print("ğŸš€ å•Ÿå‹•é“æ•™ç¶“å…¸ç¿»è­¯ç³»çµ± v2.0")
        safe_print("=" * 50)
        
        try:
            # 1. ç²å–æ›¸ç±è³‡è¨Š
            book_info = self.get_book_info(book_url)
            safe_print(f"ğŸ“š æ›¸ç±ï¼š{book_info['title']}")
            safe_print(f"ğŸ‘¤ ä½œè€…ï¼š{book_info['author']}")
            
            # 2. è¨­å®šå°ˆæ¡ˆçµæ§‹
            self.setup_project_structure(book_info)
            
            # 3. è¨­ç½®ç•¶å‰æ›¸ç±ï¼ˆç”¨æ–¼å‹•æ…‹ç™¼ç¾ç« ç¯€ï¼‰
            self.current_book = book_info
            
            # 4. ç²å–ç« ç¯€åˆ—è¡¨ï¼ˆåŒ…å«å‹•æ…‹ç™¼ç¾ï¼‰
            chapters = self.get_chapter_list(book_url)
            if not chapters:
                safe_print("âŒ ç„¡æ³•ç²å–ç« ç¯€åˆ—è¡¨ï¼Œç¨‹åºçµ‚æ­¢")
                return False
                
            safe_print(f"ğŸ“‹ æ‰¾åˆ° {len(chapters)} å€‹åˆå§‹ç« ç¯€")
            
            # 5. æ™ºèƒ½ç« ç¯€IDåˆ†æ
            safe_print("\nğŸ” é–‹å§‹æ™ºèƒ½ç« ç¯€IDåˆ†æ...")
            id_pattern = self._analyze_chapter_id_patterns(chapters)
            
            # 6. æ™ºèƒ½å­ç« ç¯€ç™¼ç¾éšæ®µ
            safe_print(f"\nğŸ” é–‹å§‹æ™ºèƒ½å­ç« ç¯€ç™¼ç¾éšæ®µ...")
            safe_print(f"ğŸ“Š ä½¿ç”¨ç­–ç•¥: {id_pattern['strategy']}")
            all_chapters = chapters.copy()
            discovered_sub_chapters = []
            
            for chapter in chapters:
                if chapter.get('level', 1) == 1:  # åªæª¢æŸ¥é ‚ç´šç« ç¯€
                    level_prefix = "  " * (chapter.get('level', 1) - 1)
                    safe_print(f"{level_prefix}ğŸ” æª¢æŸ¥ç« ç¯€: {chapter['title']}")
                    
                    try:
                        # è¨ªå•ç« ç¯€é é¢é€²è¡Œæ™ºèƒ½åˆ†æ
                        response = self.session.get(chapter['url'], timeout=self.config["timeout"])
                        if response.status_code == 200:
                            soup = BeautifulSoup(response.text, 'html.parser')
                            
                            # æ™ºèƒ½ç™¼ç¾å­ç« ç¯€
                            sub_chapters = self._smart_discover_sub_chapters(soup, chapter)
                            
                            if sub_chapters:
                                safe_print(f"{level_prefix}   âœ… ç™¼ç¾ {len(sub_chapters)} å€‹å­ç« ç¯€")
                                
                                # ç‚ºå­ç« ç¯€åˆ†é…ç·¨è™Ÿä¸¦æ·»åŠ åˆ°ç¸½åˆ—è¡¨
                                for sub_chapter in sub_chapters:
                                    sub_chapter['number'] = len(all_chapters) + 1
                                    all_chapters.append(sub_chapter)
                                    discovered_sub_chapters.append(sub_chapter)
                                    
                                    sub_level_prefix = "  " * (sub_chapter.get('level', 2) - 1)
                                    safe_print(f"{sub_level_prefix}     ğŸ“„ {sub_chapter['title']} (Level {sub_chapter['level']})")
                            else:
                                safe_print(f"{level_prefix}   âš ï¸  æœªç™¼ç¾å­ç« ç¯€")
                        else:
                            safe_print(f"{level_prefix}   âŒ ç„¡æ³•è¨ªå•é é¢: HTTP {response.status_code}")
                            
                    except Exception as e:
                        safe_print(f"{level_prefix}   âŒ æª¢æŸ¥å­ç« ç¯€æ™‚å‡ºéŒ¯: {e}")
                    
                    # æ·»åŠ å»¶é²é¿å…è«‹æ±‚éå¿«
                    time.sleep(1)
            
            safe_print(f"\nğŸ“Š æ™ºèƒ½ç™¼ç¾çµæœ:")
            safe_print(f"   åˆå§‹ç« ç¯€: {len(chapters)}")
            safe_print(f"   ç™¼ç¾å­ç« ç¯€: {len(discovered_sub_chapters)}")
            safe_print(f"   ç¸½ç« ç¯€æ•¸: {len(all_chapters)}")
            
            if discovered_sub_chapters:
                safe_print(f"\nğŸ¤– æ™ºèƒ½ç™¼ç¾çš„å­ç« ç¯€:")
                for sub_chapter in discovered_sub_chapters:
                    sub_level_prefix = "  " * (sub_chapter.get('level', 2) - 1)
                    safe_print(f"{sub_level_prefix}- {sub_chapter['title']} (çˆ¶ç« ç¯€: {sub_chapter.get('parent_title', 'æœªçŸ¥')})")
            
            # ä½¿ç”¨åŒ…å«å­ç« ç¯€çš„å®Œæ•´åˆ—è¡¨
            chapters = all_chapters
            
            # é‡æ–°ç·¨è™Ÿæ‰€æœ‰ç« ç¯€
            for i, chapter in enumerate(chapters, 1):
                chapter['number'] = i
                
            safe_print(f"\nğŸ“‹ æœ€çµ‚ç« ç¯€ç¸½æ•¸: {len(chapters)}")
            
            # 7. æ‰¹é‡çˆ¬å–å’Œç¿»è­¯
            success_count = 0
            for chapter in chapters:
                safe_print(f"\nğŸ”„ è™•ç†ç¬¬ {chapter['number']} ç« ...")
                
                # çˆ¬å–åŸæ–‡
                content_data = self.crawl_chapter(chapter)
                if content_data:
                    # ç”Ÿæˆç¿»è­¯æ¨¡æ¿
                    self.generate_translation_template(content_data, chapter['number'])
                    success_count += 1
                    
                # æ·»åŠ å»¶é²é¿å…è¢«å°é–
                time.sleep(self.config["request_delay"])
                
            # 8. å»ºç«‹å°ˆæ¡ˆæ–‡æª”
            self.create_project_readme(chapters)
            
            # 9. è¿½è¹¤æ–°ç¶“å…¸åˆ°ç³»çµ±
            if success_count > 0:
                safe_print("\nğŸ“Š æ›´æ–°ç¶“å…¸è¿½è¹¤ç³»çµ±...")
                try:
                    processed_chapters = []
                    for i, chapter in enumerate(chapters[:success_count], 1):
                        processed_chapters.append({
                            'number': i,
                            'title': chapter.get('title', f'ç¬¬{i}ç« '),
                            'url': chapter.get('url', '')
                        })
                    
                    self.tracker.track_new_classic(
                        book_info=book_info,
                        chapters=processed_chapters,
                        source_dir=self.project_root,
                        translation_dir=self.translation_dir
                    )
                    
                    safe_print("âœ… ç¶“å…¸è¿½è¹¤ç³»çµ±å·²æ›´æ–°")
                    
                except Exception as e:
                    safe_print(f"âš ï¸  è¿½è¹¤ç³»çµ±æ›´æ–°å¤±æ•—: {e}")
            
            # 10. ç”Ÿæˆç¸½çµå ±å‘Š
            safe_print(f"\nğŸ‰ ç¿»è­¯å®Œæˆï¼")
            safe_print(f"âœ… æˆåŠŸè™•ç†ï¼š{success_count}/{len(chapters)} ç« ")
            safe_print(f"ğŸ“ å°ˆæ¡ˆä½ç½®ï¼š{self.project_root}")
            safe_print(f"ğŸ“ ç¿»è­¯æª”æ¡ˆï¼š{self.translation_dir}")
            
            return success_count > 0
            
        except Exception as e:
            safe_print(f"âŒ ç¿»è­¯éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False