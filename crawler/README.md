# é“æ•™ç¶“å…¸çˆ¬èŸ²æ¨¡çµ„

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

å®Œæ•´çš„é“æ•™ç¶“å…¸çˆ¬å–å’Œç¿»è­¯å·¥ä½œæµç¨‹å·¥å…·ï¼š

âœ… **è‡ªå‹•çˆ¬å–ç¶“æ–‡** - å¾å¸«å…¸å¤ç±ç¶²ç«™çˆ¬å–é“æ•™ç¶“å…¸  
âœ… **ä¿å­˜åŸæ–‡** - çµæ§‹åŒ–ä¿å­˜ç‚ºæ–‡å­—æª”æ¡ˆ  
âœ… **ç”Ÿæˆç¿»è­¯æ¨¡æ¿** - è‡ªå‹•å»ºç«‹ Markdown ç¿»è­¯æ¨¡æ¿  
âœ… **æ‰¹é‡è™•ç†** - æ”¯æ´æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸ç±  
âœ… **å®Œæ•´æ—¥èªŒ** - è©³ç´°çš„åŸ·è¡Œæ—¥èªŒå’ŒéŒ¯èª¤è¿½è¹¤  

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æœ€ç°¡å–®çš„æ–¹å¼

```bash
# ç›´æ¥åŸ·è¡Œä¸»çˆ¬èŸ²
python crawler/shidian_crawler.py
```

### Python è…³æœ¬

```python
from crawler.shidian_crawler import ShidianCrawler

# å»ºç«‹çˆ¬èŸ²
crawler = ShidianCrawler(delay=2)

# çˆ¬å–æ›¸ç±ï¼ˆè‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼‰
book = crawler.crawl_book('DZ1422')

# æŸ¥çœ‹çµ±è¨ˆ
crawler.print_statistics(book)
```

## ğŸ“ æ¨¡çµ„çµæ§‹

```
crawler/
â”œâ”€â”€ shidian_crawler.py          # ä¸»çˆ¬èŸ²ï¼ˆæ¨è–¦ä½¿ç”¨ï¼‰â­
â”œâ”€â”€ base_crawler.py             # åŸºç¤çˆ¬èŸ²é¡åˆ¥
â”œâ”€â”€ README.md                   # æœ¬æ–‡æª”
â”œâ”€â”€ å¿«é€Ÿé–‹å§‹.md                  # 5åˆ†é˜ä¸Šæ‰‹æŒ‡å—
â”œâ”€â”€ README_æ›´æ–°èªªæ˜.md           # è©³ç´°APIæ–‡æª”
â”‚
â”œâ”€â”€ èˆŠç‰ˆçˆ¬èŸ²ï¼ˆä¿ç•™åƒè€ƒï¼‰/
â”‚   â”œâ”€â”€ shidian_selenium.py     # Seleniumç‰ˆæœ¬
â”‚   â”œâ”€â”€ smart_crawler.py        # æ™ºèƒ½çˆ¬èŸ²
â”‚   â”œâ”€â”€ taoism_crawler.py       # é€šç”¨çˆ¬èŸ²
â”‚   â””â”€â”€ ...å…¶ä»–èˆŠç‰ˆå·¥å…·
â”‚
â””â”€â”€ docs/                       # æ–‡æª”ç›®éŒ„
    â”œâ”€â”€ practical_guide.md      # å¯¦ç”¨æŒ‡å—
    â””â”€â”€ å·¥å…·åŠŸèƒ½å°ç…§è¡¨.md        # åŠŸèƒ½å°ç…§
```

## ğŸ¯ ä¸»è¦çˆ¬èŸ²ï¼šshidian_crawler.py

é€™æ˜¯ç›®å‰æœ€å®Œæ•´ã€æœ€ç©©å®šçš„çˆ¬èŸ²å·¥å…·ã€‚

### æ ¸å¿ƒç‰¹é»

- âœ… **100% æˆåŠŸç‡** - æ¸¬è©¦æ–¼ DZ1422, DZ1439
- âœ… **è‡ªå‹•åŒ–æµç¨‹** - çˆ¬å– â†’ ä¿å­˜ â†’ ç”Ÿæˆæ¨¡æ¿
- âœ… **å®Œæ•´æ—¥èªŒ** - è©³ç´°çš„åŸ·è¡Œè¨˜éŒ„
- âœ… **éŒ¯èª¤è™•ç†** - å®Œå–„çš„ç•°å¸¸è™•ç†æ©Ÿåˆ¶
- âœ… **æ‰¹é‡æ”¯æ´** - å¯æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸ç±

### ä½¿ç”¨æ–¹æ³•

#### 1. çˆ¬å–å–®æœ¬æ›¸ç±

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422')
```

#### 2. æ‰¹é‡çˆ¬å–

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler(delay=3)
book_ids = ['DZ1422', 'DZ1439', 'DZ1234']
results = crawler.batch_crawl(book_ids)
```

#### 3. ä¸ç”Ÿæˆç¿»è­¯æ¨¡æ¿

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422', generate_templates=False)
```

## ğŸ“Š è¼¸å‡ºçµæ§‹

```
Taoism/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ source_texts/          # åŸæ–‡
â”‚   â”‚   â””â”€â”€ æ›¸å/
â”‚   â”‚       â”œâ”€â”€ 00_æ›¸ç±è³‡è¨Š.txt
â”‚   â”‚       â””â”€â”€ 01_ç« ç¯€.txt
â”‚   â”‚
â”‚   â””â”€â”€ translations/          # ç¿»è­¯æ¨¡æ¿
â”‚       â””â”€â”€ æ›¸å/
â”‚           â”œâ”€â”€ README.md      # å°ˆæ¡ˆèªªæ˜
â”‚           â””â”€â”€ 01_ç« ç¯€.md     # ç¿»è­¯æ¨¡æ¿
â”‚
â””â”€â”€ data/
    â””â”€â”€ crawled/               # JSONè³‡æ–™
        â””â”€â”€ DZ1422_æ›¸å.json
```

## ğŸ“ ä½¿ç”¨æ–‡æª”

### æ–°æ‰‹å…¥é–€
1. **å¿«é€Ÿé–‹å§‹.md** - 5åˆ†é˜å¿«é€Ÿä¸Šæ‰‹
2. **README_æ›´æ–°èªªæ˜.md** - è©³ç´°APIæ–‡æª”
3. **practical_guide.md** - å¯¦ç”¨æŒ‡å—

### é€²éšä½¿ç”¨
- æŸ¥çœ‹ `shidian_crawler.py` åŸå§‹ç¢¼
- åƒè€ƒ `å·¥å…·åŠŸèƒ½å°ç…§è¡¨.md`

## ğŸ“ˆ æ¸¬è©¦çµæœ

### DZ1422 æ•ä¸­ç¶“
- âœ… ç« ç¯€æ•¸: 1 ç« 
- âœ… ç¸½å­—æ•¸: 853 å­—
- âœ… æˆåŠŸç‡: 100%

### DZ1439 æ´ç„éˆå¯¶ç‰äº¬å±±æ­¥è™›ç¶“
- âœ… ç« ç¯€æ•¸: 7 ç« 
- âœ… ç¸½å­—æ•¸: 3,502 å­—
- âœ… æˆåŠŸç‡: 100%

## ğŸ”§ API åƒè€ƒ

### ShidianCrawler é¡åˆ¥

```python
class ShidianCrawler:
    def __init__(self, delay=2)
    def get_book_info(self, book_id)
    def get_chapter_content(self, chapter_url, chapter_name="")
    def crawl_all_chapters(self, book_info)
    def crawl_book(self, book_id, generate_templates=True)
    def save_to_json(self, book_info, output_dir='data/crawled')
    def save_to_text_files(self, book_info, output_dir=None)
    def generate_translation_templates(self, book_info, output_dir=None)
    def batch_crawl(self, book_ids, output_dir='data/crawled')
    def print_statistics(self, book_info)
```

è©³ç´°èªªæ˜è«‹åƒè€ƒ `README_æ›´æ–°èªªæ˜.md`

## ğŸ¯ å¦‚ä½•æ‰¾åˆ°æ›¸ç±ç·¨è™Ÿ

å¾å¸«å…¸å¤ç±ç¶²ç«™çš„ URL ä¸­æ‰¾ï¼š

```
https://www.shidianguji.com/book/DZ1422
                                  ^^^^^^
                                  æ›¸ç±ç·¨è™Ÿ
```

## âš™ï¸ é…ç½®é¸é …

### å»¶é²æ™‚é–“

```python
# é è¨­ 2 ç§’ï¼ˆæ¨è–¦ï¼‰
crawler = ShidianCrawler(delay=2)

# æ‰¹é‡çˆ¬å–å»ºè­° 3 ç§’
crawler = ShidianCrawler(delay=3)
```

### è¼¸å‡ºç›®éŒ„

```python
# ä½¿ç”¨é è¨­ç›®éŒ„
crawler.save_to_text_files(book)
crawler.generate_translation_templates(book)

# è‡ªè¨‚ç›®éŒ„
crawler.save_to_text_files(book, 'my_output/texts')
crawler.generate_translation_templates(book, 'my_output/translations')
```

## ğŸ“ å®Œæ•´ç¯„ä¾‹

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„çˆ¬èŸ²ä½¿ç”¨ç¯„ä¾‹
"""

from crawler.shidian_crawler import ShidianCrawler

def main():
    # 1. å»ºç«‹çˆ¬èŸ²
    crawler = ShidianCrawler(delay=2)
    
    # 2. çˆ¬å–æ›¸ç±
    book = crawler.crawl_book('DZ1422')
    
    # 3. æŸ¥çœ‹çµæœ
    if book:
        crawler.print_statistics(book)
        print(f"\nâœ“ å®Œæˆï¼")
        print(f"åŸæ–‡: docs/source_texts/{book['title']}/")
        print(f"ç¿»è­¯: docs/translations/{book['title']}/")

if __name__ == "__main__":
    main()
```

## â“ å¸¸è¦‹å•é¡Œ

### Q1: çˆ¬å–å¤±æ•—æ€éº¼è¾¦ï¼Ÿ

**A:** æª¢æŸ¥ï¼š
1. ç¶²è·¯é€£ç·šæ˜¯å¦æ­£å¸¸
2. æ›¸ç±ç·¨è™Ÿæ˜¯å¦æ­£ç¢º
3. æŸ¥çœ‹æ—¥èªŒ: `data/logs/shidian_crawler.log`

### Q2: ç¿»è­¯æ¨¡æ¿æ²’æœ‰ç”Ÿæˆï¼Ÿ

**A:** ç¢ºèªåƒæ•¸è¨­å®šï¼š
```python
book = crawler.crawl_book('DZ1422', generate_templates=True)
```

### Q3: å¯ä»¥æ‰¹é‡çˆ¬å–å—ï¼Ÿ

**A:** å¯ä»¥ï¼
```python
results = crawler.batch_crawl(['DZ1422', 'DZ1439'])
```

## âš ï¸ æ³¨æ„äº‹é …

1. **ç¶²è·¯ç©©å®š** - ç¢ºä¿ç¶²è·¯é€£ç·šç©©å®š
2. **è«‹æ±‚é »ç‡** - ä¸è¦è¨­å®šéçŸ­çš„å»¶é²ï¼ˆæœ€ä½ 1 ç§’ï¼‰
3. **ç£ç¢Ÿç©ºé–“** - ç¢ºä¿æœ‰è¶³å¤ ç©ºé–“å„²å­˜çµæœ
4. **ç‰ˆæ¬Šå°Šé‡** - åƒ…ä¾›å­¸ç¿’ç ”ç©¶ä½¿ç”¨

## ğŸ”„ èˆŠç‰ˆå·¥å…·èªªæ˜

æ¨¡çµ„ä¸­ä¿ç•™äº†ä¸€äº›èˆŠç‰ˆçˆ¬èŸ²å·¥å…·ä¾›åƒè€ƒï¼š

- `shidian_selenium.py` - ä½¿ç”¨ Selenium çš„ç‰ˆæœ¬ï¼ˆéœ€è¦ ChromeDriverï¼‰
- `smart_crawler.py` - æ™ºèƒ½çˆ¬èŸ²ï¼ˆè‡ªå‹•é¸æ“‡ç­–ç•¥ï¼‰
- `taoism_crawler.py` - é€šç”¨é“æ•™ç¶“å…¸çˆ¬èŸ²

**å»ºè­°ï¼š** æ–°å°ˆæ¡ˆè«‹ä½¿ç”¨ `shidian_crawler.py`

## ğŸ“š ç›¸é—œæ–‡æª”

- [å¿«é€Ÿé–‹å§‹æŒ‡å—](å¿«é€Ÿé–‹å§‹.md) - 5åˆ†é˜ä¸Šæ‰‹
- [è©³ç´°APIæ–‡æª”](README_æ›´æ–°èªªæ˜.md) - å®Œæ•´APIèªªæ˜
- [å¯¦ç”¨æŒ‡å—](docs/practical_guide.md) - é€²éšæŠ€å·§
- [åŠŸèƒ½å°ç…§è¡¨](å·¥å…·åŠŸèƒ½å°ç…§è¡¨.md) - å·¥å…·æ¯”è¼ƒ

## ğŸ‰ é–‹å§‹ä½¿ç”¨

```bash
# ç«‹å³é–‹å§‹
python crawler/shidian_crawler.py
```

æˆ–æŸ¥çœ‹ [å¿«é€Ÿé–‹å§‹æŒ‡å—](å¿«é€Ÿé–‹å§‹.md) äº†è§£æ›´å¤šã€‚

---

**æ¨¡çµ„ç‰ˆæœ¬**: v2.0  
**æ›´æ–°æ™‚é–“**: 2025-10-20  
**æ¸¬è©¦ç‹€æ…‹**: âœ… é€šé  
**ç¶­è­·ç‹€æ…‹**: âœ… æ´»èºç¶­è­·  
