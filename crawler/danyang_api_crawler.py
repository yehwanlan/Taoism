#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸¹é™½çœŸäººç›´è¨€ API çˆ¬èŸ²
ç›´æ¥èª¿ç”¨å¸«å…¸å¤ç±çš„ API ç²å–å…§å®¹
"""

import json
import re
import sys
from pathlib import Path
from urllib.parse import urljoin

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent))

from base_crawler import BaseCrawler

def safe_print(*args, **kwargs):
    """å®‰å…¨æ‰“å°"""
    try:
        print(*args, **kwargs)
    except UnicodeEncodeError:
        # ç§»é™¤ emoji å’Œç‰¹æ®Šå­—ç¬¦
        import re
        safe_args = []
        for arg in args:
            text = str(arg)
            # ç§»é™¤ emoji
            text = re.sub(r'[^\u0000-\uFFFF]', '', text)
            safe_args.append(text)
        try:
            print(*safe_args, **kwargs)
        except:
            # æœ€å¾Œæ‰‹æ®µï¼šåªä¿ç•™ ASCII å’ŒåŸºæœ¬ä¸­æ–‡
            ascii_args = [str(arg).encode('ascii', errors='ignore').decode('ascii') for arg in args]
            print(*ascii_args, **kwargs)

class DanyangAPICrawler(BaseCrawler):
    """ä¸¹é™½çœŸäººç›´è¨€ API çˆ¬èŸ²"""
    
    def __init__(self):
        super().__init__(delay_range=(2, 4))
        self.base_url = "https://www.shidianguji.com"
        
    def extract_ids_from_url(self, url):
        """å¾ URL æå–æ›¸ç±å’Œç« ç¯€ ID"""
        book_match = re.search(r'/book/([^/]+)', url)
        chapter_match = re.search(r'/chapter/([^/?]+)', url)
        
        book_id = book_match.group(1) if book_match else None
        chapter_id = chapter_match.group(1) if chapter_match else None
        
        return book_id, chapter_id
    
    def try_api_endpoints(self, book_id, chapter_id):
        """å˜—è©¦å„ç¨®å¯èƒ½çš„ API ç«¯é»"""
        safe_print(f"ğŸ”Œ å˜—è©¦ API ç«¯é»...")
        safe_print(f"   æ›¸ç±ID: {book_id}")
        safe_print(f"   ç« ç¯€ID: {chapter_id}")
        safe_print()
        
        # å¯èƒ½çš„ API ç«¯é»
        api_patterns = [
            f"/api/book/{book_id}",
            f"/api/book/{book_id}/chapters",
            f"/api/book/{book_id}/chapter/{chapter_id}",
            f"/api/chapter/{chapter_id}",
            f"/api/ancientlib/book/{book_id}",
            f"/api/ancientlib/book/{book_id}/chapter/{chapter_id}",
            f"/api/ancientlib/chapter/{chapter_id}",
            f"/api/ancientlib/volume/{chapter_id}/content",
        ]
        
        results = []
        
        for i, pattern in enumerate(api_patterns, 1):
            api_url = urljoin(self.base_url, pattern)
            safe_print(f"[{i}/{len(api_patterns)}] å˜—è©¦: {pattern}")
            
            response = self.make_request(api_url)
            
            if response and response.status_code == 200:
                try:
                    data = response.json()
                    if data:
                        safe_print(f"     âœ… æˆåŠŸï¼ç²å¾— JSON æ•¸æ“š")
                        results.append({
                            'url': api_url,
                            'pattern': pattern,
                            'data': data,
                            'type': 'json'
                        })
                        
                        # é¡¯ç¤ºæ•¸æ“šçµæ§‹é è¦½
                        if isinstance(data, dict):
                            keys = list(data.keys())[:5]
                            safe_print(f"     ğŸ“Š æ•¸æ“šéµ: {keys}")
                        
                except json.JSONDecodeError:
                    if len(response.text) > 100:
                        safe_print(f"     âš ï¸  æˆåŠŸä½†é JSON")
                        
                        # ä¿å­˜ HTML ç”¨æ–¼èª¿è©¦
                        debug_file = Path(f"debug_api_{i}_html.html")
                        with open(debug_file, 'w', encoding='utf-8') as f:
                            f.write(response.text)
                        safe_print(f"     å·²ä¿å­˜: {debug_file}")
                        
                        results.append({
                            'url': api_url,
                            'pattern': pattern,
                            'data': response.text,
                            'type': 'text'
                        })
            else:
                status = response.status_code if response else 'No Response'
                safe_print(f"     âŒ å¤±æ•— (ç‹€æ…‹: {status})")
            
            self.delay()
        
        safe_print()
        safe_print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(results)} å€‹æœ‰æ•ˆç«¯é»")
        return results
    
    def extract_content_from_json(self, data, depth=0, max_depth=5):
        """å¾ JSON æ•¸æ“šä¸­éæ­¸æå–å…§å®¹"""
        if depth > max_depth:
            return []
        
        contents = []
        
        if isinstance(data, dict):
            # æª¢æŸ¥å¸¸è¦‹çš„å…§å®¹å­—æ®µ
            content_fields = ['content', 'text', 'body', 'data', 'chapterContent', 
                            'originalText', 'contentText', 'fullText']
            
            for field in content_fields:
                if field in data:
                    value = data[field]
                    if isinstance(value, str) and len(value) > 50:
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡
                        if re.search(r'[\u4e00-\u9fff]', value):
                            contents.append({
                                'field': field,
                                'content': value,
                                'length': len(value)
                            })
            
            # éæ­¸æœç´¢
            for key, value in data.items():
                if isinstance(value, (dict, list)):
                    contents.extend(self.extract_content_from_json(value, depth + 1, max_depth))
        
        elif isinstance(data, list):
            for item in data:
                if isinstance(item, (dict, list)):
                    contents.extend(self.extract_content_from_json(item, depth + 1, max_depth))
                elif isinstance(item, str) and len(item) > 50:
                    if re.search(r'[\u4e00-\u9fff]', item):
                        contents.append({
                            'field': 'list_item',
                            'content': item,
                            'length': len(item)
                        })
        
        return contents
    
    def crawl_danyang(self, url):
        """çˆ¬å–ä¸¹é™½çœŸäººç›´è¨€"""
        safe_print("=" * 80)
        safe_print("ğŸ¯ ä¸¹é™½çœŸäººç›´è¨€ API çˆ¬èŸ²")
        safe_print("=" * 80)
        safe_print(f"ğŸŒ ç›®æ¨™ URL: {url}")
        safe_print()
        
        # 1. æå– ID
        book_id, chapter_id = self.extract_ids_from_url(url)
        
        if not book_id or not chapter_id:
            safe_print("âŒ ç„¡æ³•å¾ URL æå– ID")
            return False
        
        # 2. å˜—è©¦ API ç«¯é»
        api_results = self.try_api_endpoints(book_id, chapter_id)
        
        if not api_results:
            safe_print("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ API ç«¯é»")
            return False
        
        # 3. å¾æ¯å€‹çµæœä¸­æå–å…§å®¹
        safe_print("ğŸ“– é–‹å§‹æå–å…§å®¹...")
        safe_print()
        
        all_contents = []
        
        for i, result in enumerate(api_results, 1):
            safe_print(f"[{i}/{len(api_results)}] åˆ†æ: {result['pattern']}")
            
            if result['type'] == 'json':
                contents = self.extract_content_from_json(result['data'])
                
                if contents:
                    safe_print(f"     âœ… æ‰¾åˆ° {len(contents)} å€‹å…§å®¹ç‰‡æ®µ")
                    for content in contents:
                        safe_print(f"        - {content['field']}: {content['length']} å­—ç¬¦")
                        all_contents.append(content)
                else:
                    safe_print(f"     âš ï¸  æœªæ‰¾åˆ°å…§å®¹")
                    
                    # ä¿å­˜ JSON ç”¨æ–¼èª¿è©¦
                    debug_file = Path("crawler") / f"debug_api_{i}.json"
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        json.dump(result['data'], f, ensure_ascii=False, indent=2)
                    safe_print(f"     ğŸ’¾ å·²ä¿å­˜èª¿è©¦æ–‡ä»¶: {debug_file}")
            
            safe_print()
        
        # 4. é¸æ“‡æœ€ä½³å…§å®¹
        if not all_contents:
            safe_print("âŒ æœªèƒ½å¾ä»»ä½• API æå–åˆ°å…§å®¹")
            safe_print("ğŸ’¡ è«‹æª¢æŸ¥ debug_api_*.json æ–‡ä»¶æŸ¥çœ‹åŸå§‹æ•¸æ“š")
            return False
        
        # æŒ‰é•·åº¦æ’åºï¼Œé¸æ“‡æœ€é•·çš„
        all_contents.sort(key=lambda x: x['length'], reverse=True)
        best_content = all_contents[0]
        
        safe_print("=" * 80)
        safe_print("ğŸ“Š å…§å®¹æå–çµæœ")
        safe_print("=" * 80)
        safe_print(f"âœ… æœ€ä½³å…§å®¹ä¾†æº: {best_content['field']}")
        safe_print(f"ğŸ“ å…§å®¹é•·åº¦: {best_content['length']} å­—ç¬¦")
        safe_print()
        
        # é¡¯ç¤ºé è¦½
        preview = best_content['content'][:200]
        safe_print("ğŸ“ å…§å®¹é è¦½:")
        safe_print("-" * 80)
        safe_print(preview + "...")
        safe_print("-" * 80)
        safe_print()
        
        # 5. ä¿å­˜å…§å®¹
        filename = f"ä¸¹é™½çœŸäººç›´è¨€_{book_id}_APIç‰ˆ.txt"
        save_dir = Path("docs/source_texts")
        save_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = save_dir / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(best_content['content'])
        
        safe_print(f"âœ… å·²ä¿å­˜: {file_path}")
        safe_print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_path.stat().st_size} å­—ç¯€")
        safe_print()
        
        return True

def main():
    """ä¸»å‡½æ•¸"""
    target_url = "https://www.shidianguji.com/book/DZ1234/chapter/start?page_from=bookshelf&mode=book"
    
    crawler = DanyangAPICrawler()
    success = crawler.crawl_danyang(target_url)
    
    safe_print("=" * 80)
    if success:
        safe_print("ğŸ‰ API çˆ¬å–æˆåŠŸï¼")
        safe_print("ğŸ“ æª”æ¡ˆå·²ä¿å­˜åˆ° docs/source_texts/ ç›®éŒ„")
    else:
        safe_print("âŒ API çˆ¬å–å¤±æ•—")
        safe_print("ğŸ’¡ å¯èƒ½åŸå› :")
        safe_print("   1. API ç«¯é»å·²è®Šæ›´")
        safe_print("   2. éœ€è¦ç™»éŒ„æ‰èƒ½è¨ªå• API")
        safe_print("   3. å…§å®¹çµæ§‹èˆ‡é æœŸä¸åŒ")
        safe_print()
        safe_print("ğŸ”§ è«‹æª¢æŸ¥ debug_api_*.json æ–‡ä»¶äº†è§£è©³æƒ…")
    safe_print("=" * 80)

if __name__ == "__main__":
    main()
