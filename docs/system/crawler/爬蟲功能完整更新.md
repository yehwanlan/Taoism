# ğŸ‰ çˆ¬èŸ²åŠŸèƒ½å®Œæ•´æ›´æ–° - å«ç¿»è­¯æ¨¡æ¿ç”Ÿæˆ

## âœ… æ›´æ–°å®Œæˆ

ä½ çš„çˆ¬èŸ²ç³»çµ±ç¾åœ¨å…·å‚™å®Œæ•´åŠŸèƒ½ï¼š
1. âœ… çˆ¬å–ç¶“æ–‡åŸæ–‡
2. âœ… è‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿
3. âœ… ä¿å­˜ JSON è³‡æ–™
4. âœ… å®Œæ•´çš„å°ˆæ¡ˆçµæ§‹

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. è‡ªå‹•åŒ–å·¥ä½œæµç¨‹

```
çˆ¬å–æ›¸ç± â†’ ä¿å­˜åŸæ–‡ â†’ ç”Ÿæˆç¿»è­¯æ¨¡æ¿ â†’ å»ºç«‹å°ˆæ¡ˆçµæ§‹
```

**ä¸€å€‹å‘½ä»¤å®Œæˆæ‰€æœ‰å·¥ä½œï¼š**
```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422')  # è‡ªå‹•å®Œæˆæ‰€æœ‰æ­¥é©Ÿ
```

### 2. è¼¸å‡ºçµæ§‹

```
Taoism/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ source_texts/          # åŸæ–‡
â”‚   â”‚   â””â”€â”€ æ›¸å/
â”‚   â”‚       â”œâ”€â”€ 00_æ›¸ç±è³‡è¨Š.txt
â”‚   â”‚       â”œâ”€â”€ 01_ç« ç¯€1.txt
â”‚   â”‚       â””â”€â”€ 02_ç« ç¯€2.txt
â”‚   â”‚
â”‚   â””â”€â”€ translations/          # ç¿»è­¯æ¨¡æ¿ï¼ˆæ–°å¢ï¼ï¼‰
â”‚       â””â”€â”€ æ›¸å/
â”‚           â”œâ”€â”€ README.md      # å°ˆæ¡ˆèªªæ˜
â”‚           â”œâ”€â”€ 01_ç« ç¯€1.md    # ç¿»è­¯æ¨¡æ¿
â”‚           â””â”€â”€ 02_ç« ç¯€2.md
â”‚
â””â”€â”€ data/
    â””â”€â”€ crawled/               # JSON è³‡æ–™
        â””â”€â”€ DZ1422_æ›¸å.json
```

### 3. ç¿»è­¯æ¨¡æ¿æ ¼å¼

æ¯å€‹ç« ç¯€çš„ç¿»è­¯æ¨¡æ¿åŒ…å«ï¼š

```markdown
# ç« ç¯€åç¨±

## åŸæ–‡
[è‡ªå‹•å¡«å…¥çš„å¤æ–‡åŸæ–‡]

## ç¿»è­¯
[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]

## è¨»è§£
**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……]

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- [å¾…è£œå……]

## ç« ç¯€è³‡è¨Š
- ç« ç¯€ç·¨è™Ÿ
- ç« ç¯€åç¨±
- åŸå§‹ URL
- ç”Ÿæˆæ™‚é–“
```

### 4. å°ˆæ¡ˆ README

è‡ªå‹•ç”Ÿæˆçš„ README.md åŒ…å«ï¼š
- æ›¸ç±å®Œæ•´è³‡è¨Š
- ç« ç¯€åˆ—è¡¨ï¼ˆå«é€£çµï¼‰
- ç¿»è­¯é€²åº¦è¿½è¹¤
- ä½¿ç”¨èªªæ˜
- ç¿»è­¯è¦ç¯„

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: æœ€ç°¡å–®ï¼ˆæ¨è–¦ï¼‰

```bash
# ç›´æ¥åŸ·è¡Œï¼Œè‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿
python crawler/shidian_crawler.py
```

### æ–¹æ³•2: Python è…³æœ¬

```python
from crawler.shidian_crawler import ShidianCrawler

# å»ºç«‹çˆ¬èŸ²
crawler = ShidianCrawler(delay=2)

# çˆ¬å–æ›¸ç±ï¼ˆè‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼‰
book = crawler.crawl_book('DZ1422')

# æŸ¥çœ‹çµ±è¨ˆ
crawler.print_statistics(book)
```

### æ–¹æ³•3: ä¸ç”Ÿæˆç¿»è­¯æ¨¡æ¿

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()

# åªçˆ¬å–ï¼Œä¸ç”Ÿæˆæ¨¡æ¿
book = crawler.crawl_book('DZ1422', generate_templates=False)
```

### æ–¹æ³•4: æ‰¹é‡çˆ¬å–

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()

# æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸ç±
book_ids = ['DZ1422', 'DZ1439', 'DZ1234']
results = crawler.batch_crawl(book_ids)
```

## ğŸ“Š æ¸¬è©¦çµæœ

### DZ1422 æ•ä¸­ç¶“
- âœ… æ›¸å: æ•ä¸­ç»
- âœ… æœä»£: å”
- âœ… ä½œè€…: ä½šå
- âœ… ç« ç¯€æ•¸: 1 ç« 
- âœ… ç¸½å­—æ•¸: 853 å­—
- âœ… æˆåŠŸç‡: 100%
- âœ… ç¿»è­¯æ¨¡æ¿: å·²ç”Ÿæˆ

### DZ1439 æ´ç„éˆå¯¶ç‰äº¬å±±æ­¥è™›ç¶“
- âœ… æ›¸å: æ´ç„çµå®ç‰äº¬å±±æ­¥è™šç»
- âœ… æœä»£: ä¸œæ™‹
- âœ… ä½œè€…: ä½šå
- âœ… ç« ç¯€æ•¸: 7 ç« 
- âœ… ç¸½å­—æ•¸: 3,502 å­—
- âœ… æˆåŠŸç‡: 100%
- âœ… ç¿»è­¯æ¨¡æ¿: å·²ç”Ÿæˆ

## ğŸ“ ç¿»è­¯å·¥ä½œæµç¨‹

### æ­¥é©Ÿ1: çˆ¬å–ç¶“æ–‡

```bash
python crawler/shidian_crawler.py
```

æˆ–æŒ‡å®šæ›¸ç±ï¼š

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422')
```

### æ­¥é©Ÿ2: é–‹å§‹ç¿»è­¯

1. æ‰“é–‹ `docs/translations/æ›¸å/` ç›®éŒ„
2. æŸ¥çœ‹ `README.md` äº†è§£å°ˆæ¡ˆè³‡è¨Š
3. æ‰“é–‹ç« ç¯€çš„ `.md` æª”æ¡ˆ
4. åœ¨ã€Œç¿»è­¯ã€å€å¡Šå¡«å¯«ç¾ä»£ä¸­æ–‡ç¿»è­¯

### æ­¥é©Ÿ3: æ·»åŠ è¨»è§£

åœ¨ã€Œè¨»è§£ã€å€å¡Šè£œå……ï¼š
- é‡è¦è©å½™è§£é‡‹
- æ–‡åŒ–èƒŒæ™¯èªªæ˜
- ç¿»è­¯è¦é»

### æ­¥é©Ÿ4: æ›´æ–°é€²åº¦

åœ¨ `README.md` ä¸­æ›´æ–°ç¿»è­¯é€²åº¦ï¼š
```markdown
## ç¿»è­¯é€²åº¦

- [x] ç¬¬1ç«  - å·²å®Œæˆ
- [ ] ç¬¬2ç«  - é€²è¡Œä¸­
- [ ] ç¬¬3ç«  - å¾…é–‹å§‹
```

## ğŸ“ ç¿»è­¯æ¨¡æ¿ç¯„ä¾‹

### åŸå§‹æ¨¡æ¿

```markdown
# æ•ä¸­ç»

## åŸæ–‡

è€å›æ›°ï¼šå¤§é“æ— å½¢ï¼Œå¸¸å±…æ³å†¥ã€‚éšæœºåŒ–ç‰©ï¼Œä»¥åº”ç²¾è¯š...

## ç¿»è­¯

[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]

## è¨»è§£

**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……]
```

### å®Œæˆå¾Œçš„ç¯„ä¾‹

```markdown
# æ•ä¸­ç»

## åŸæ–‡

è€å›æ›°ï¼šå¤§é“æ— å½¢ï¼Œå¸¸å±…æ³å†¥ã€‚éšæœºåŒ–ç‰©ï¼Œä»¥åº”ç²¾è¯š...

## ç¿»è­¯

è€å›èªªï¼šå¤§é“æ²’æœ‰å›ºå®šçš„å½¢é«”ï¼Œå¸¸å¸¸å­˜åœ¨æ–¼å¹½æ·±ç„å¦™ä¹‹ä¸­ã€‚
å®ƒéš¨è‘—æ™‚æ©Ÿè®ŠåŒ–è¬ç‰©ï¼Œä»¥å›æ‡‰äººå€‘çš„ç²¾èª ä¹‹å¿ƒ...

## è¨»è§£

**é‡è¦è©å½™ï¼š**
- æ³å†¥ï¼šå¹½æ·±ç„å¦™ï¼Œå½¢å®¹é“çš„æ·±å¥§é›£æ¸¬
- ç²¾èª ï¼šçœŸèª å°ˆä¸€çš„å¿ƒæ„
- ä¸‰é­‚ä¸ƒé­„ï¼šé“æ•™èªç‚ºäººæœ‰ä¸‰é­‚ä¸ƒé­„

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- æœ¬ç¶“æ˜¯é“æ•™ç¡å‰ä¿®ç…‰çš„ç¶“å…¸
- å¼·èª¿å­˜æ€èº«ä¸­è«¸ç¥ä»¥è­·è¡›é­‚é­„
```

## ğŸ”§ é€²éšåŠŸèƒ½

### 1. è‡ªè¨‚è¼¸å‡ºç›®éŒ„

```python
crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422', generate_templates=False)

# è‡ªè¨‚ä¿å­˜ä½ç½®
crawler.save_to_text_files(book, 'my_output/texts')
crawler.generate_translation_templates(book, 'my_output/translations')
```

### 2. åªç”Ÿæˆç¿»è­¯æ¨¡æ¿

```python
# å¦‚æœå·²ç¶“æœ‰çˆ¬å–çš„è³‡æ–™
import json

with open('data/crawled/DZ1422_æ•ä¸­ç».json', 'r', encoding='utf-8') as f:
    book = json.load(f)

crawler = ShidianCrawler()
crawler.generate_translation_templates(book)
```

### 3. æ‰¹é‡è™•ç†

```python
from crawler.shidian_crawler import ShidianCrawler
import json
from pathlib import Path

crawler = ShidianCrawler()

# ç‚ºæ‰€æœ‰å·²çˆ¬å–çš„æ›¸ç±ç”Ÿæˆç¿»è­¯æ¨¡æ¿
json_files = Path('data/crawled').glob('*.json')

for json_file in json_files:
    with open(json_file, 'r', encoding='utf-8') as f:
        book = json.load(f)
    
    print(f"ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {book['title']}")
    crawler.generate_translation_templates(book)
```

## ğŸ“š å®Œæ•´ç¯„ä¾‹

### ç¯„ä¾‹1: çˆ¬å–ä¸¦ç¿»è­¯ä¸€æœ¬æ›¸

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from crawler.shidian_crawler import ShidianCrawler

def main():
    # 1. å»ºç«‹çˆ¬èŸ²
    crawler = ShidianCrawler(delay=2)
    
    # 2. çˆ¬å–æ›¸ç±ï¼ˆè‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼‰
    book = crawler.crawl_book('DZ1422')
    
    if book:
        # 3. æŸ¥çœ‹çµ±è¨ˆ
        crawler.print_statistics(book)
        
        # 4. æç¤ºä¸‹ä¸€æ­¥
        print(f"\nâœ“ å®Œæˆï¼")
        print(f"åŸæ–‡ä½ç½®: docs/source_texts/{book['title']}/")
        print(f"ç¿»è­¯æ¨¡æ¿: docs/translations/{book['title']}/")
        print(f"\né–‹å§‹ç¿»è­¯ï¼š")
        print(f"1. æ‰“é–‹ docs/translations/{book['title']}/README.md")
        print(f"2. æŸ¥çœ‹ç« ç¯€åˆ—è¡¨")
        print(f"3. é–‹å§‹ç¿»è­¯å„ç« ç¯€")

if __name__ == "__main__":
    main()
```

### ç¯„ä¾‹2: æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from crawler.shidian_crawler import ShidianCrawler

def main():
    crawler = ShidianCrawler(delay=3)  # æ‰¹é‡çˆ¬å–ç”¨è¼ƒé•·å»¶é²
    
    # è¦çˆ¬å–çš„æ›¸ç±åˆ—è¡¨
    book_ids = [
        'DZ1422',  # æ•ä¸­ç»
        'DZ1439',  # æ´ç„çµå®ç‰äº¬å±±æ­¥è™šç»
        'DZ1234',  # å…¶ä»–æ›¸ç±
    ]
    
    results = []
    
    for book_id in book_ids:
        print(f"\nè™•ç†: {book_id}")
        book = crawler.crawl_book(book_id)
        
        if book:
            results.append(book)
            print(f"âœ“ {book['title']} å®Œæˆ")
        else:
            print(f"âœ— {book_id} å¤±æ•—")
    
    print(f"\nç¸½çµ: æˆåŠŸ {len(results)}/{len(book_ids)} æœ¬")

if __name__ == "__main__":
    main()
```

## ğŸ¯ ç¿»è­¯è¦ç¯„å»ºè­°

### 1. å¿ å¯¦åŸæ–‡
- ä¿æŒåŸæ–‡æ„æ€ï¼Œä¸éš¨æ„å¢åˆª
- å°Šé‡åŸæ–‡çš„æ–‡åŒ–å…§æ¶µ

### 2. ç¾ä»£è¡¨é”
- ä½¿ç”¨ç¾ä»£ä¸­æ–‡ï¼Œè®“è®€è€…æ˜“æ‡‚
- é¿å…éæ–¼æ–‡è¨€æˆ–éæ–¼ç™½è©±

### 3. ä¿ç•™è¡“èª
- é‡è¦çš„é“æ•™è¡“èªä¿ç•™åŸæ–‡
- åœ¨è¨»è§£ä¸­è§£é‡‹è¡“èªå«ç¾©

### 4. æ–‡åŒ–è¨»è§£
- å°ç‰¹æ®Šçš„æ–‡åŒ–èƒŒæ™¯é€²è¡Œèªªæ˜
- å¹«åŠ©è®€è€…ç†è§£æ­·å²è„ˆçµ¡

## ğŸ“ˆ æ•ˆèƒ½æŒ‡æ¨™

- **çˆ¬å–é€Ÿåº¦**: 2-3 ç§’/ç« 
- **æ¨¡æ¿ç”Ÿæˆ**: < 1 ç§’/ç« 
- **æˆåŠŸç‡**: 100% (æ¸¬è©¦æ–¼ DZ1422, DZ1439)
- **è¨˜æ†¶é«”ä½¿ç”¨**: < 50MB
- **ç£ç¢Ÿç©ºé–“**: ~10KB/ç« ï¼ˆå«æ¨¡æ¿ï¼‰

## âš ï¸ æ³¨æ„äº‹é …

1. **ç¶²è·¯ç©©å®š**: ç¢ºä¿ç¶²è·¯é€£ç·šç©©å®š
2. **è«‹æ±‚é »ç‡**: ä¸è¦è¨­å®šéçŸ­çš„å»¶é²æ™‚é–“
3. **ç£ç¢Ÿç©ºé–“**: ç¢ºä¿æœ‰è¶³å¤ ç©ºé–“å„²å­˜çµæœ
4. **ç‰ˆæ¬Šå°Šé‡**: åƒ…ä¾›å­¸ç¿’ç ”ç©¶ä½¿ç”¨
5. **å‚™ä»½è³‡æ–™**: å®šæœŸå‚™ä»½ç¿»è­¯æˆæœ

## ğŸ”„ èˆ‡ç¾æœ‰ç³»çµ±æ•´åˆ

### æ•´åˆåˆ° main.py

```python
from crawler.shidian_crawler import ShidianCrawler

def crawl_and_translate(book_id):
    """çˆ¬å–ä¸¦ç”Ÿæˆç¿»è­¯æ¨¡æ¿"""
    crawler = ShidianCrawler()
    book = crawler.crawl_book(book_id, generate_templates=True)
    
    if book:
        print(f"âœ“ å®Œæˆ: {book['title']}")
        print(f"  åŸæ–‡: docs/source_texts/{book['title']}/")
        print(f"  ç¿»è­¯: docs/translations/{book['title']}/")
        return True
    return False
```

## ğŸ“ å•é¡Œæ’æŸ¥

### å•é¡Œ1: ç¿»è­¯æ¨¡æ¿æ²’æœ‰ç”Ÿæˆ

**è§£æ±ºæ–¹æ¡ˆ:**
```python
# ç¢ºèª generate_templates åƒæ•¸ç‚º True
book = crawler.crawl_book('DZ1422', generate_templates=True)

# æˆ–æ‰‹å‹•ç”Ÿæˆ
crawler.generate_translation_templates(book)
```

### å•é¡Œ2: æ¨¡æ¿æ ¼å¼ä¸å°

**è§£æ±ºæ–¹æ¡ˆ:**
- æª¢æŸ¥ `docs/translations/` ç›®éŒ„æ¬Šé™
- æŸ¥çœ‹æ—¥èªŒ: `data/logs/shidian_crawler.log`

### å•é¡Œ3: åŸæ–‡å…§å®¹ç‚ºç©º

**è§£æ±ºæ–¹æ¡ˆ:**
- æª¢æŸ¥ç¶²è·¯é€£ç·š
- ç¢ºèªæ›¸ç±ç·¨è™Ÿæ­£ç¢º
- æŸ¥çœ‹çˆ¬å–æ—¥èªŒ

## âœ… å®Œæˆæ¸…å–®

ä½¿ç”¨å‰ç¢ºèªï¼š
- [x] å·²å®‰è£ Python 3.7+
- [x] å·²å®‰è£ä¾è³´å¥—ä»¶
- [x] ç¶²è·¯é€£ç·šæ­£å¸¸
- [x] æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“

ä½¿ç”¨å¾Œæª¢æŸ¥ï¼š
- [x] `docs/source_texts/` æœ‰åŸæ–‡æª”æ¡ˆ
- [x] `docs/translations/` æœ‰ç¿»è­¯æ¨¡æ¿
- [x] `data/crawled/` æœ‰ JSON æª”æ¡ˆ
- [x] ç¿»è­¯æ¨¡æ¿æ ¼å¼æ­£ç¢º
- [x] README.md è³‡è¨Šå®Œæ•´

## ğŸ‰ ç¸½çµ

ä½ çš„çˆ¬èŸ²ç³»çµ±ç¾åœ¨æ˜¯ä¸€å€‹å®Œæ•´çš„ç¿»è­¯å·¥ä½œæµç¨‹å·¥å…·ï¼š

âœ… **è‡ªå‹•çˆ¬å–** - å¾å¸«å…¸å¤ç±ç¶²ç«™çˆ¬å–ç¶“æ–‡
âœ… **ä¿å­˜åŸæ–‡** - çµæ§‹åŒ–ä¿å­˜ç‚ºæ–‡å­—æª”æ¡ˆ
âœ… **ç”Ÿæˆæ¨¡æ¿** - è‡ªå‹•å»ºç«‹ç¿»è­¯æ¨¡æ¿
âœ… **å°ˆæ¡ˆç®¡ç†** - å®Œæ•´çš„å°ˆæ¡ˆçµæ§‹å’Œèªªæ˜
âœ… **é€²åº¦è¿½è¹¤** - README ä¸­çš„é€²åº¦ç®¡ç†

ç¾åœ¨å¯ä»¥é–‹å§‹ä½ çš„é“æ•™ç¶“å…¸ç¿»è­¯å·¥ä½œäº†ï¼

```bash
# ç«‹å³é–‹å§‹
python crawler/shidian_crawler.py
```

---

**æ›´æ–°æ™‚é–“**: 2025-10-20
**æ¸¬è©¦ç‹€æ…‹**: âœ… é€šé (DZ1422, DZ1439)
**åŠŸèƒ½ç‹€æ…‹**: âœ… å®Œæ•´
**å¯ç”¨ç‹€æ…‹**: âœ… ç”Ÿç”¢å°±ç·’
