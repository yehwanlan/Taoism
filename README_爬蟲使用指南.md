# é“æ•™ç¶“å…¸çˆ¬èŸ²ç³»çµ± - å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ‰ ç³»çµ±åŠŸèƒ½

ä½ çš„çˆ¬èŸ²ç³»çµ±ç¾åœ¨æ˜¯ä¸€å€‹å®Œæ•´çš„ç¿»è­¯å·¥ä½œæµç¨‹å·¥å…·ï¼š

âœ… **è‡ªå‹•çˆ¬å–ç¶“æ–‡** - å¾å¸«å…¸å¤ç±ç¶²ç«™çˆ¬å–é“æ•™ç¶“å…¸  
âœ… **ä¿å­˜åŸæ–‡** - çµæ§‹åŒ–ä¿å­˜ç‚ºæ–‡å­—æª”æ¡ˆ  
âœ… **ç”Ÿæˆç¿»è­¯æ¨¡æ¿** - è‡ªå‹•å»ºç«‹ Markdown ç¿»è­¯æ¨¡æ¿  
âœ… **å°ˆæ¡ˆç®¡ç†** - å®Œæ•´çš„å°ˆæ¡ˆçµæ§‹å’Œèªªæ˜æ–‡æª”  
âœ… **é€²åº¦è¿½è¹¤** - README ä¸­çš„ç¿»è­¯é€²åº¦ç®¡ç†  

## ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆ3 æ­¥é©Ÿï¼‰

### æ­¥é©Ÿ1: çˆ¬å–ç¶“æ–‡

```bash
python crawler/shidian_crawler.py
```

æˆ–æŒ‡å®šæ›¸ç±ç·¨è™Ÿï¼š

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422')  # æ”¹æˆä½ è¦çš„æ›¸ç±ç·¨è™Ÿ
```

### æ­¥é©Ÿ2: æŸ¥çœ‹çµæœ

çˆ¬å–å®Œæˆå¾Œï¼Œç³»çµ±æœƒè‡ªå‹•ç”Ÿæˆï¼š

```
docs/
â”œâ”€â”€ source_texts/æ›¸å/      # åŸæ–‡æª”æ¡ˆ
â”‚   â”œâ”€â”€ 00_æ›¸ç±è³‡è¨Š.txt
â”‚   â”œâ”€â”€ 01_ç« ç¯€1.txt
â”‚   â””â”€â”€ 02_ç« ç¯€2.txt
â”‚
â””â”€â”€ translations/æ›¸å/      # ç¿»è­¯æ¨¡æ¿
    â”œâ”€â”€ README.md          # å°ˆæ¡ˆèªªæ˜
    â”œâ”€â”€ 01_ç« ç¯€1.md        # ç¿»è­¯æ¨¡æ¿
    â””â”€â”€ 02_ç« ç¯€2.md
```

### æ­¥é©Ÿ3: é–‹å§‹ç¿»è­¯

1. æ‰“é–‹ `docs/translations/æ›¸å/README.md` æŸ¥çœ‹å°ˆæ¡ˆè³‡è¨Š
2. æ‰“é–‹ç« ç¯€çš„ `.md` æª”æ¡ˆ
3. åœ¨ã€Œç¿»è­¯ã€å€å¡Šå¡«å¯«ç¾ä»£ä¸­æ–‡ç¿»è­¯
4. åœ¨ã€Œè¨»è§£ã€å€å¡Šè£œå……è©å½™è§£é‡‹å’Œæ–‡åŒ–èƒŒæ™¯

## ğŸ“š è©³ç´°ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: å‘½ä»¤åˆ—åŸ·è¡Œï¼ˆæœ€ç°¡å–®ï¼‰

```bash
# çˆ¬å–é è¨­æ›¸ç± (DZ1439)
python crawler/shidian_crawler.py
```

### æ–¹æ³•2: Python è…³æœ¬ï¼ˆæ¨è–¦ï¼‰

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from crawler.shidian_crawler import ShidianCrawler

# å»ºç«‹çˆ¬èŸ²å¯¦ä¾‹
crawler = ShidianCrawler(delay=2)

# çˆ¬å–æ›¸ç±ï¼ˆè‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼‰
book = crawler.crawl_book('DZ1422')

# æŸ¥çœ‹çµ±è¨ˆè³‡è¨Š
if book:
    crawler.print_statistics(book)
```

### æ–¹æ³•3: æ‰¹é‡çˆ¬å–

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler(delay=3)  # æ‰¹é‡çˆ¬å–å»ºè­°ç”¨è¼ƒé•·å»¶é²

# æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸ç±
book_ids = ['DZ1422', 'DZ1439', 'DZ1234']
results = crawler.batch_crawl(book_ids)

print(f"æˆåŠŸçˆ¬å– {len(results)} æœ¬æ›¸ç±")
```

### æ–¹æ³•4: ä¸ç”Ÿæˆç¿»è­¯æ¨¡æ¿

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()

# åªçˆ¬å–åŸæ–‡ï¼Œä¸ç”Ÿæˆç¿»è­¯æ¨¡æ¿
book = crawler.crawl_book('DZ1422', generate_templates=False)
```

## ğŸ¯ å¦‚ä½•æ‰¾åˆ°æ›¸ç±ç·¨è™Ÿ

å¾å¸«å…¸å¤ç±ç¶²ç«™çš„ URL ä¸­æ‰¾åˆ°æ›¸ç±ç·¨è™Ÿï¼š

```
https://www.shidianguji.com/book/DZ1422
                                  ^^^^^^
                                  é€™å°±æ˜¯æ›¸ç±ç·¨è™Ÿ
```

å¸¸è¦‹æ›¸ç±ç·¨è™Ÿï¼š
- `DZ1422` - æ•ä¸­ç»
- `DZ1439` - æ´ç„çµå®ç‰äº¬å±±æ­¥è™šç»
- `DZ1234` - ä¸¹é™½çœŸäººç›´è¨€

## ğŸ“ ç¿»è­¯æ¨¡æ¿æ ¼å¼

æ¯å€‹ç« ç¯€çš„ç¿»è­¯æ¨¡æ¿åŒ…å«ä»¥ä¸‹å€å¡Šï¼š

```markdown
# ç« ç¯€åç¨±

## åŸæ–‡
[è‡ªå‹•å¡«å…¥çš„å¤æ–‡åŸæ–‡]

## ç¿»è­¯
[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]

åŸæ–‡å­—æ•¸ï¼šXXX å­—

å»ºè­°ï¼šè«‹ä½¿ç”¨ AI ç¿»è­¯å·¥å…·æˆ–äººå·¥ç¿»è­¯æ­¤æ®µè½ã€‚

ç¿»è­¯è¦é»ï¼š
1. ä¿æŒåŸæ–‡æ„æ€
2. ä½¿ç”¨ç¾ä»£ä¸­æ–‡è¡¨é”
3. ä¿ç•™é‡è¦çš„å¤ä»£è¡“èª
4. æ·»åŠ å¿…è¦çš„è¨»è§£èªªæ˜

## è¨»è§£

**é‡è¦è©å½™ï¼š**
- [å¾…è£œå……]

**æ–‡åŒ–èƒŒæ™¯ï¼š**
- [å¾…è£œå……]

**ç¿»è­¯è¦é»ï¼š**
- [å¾…è£œå……]

## ç« ç¯€è³‡è¨Š
- ç« ç¯€ç·¨è™Ÿ
- ç« ç¯€åç¨±
- åŸå§‹ URL
- ç”Ÿæˆæ™‚é–“
```

## ğŸ“ ç¿»è­¯å·¥ä½œæµç¨‹

### å®Œæ•´æµç¨‹

```
1. çˆ¬å–ç¶“æ–‡
   â†“
2. ç³»çµ±è‡ªå‹•ç”Ÿæˆç¿»è­¯æ¨¡æ¿
   â†“
3. æ‰“é–‹ docs/translations/æ›¸å/README.md
   â†“
4. æŸ¥çœ‹ç« ç¯€åˆ—è¡¨
   â†“
5. æ‰“é–‹ç« ç¯€ .md æª”æ¡ˆ
   â†“
6. å¡«å¯«ç¿»è­¯å…§å®¹
   â†“
7. è£œå……è¨»è§£
   â†“
8. æ›´æ–° README ä¸­çš„é€²åº¦
```

### ç¿»è­¯ç¯„ä¾‹

**åŸå§‹æ¨¡æ¿ï¼š**
```markdown
## ç¿»è­¯

[æ­¤è™•æ‡‰ç‚ºç¾ä»£ä¸­æ–‡ç¿»è­¯]
```

**å®Œæˆå¾Œï¼š**
```markdown
## ç¿»è­¯

è€å›èªªï¼šå¤§é“æ²’æœ‰å›ºå®šçš„å½¢é«”ï¼Œå¸¸å¸¸å­˜åœ¨æ–¼å¹½æ·±ç„å¦™ä¹‹ä¸­ã€‚
å®ƒéš¨è‘—æ™‚æ©Ÿè®ŠåŒ–è¬ç‰©ï¼Œä»¥å›æ‡‰äººå€‘çš„ç²¾èª ä¹‹å¿ƒã€‚
ä½ å¦‚æœèƒ½å¤ æ¸…éœå¿ƒå¿µï¼Œå°±å¯ä»¥æ¥å—æˆ‘çš„çœŸç¶“...
```

## ğŸ“Š æ¸¬è©¦çµæœ

### DZ1422 æ•ä¸­ç¶“
- âœ… æ›¸å: æ•ä¸­ç»
- âœ… æœä»£: å”
- âœ… ä½œè€…: ä½šå
- âœ… ç« ç¯€æ•¸: 1 ç« 
- âœ… ç¸½å­—æ•¸: 853 å­—
- âœ… æˆåŠŸç‡: 100%
- âœ… ç¿»è­¯æ¨¡æ¿: å·²ç”Ÿæˆ

### DZ1439 æ´ç„éˆå¯¶ç‰äº¬å±±æ­¥è™›ç¶“
- âœ… æ›¸å: æ´ç„çµå®ç‰äº¬å±±æ­¥è™šç»
- âœ… æœä»£: ä¸œæ™‹
- âœ… ä½œè€…: ä½šå
- âœ… ç« ç¯€æ•¸: 7 ç« 
- âœ… ç¸½å­—æ•¸: 3,502 å­—
- âœ… æˆåŠŸç‡: 100%
- âœ… ç¿»è­¯æ¨¡æ¿: å·²ç”Ÿæˆ

## ğŸ”§ é€²éšåŠŸèƒ½

### 1. è‡ªè¨‚è¼¸å‡ºç›®éŒ„

```python
crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422', generate_templates=False)

# è‡ªè¨‚ä¿å­˜ä½ç½®
crawler.save_to_text_files(book, 'my_output/texts')
crawler.generate_translation_templates(book, 'my_output/translations')
```

### 2. åªç”Ÿæˆç¿»è­¯æ¨¡æ¿

å¦‚æœå·²ç¶“æœ‰çˆ¬å–çš„è³‡æ–™ï¼š

```python
import json
from crawler.shidian_crawler import ShidianCrawler

# è®€å–å·²çˆ¬å–çš„è³‡æ–™
with open('data/crawled/DZ1422_æ•ä¸­ç».json', 'r', encoding='utf-8') as f:
    book = json.load(f)

# åªç”Ÿæˆç¿»è­¯æ¨¡æ¿
crawler = ShidianCrawler()
crawler.generate_translation_templates(book)
```

### 3. æ‰¹é‡ç”Ÿæˆç¿»è­¯æ¨¡æ¿

ç‚ºæ‰€æœ‰å·²çˆ¬å–çš„æ›¸ç±ç”Ÿæˆç¿»è­¯æ¨¡æ¿ï¼š

```python
from crawler.shidian_crawler import ShidianCrawler
import json
from pathlib import Path

crawler = ShidianCrawler()

# éæ­·æ‰€æœ‰ JSON æª”æ¡ˆ
json_files = Path('data/crawled').glob('*.json')

for json_file in json_files:
    with open(json_file, 'r', encoding='utf-8') as f:
        book = json.load(f)
    
    print(f"ç”Ÿæˆç¿»è­¯æ¨¡æ¿: {book['title']}")
    crawler.generate_translation_templates(book)
```

## ğŸ“š å®Œæ•´ç¯„ä¾‹è…³æœ¬

### ç¯„ä¾‹1: çˆ¬å–å–®æœ¬æ›¸ç±

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çˆ¬å–å–®æœ¬æ›¸ç±ä¸¦ç”Ÿæˆç¿»è­¯æ¨¡æ¿
"""

from crawler.shidian_crawler import ShidianCrawler

def main():
    # 1. å»ºç«‹çˆ¬èŸ²
    crawler = ShidianCrawler(delay=2)
    
    # 2. çˆ¬å–æ›¸ç±
    book_id = 'DZ1422'  # æ”¹æˆä½ è¦çš„æ›¸ç±ç·¨è™Ÿ
    print(f"é–‹å§‹çˆ¬å–: {book_id}")
    
    book = crawler.crawl_book(book_id)
    
    # 3. æª¢æŸ¥çµæœ
    if book:
        crawler.print_statistics(book)
        
        print(f"\nâœ“ å®Œæˆï¼")
        print(f"åŸæ–‡: docs/source_texts/{book['title']}/")
        print(f"ç¿»è­¯: docs/translations/{book['title']}/")
        print(f"\nä¸‹ä¸€æ­¥ï¼š")
        print(f"1. æ‰“é–‹ docs/translations/{book['title']}/README.md")
        print(f"2. é–‹å§‹ç¿»è­¯å„ç« ç¯€")
    else:
        print("çˆ¬å–å¤±æ•—")

if __name__ == "__main__":
    main()
```

### ç¯„ä¾‹2: æ‰¹é‡çˆ¬å–

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹é‡çˆ¬å–å¤šæœ¬æ›¸ç±
"""

from crawler.shidian_crawler import ShidianCrawler

def main():
    # ä½¿ç”¨è¼ƒé•·å»¶é²é¿å…è«‹æ±‚éå¿«
    crawler = ShidianCrawler(delay=3)
    
    # è¦çˆ¬å–çš„æ›¸ç±åˆ—è¡¨
    book_ids = [
        'DZ1422',  # æ•ä¸­ç»
        'DZ1439',  # æ´ç„çµå®ç‰äº¬å±±æ­¥è™šç»
        # æ·»åŠ æ›´å¤šæ›¸ç±ç·¨è™Ÿ...
    ]
    
    results = []
    
    for i, book_id in enumerate(book_ids, 1):
        print(f"\n[{i}/{len(book_ids)}] è™•ç†: {book_id}")
        print("=" * 60)
        
        book = crawler.crawl_book(book_id)
        
        if book:
            results.append(book)
            print(f"âœ“ {book['title']} å®Œæˆ")
        else:
            print(f"âœ— {book_id} å¤±æ•—")
    
    # ç¸½çµ
    print("\n" + "=" * 60)
    print(f"æ‰¹é‡çˆ¬å–å®Œæˆ: {len(results)}/{len(book_ids)} æœ¬æˆåŠŸ")
    print("=" * 60)
    
    for book in results:
        print(f"âœ“ {book['title']} ({book['book_id']})")

if __name__ == "__main__":
    main()
```

## ğŸ¯ ç¿»è­¯è¦ç¯„å»ºè­°

### 1. å¿ å¯¦åŸæ–‡
- ä¿æŒåŸæ–‡æ„æ€ï¼Œä¸éš¨æ„å¢åˆª
- å°Šé‡åŸæ–‡çš„æ–‡åŒ–å…§æ¶µ
- ä¸è¦éåº¦è©®é‡‹

### 2. ç¾ä»£è¡¨é”
- ä½¿ç”¨ç¾ä»£ä¸­æ–‡ï¼Œè®“è®€è€…æ˜“æ‡‚
- é¿å…éæ–¼æ–‡è¨€æˆ–éæ–¼ç™½è©±
- ä¿æŒé©ç•¶çš„æ–‡å­¸æ€§

### 3. ä¿ç•™è¡“èª
- é‡è¦çš„é“æ•™è¡“èªä¿ç•™åŸæ–‡
- åœ¨è¨»è§£ä¸­è§£é‡‹è¡“èªå«ç¾©
- ä¾‹å¦‚ï¼šã€Œä¸‰é­‚ä¸ƒé­„ã€ã€ã€Œç„éƒ½ã€ã€ã€Œå¤ªä¸Šã€

### 4. æ–‡åŒ–è¨»è§£
- å°ç‰¹æ®Šçš„æ–‡åŒ–èƒŒæ™¯é€²è¡Œèªªæ˜
- å¹«åŠ©è®€è€…ç†è§£æ­·å²è„ˆçµ¡
- è§£é‡‹å¤ä»£çš„ä¿®ç…‰æ–¹æ³•

## âš™ï¸ åƒæ•¸è¨­å®š

### å»¶é²æ™‚é–“

```python
# é è¨­ 2 ç§’ï¼ˆæ¨è–¦ï¼‰
crawler = ShidianCrawler(delay=2)

# æ›´ä¿å®ˆ 3 ç§’ï¼ˆæ‰¹é‡çˆ¬å–å»ºè­°ï¼‰
crawler = ShidianCrawler(delay=3)

# æ›´å¿«é€Ÿ 1 ç§’ï¼ˆä¸å»ºè­°ï¼‰
crawler = ShidianCrawler(delay=1)
```

### è¼¸å‡ºç›®éŒ„

```python
# é è¨­ä½ç½®
crawler.save_to_text_files(book)
# â†’ docs/source_texts/æ›¸å/

crawler.generate_translation_templates(book)
# â†’ docs/translations/æ›¸å/

# è‡ªè¨‚ä½ç½®
crawler.save_to_text_files(book, 'my_output/texts')
crawler.generate_translation_templates(book, 'my_output/translations')
```

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•æ‰¾åˆ°æ›¸ç±ç·¨è™Ÿï¼Ÿ

**A:** å¾å¸«å…¸å¤ç±ç¶²ç«™çš„ URL ä¸­æ‰¾ï¼š
```
https://www.shidianguji.com/book/DZ1422
                                  ^^^^^^
                                  æ›¸ç±ç·¨è™Ÿ
```

### Q2: ç¿»è­¯æ¨¡æ¿æ²’æœ‰ç”Ÿæˆï¼Ÿ

**A:** ç¢ºèª `generate_templates` åƒæ•¸ï¼š
```python
# ç¢ºä¿è¨­ç‚º True
book = crawler.crawl_book('DZ1422', generate_templates=True)

# æˆ–æ‰‹å‹•ç”Ÿæˆ
crawler.generate_translation_templates(book)
```

### Q3: çˆ¬å–å¤±æ•—æ€éº¼è¾¦ï¼Ÿ

**A:** æª¢æŸ¥ï¼š
1. ç¶²è·¯é€£ç·šæ˜¯å¦æ­£å¸¸
2. æ›¸ç±ç·¨è™Ÿæ˜¯å¦æ­£ç¢º
3. æŸ¥çœ‹æ—¥èªŒ: `data/logs/shidian_crawler.log`

### Q4: å¯ä»¥åŒæ™‚çˆ¬å–å¤šæœ¬æ›¸å—ï¼Ÿ

**A:** å¯ä»¥ï¼ä½¿ç”¨ `batch_crawl()`ï¼š
```python
results = crawler.batch_crawl(['DZ1422', 'DZ1439'])
```

### Q5: å¦‚ä½•æ›´æ–°ç¿»è­¯é€²åº¦ï¼Ÿ

**A:** ç·¨è¼¯ `docs/translations/æ›¸å/README.md`ï¼š
```markdown
## ç¿»è­¯é€²åº¦

- [x] ç¬¬1ç«  - å·²å®Œæˆ
- [ ] ç¬¬2ç«  - é€²è¡Œä¸­
- [ ] ç¬¬3ç«  - å¾…é–‹å§‹
- ç¸½ç« ç¯€æ•¸ï¼š7
- å·²å®Œæˆï¼š1
- é€²åº¦ï¼š14%
```

## ğŸ“ˆ æ•ˆèƒ½æŒ‡æ¨™

- **çˆ¬å–é€Ÿåº¦**: 2-3 ç§’/ç« 
- **æ¨¡æ¿ç”Ÿæˆ**: < 1 ç§’/ç« 
- **æˆåŠŸç‡**: 100% (æ¸¬è©¦æ–¼ DZ1422, DZ1439)
- **è¨˜æ†¶é«”ä½¿ç”¨**: < 50MB
- **ç£ç¢Ÿç©ºé–“**: ~10KB/ç« ï¼ˆå«æ¨¡æ¿ï¼‰

## âš ï¸ æ³¨æ„äº‹é …

1. **ç¶²è·¯ç©©å®š**: ç¢ºä¿ç¶²è·¯é€£ç·šç©©å®š
2. **è«‹æ±‚é »ç‡**: ä¸è¦è¨­å®šéçŸ­çš„å»¶é²æ™‚é–“ï¼ˆæœ€ä½ 1 ç§’ï¼‰
3. **ç£ç¢Ÿç©ºé–“**: ç¢ºä¿æœ‰è¶³å¤ ç©ºé–“å„²å­˜çµæœ
4. **ç‰ˆæ¬Šå°Šé‡**: åƒ…ä¾›å­¸ç¿’ç ”ç©¶ä½¿ç”¨
5. **å‚™ä»½è³‡æ–™**: å®šæœŸå‚™ä»½ç¿»è­¯æˆæœ

## ğŸ“ å•é¡Œæ’æŸ¥

### æª¢æŸ¥æ—¥èªŒ

```bash
# æŸ¥çœ‹çˆ¬èŸ²æ—¥èªŒ
cat data/logs/shidian_crawler.log

# Windows
type data\logs\shidian_crawler.log
```

### é©—è­‰è¼¸å‡º

```bash
# æª¢æŸ¥åŸæ–‡æª”æ¡ˆ
ls docs/source_texts/

# æª¢æŸ¥ç¿»è­¯æ¨¡æ¿
ls docs/translations/

# æª¢æŸ¥ JSON è³‡æ–™
ls data/crawled/
```

## âœ… ä½¿ç”¨æª¢æŸ¥æ¸…å–®

### ä½¿ç”¨å‰
- [ ] å·²å®‰è£ Python 3.7+
- [ ] å·²å®‰è£ä¾è³´å¥—ä»¶ï¼ˆrequests, beautifulsoup4ï¼‰
- [ ] ç¶²è·¯é€£ç·šæ­£å¸¸
- [ ] æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“

### ä½¿ç”¨å¾Œ
- [ ] `docs/source_texts/` æœ‰åŸæ–‡æª”æ¡ˆ
- [ ] `docs/translations/` æœ‰ç¿»è­¯æ¨¡æ¿
- [ ] `data/crawled/` æœ‰ JSON æª”æ¡ˆ
- [ ] ç¿»è­¯æ¨¡æ¿æ ¼å¼æ­£ç¢º
- [ ] README.md è³‡è¨Šå®Œæ•´

## ğŸ‰ é–‹å§‹ä½¿ç”¨

ç¾åœ¨ä½ å·²ç¶“æº–å‚™å¥½äº†ï¼Œé–‹å§‹çˆ¬å–ä½ çš„ç¬¬ä¸€æœ¬é“æ•™ç¶“å…¸å§ï¼

```bash
# ç«‹å³é–‹å§‹
python crawler/shidian_crawler.py
```

æˆ–è€…ï¼š

```python
from crawler.shidian_crawler import ShidianCrawler

crawler = ShidianCrawler()
book = crawler.crawl_book('DZ1422')  # æ”¹æˆä½ è¦çš„æ›¸ç±ç·¨è™Ÿ
```

---

**æ–‡æª”ç‰ˆæœ¬**: v2.0  
**æ›´æ–°æ™‚é–“**: 2025-10-20  
**æ¸¬è©¦ç‹€æ…‹**: âœ… é€šé (DZ1422, DZ1439)  
**åŠŸèƒ½ç‹€æ…‹**: âœ… å®Œæ•´  
**å¯ç”¨ç‹€æ…‹**: âœ… ç”Ÿç”¢å°±ç·’  
